## 排序

|     排序算法     | 时间复杂度 | 是否基于比较 |
| :--------------: | :--------: | :----------: |
| 冒泡、插入、选择 |   O(n*n)   |      是      |
|    快排、归并    | O(n*logn)  |      是      |
|  桶、计数、基数  |    O(n)    |      否      |

**1. 冒泡、插入、选择（适合小规模数据量排序）**

冒泡和选择都是固定的移动次数，也就是原始数据的逆序度。而插入排序移动次数在实际中更少，虽然这三种排序的时间复杂度都是 O(n*n)，但一般选择的循序是：插入>冒泡>选择。这三种都是原地排序，因为空间复杂度都是 O(1)，都没有利用额外的空间。而插入和冒泡是稳定的排序，但是选择排序由于每次都是将未排序的那一部分中最小的那个元素和第一个元素进行交换，改变了原有的顺序，所以选择排序是不稳定的。

**2. 快排、归并（适合大规模数据量排序）**

**归并排序**用到分治思想，分治需要用到递归来实现。分治是一种解决问题的处理思想，递归是一种编程技巧。

可以看出，归并排序先是不断的分治，然后利用 merge() 函数对两个子队列进行合并，那么当子队列1和子队列2中出现相同元素的时候，我们会先把子队列1放到新的合并位置上，所以不会影响原先的顺序，是稳定的排序。

归并排序的执行效率与原始数组的有序程度无关，时间复杂度非常稳定，最好、最坏、平均都是 O(nlogn)。看起来非常优秀，因为快排最坏情况下也要 O(n*n)，但是归并排序也有致命缺点，就是它不是原地排序，在 merge 时它需要 O(n) 的空间来合并两个子队列。

**快排**也用到分治思想，但是它的核心思想是分区：

如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。我们遍历 p 到 r 之间的数据，将小于 pivot 的数据放到左边，大于 pivot 的数据放到右边，pivot 放到中间。这样就将 p 到 r 之间的数据分成了三部分。

问题：有十个小日志文件，每个 300 MB，你有十个接口去访问这个十个文件，每个文件中的日志都按照时间戳从小到大排好了序，你只有 1 G 的内存，让你合并这十个日志文件成一个，如何比较快速的合并？



#### 线性排序

下面几种排序因为时间复杂度是线性的，所以称为线性排序。它们不是基于比较的排序算法，不涉及元素之间的比较操作。

**3. 桶排序**

思想也很好理解，就是先划分成很多个桶，每个桶中放的是固定大小区间的数据，然后如果你要对一大批数据进行排序，你就直接把这批数据逐个放到对应区间的桶里面就行了。然后再利用快排分别对每个桶进行排序，这样从第一个桶到最后一个桶依次取出数据就是最终的排序结果了。

桶排序时间复杂度是 O(nlog(n/m))，当桶的个数接近数的个数时，就变成了 O(n)，但这都基于所有数据能够比较均匀的分布在各个桶之内这个假设，如果所有数据都被分到一个桶内，那就退化成 O(nlogn) 了。

比较适用于外存上的，数据量比较大，内存有限的排序。

**4. 记数排序**

针对数据量远大于数据所在区间的这种情况，是一种特殊的桶排序。比如高考有 50 万考生，但是成绩都是在 0~750 之间，那么可以设置 751 个桶，把相同分数的放到相同的桶里面。

**5. 基数排序**

比如你要给十万个 11 位的电话号码排序，你用快排也可以，但是是 O(nlogn)，用桶排序或者记数排序肯定不现实了，因为 11 位代表的数字太大了。用基数排序就是从最后一位开始排序，一直到电话号码的第一位，但是这里针对每一位上的排序要用稳定性排序。我们在每一位上排序可以用桶排序，比如这里的电话号码有 11 位，那么就需要进行 11 次桶排序，这样时间复杂度就是 11*O(n)，也就是 O(n)。

但是如果这些电话号码不都是 11 位的呢？你可以给不是 11 位的那些号码在前面补 0，补齐 11 位，因为这样也不会影响比较。

可以仔细想想，基数排序是需要可以分割出独立的“位”来比较的，而且“位”之间有递进的关系，如果 a 数据的高位比 b 数据大，那么剩下的低位就不用比较了。而且每一位上的数据范围不能太大，否则就不能用线性排序了，最终也就达不到 O(n) 的时间复杂度了。



### 如何实现一个通用的、高性能的排序算法

由于 O(n) 这类线性排序算法只适用于特定数据，所以不太考虑。一般小数据量选择冒泡、选择、插入这种 O(nn) 的排序，但是当数据量大的时候，肯定还是选择 O(nlogn) 的，那么这里又有归并、快排，堆排序，由于归并不是原地排序，需要耗费额外空间，所以一般用的是快排，那么快排也有缺点就是当最坏情况（也就是当所有的数据都跑到一个分区里面了）下会变成 O(n*n)，这是由于分区点选的不合理导致的，当分区点分成的分区之间数据量差不多才是最理想的。

为了让每个分区数据量都比较平均，也就是你要找到一个 pivot，这个 pivot 越接近中位数越好，那么我们一般可以用：

1.三数取中法（多数取中法）

从首、尾、中间取到三个点，取这三个数的中间值作为 pivot。

2.随机法

也就是从这些数据中随机去一个数作为 pivot，这样也比你每次都取第一个或者最后一个数作为 pivot 遇到最坏情况的可能性要小。



### C 语言中的 qsort() 函数

这个函数会优先使用归并排序，因为当数据量少的时候排序更稳定。但数据量大的时候会转而使用快排，而且 qsort() 函数在快排中也是用三数取中法来确定 pivot 的。并且当数据量很小很小时，它会转而使用插入排序，因为小数据量的时候 O(n*n) 并不一定比 O(nlogn) 的算法执行时间长。

而且为了防止堆栈溢出，qsort 实现了一个堆上的栈，手动模拟递归。

