## 第一次学习任务

### 1. virtualenv

在 Python 中用于环境隔离，因为由于各个 Python 项目所需要的包的版本不相同，所以把聚焦点放到某一个项目上，为每一个项目单独配置一套环境。

virtualenv 虚拟环境的原理就是：执行 source myenv/bin/activate 以后会把 myenv/bin （也就是你程序要用的解释器）塞到 PATH 前面，让这个**复制**出来的 Python 解释器最优先被搜索到，所以后面再安装包时，<path_prefix> 就会是myenv 了，实现安装路径的隔离。

用命令 source venv/bin/activate 进入一个 virtualenv 环境时，virtualenv 会修改相关环境变量，让命令 python 和 pip 均指向当前的 virtualenv 环境。

### 2. 关于 Python 中安装的第三方包

 python 解释器在哪 --> 推导出包的路径 <path_prefix>

Python3.7 自带了 pip3

```shell
# 创建一个虚拟环境
python3 -m virtualenv titanicEnv
```

参考来源：[Python安装包的问题](https://frostming.com/2019/03-13/where-do-your-packages-go)

### 3. Kaggle 初步学习（机器学习常规步骤）

1. 基本步骤

（1）读数据

（2）选取特征 X，拿到 train_data 中的特征数据 X，y

（3）选定模型，拿 X 和 y 去训练 model，然后拿 X_test 去预测，得到 prediction

2. 对模型进行评估

（1）mean absoluted error（MAE）

3. 欠拟合和过拟合

This is a phenomenon called **overfitting**, where a model matches the training data almost perfectly, but does poorly in validation and other new data.

When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called **underfitting**.

we want the low point of the (red) validation curve in.（就是要MAE值最低的那个点）

### 4. Titanic 问题

1. data science 需要解决的问题

   （1）classifying 分类

   （2）correlating 相关联

   （3）converting 转换（可能需要将文本转成数值）

   （4）completing 补全缺失值

   （5）correcting 将样本中一些可能错误的值进行更正或者排除这些异常样本。如果某个特征没啥用而且可能扭曲最   		 终结果，我们可以将这个特征直接抛弃。

   （6）creating 可以依据已给的特征创造新的特征

   （7）charting 画图来看中间结果

总结：基于数据分析去做出 Assumtions。通过初步的看数据（train_df.info, descripe）来观察，观察之后做一些猜想，然后再通过对数据进行分析（可以作图）来验证猜想，再去决定要不要将某个特征放到 model 中训练。（观察 --> 决定）

2. 数据分析

   （1）单个分析某个特征和 goal 之间的关系（类似于单一变量法），目的是去验证我们的一些猜想和假设。

   （2）可以通过作图发现某些特征和 goal 之间并不存在线性关系。

3. 整理数据

   （1）Correcting by drop features

   丢弃一些特征，这样我们可以处理更少的数据，简化分析。但是不能随便丢弃，要基于 assumption and decisions来决定丢弃。

   （2）Creating new feature extracting from existing

   某些给的特征可能看上去和 goal 之间没有直接联系，但是通过处理之后，可能找到它们之间的关系，从而创造出一个新的特征。

   （3）Converting a categorical feature

   对于像性别为 female、male 这样的带有字符串的特征，我们需要将它数字化，也就是转成数值型。

   （4）Completing a numerical continuous feature

   给的 train 或者 test data 中某些数值型样本可能存在缺失，所以需要对其补全。补全一般有三种方式，比如这里对 Age 补全：

   - 一种简单的方法是在均值和标准差之间生成随机数
   - 还可以通过**利用其它特征来猜测缺失值**， In our case we note correlation among Age, Gender, and Pclass. Guess Age values using median values for Age across sets of Pclass and Gender feature combinations. So, median Age for Pclass=1 and Gender=0, Pclass=1 and Gender=1, and so on...
   - 结合方法1和方法2。因此，不要根据中位数来猜测年龄值，而是使用平均值和标准差之间的随机数，基于一组Pclass和性别组合

   但是注意补全得考虑是否会带入 noise，这里的第一种和第三种方法 will introduce random noise into our models，所以这里采用方法二。

   （5）对数值型特征转成某个区间来观察

   比如这里通过给 Age 划分成一个个的区间，来观察各年龄段（AgeBand）和 survived 之间的关系。但是在模型中用的是数值，所以还需要将 AgeBand 换成序数型特征。通过转成区间的方法，避免了某些不太正常的样本对模型产生噪音。

   （6）Create new feature combining existing features

   我们还可以通过将 Parch 和 SlibSp 联合起来创建一个新的特征 FamilySize，这样就可以 drop 掉 Parch 和 SlibSp。在 FamilySize 和 survived 的关系表格可以看到其实它和 survived 没有一个线性关系，所以我们创建了一个 IsAlone 特征，这个特征就和 survived 有线性关系了，所以把其它几个特征直接 drop 掉。

4. 模型

   要搞清你解决的是哪类问题，是分类问题吗？分类又有二分类、多分类，是监督/无监督学习？是回归问题吗？主要看你的特征和 goal 之间的关系。监督学习 + 分类 + 回归问题，可以用以下模型：

   - Logistic Regression
   - KNN or k-Nearest Neighbors
   - Support Vector Machines
   - Naive Bayes classifier
   - Decision Tree
   - Random Forrest
   - Perceptron
   - Artificial neural network
   - RVM or Relevance Vector Machine

### 5. 总结

主要通过 [Titanic Data Science Solutions](https://www.kaggle.com/startupsci/titanic-data-science-solutions) 学习，对利用 data science 来解决问题有了一个初步的认识，当然，这个帖子在 Kaggle 中并不是得分最高的，但是这却是一个很好的数据分析、用 data science 解决实际问题的帖子。在对这个帖子进行学习中我还产生了很多疑问，比如：这是一个线性回归问题没错，但是在将字符串特征转换数值型特征中，简单的将 female 转成 1，male 转成 0，或者登船口的转换关系为 {'S': 0, 'C': 1, 'Q': 2}，我还不太明白，对训练之后的模型中特征的对应的系数怎么来的也不清楚。

复现过程：[点这里](https://github.com/winterliu1020/MachineLearning/blob/main/titanic.ipynb)

