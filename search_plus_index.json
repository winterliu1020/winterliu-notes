{"./":{"url":"./","title":"Introduction","keywords":"","body":"winterliu-notes 我学习过程中记录的一些笔记 :rocket: zheli这里是 删除线这里是删除线 输入：[toc]+回车，会产生目录 输入：|姓名|性别|学校| + 回车，产生表格 任务列表：- [ ] 任务1 [x] 任务1 [x] 吃饭 算法 :rocket::rocket::rocket::rocket::rocket: [ ] LeetCode + labuladong算法小抄 (300+题) [ ] 剑指offer [ ] 算法第四版 [ ] 左神算法视频（中级、高级课程） [ ] 程序员代码面试指南 基础:rocket::rocket::rocket::rocket: 计算机网络 操作系统 数据库 Java语言基础 Java并发 JVM Linux 设计模式 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-08 20:14:17 "},"notes/SUMMARY/Java 基础.html":{"url":"notes/SUMMARY/Java 基础.html","title":"Java 基础","keywords":"","body":"Java 基础 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-20 16:57:20 "},"notes/Java 基础/Java基础知识.html":{"url":"notes/Java 基础/Java基础知识.html","title":"Java 基础知识","keywords":"","body":"Java基础1 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-11 11:40:20 "},"notes/Java 基础/Java内存区域.html":{"url":"notes/Java 基础/Java内存区域.html","title":"Java 内存区域","keywords":"","body":"前言 Java虚拟机在执行Java程序的过程中会把它管理的内存区域划分成若干个不同的数据区域。有的区域属于所有线程共享的(这些区域随着虚拟机进程的启动而存在)、有些区域属于线程隔离的(这些区域则依赖于用户线程的启动和结束)。划分成以下区域： 1. 程序计数器 程序计数器是一个很小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个程序计数器来完成。 每条线程都需要一个独立的程序计数器，各个线程之间程序计数器互不影响，独立存储，程序计数器这片小内存叫做“线程私有”的内存。 如果线程正在执行的是一个Java方法，那么这个程序计数器记录的就是正在执行的虚拟机字节码指令的地址。 2. Java虚拟机栈 这片区域也是线程私有的，它的生命周期和线程相同。虚拟机栈描述的是Java方法执行的内存模型(也就是说虚拟机栈是对于Java方法而言，而方法区则存储的是一些Class基本信息，即针对的是类)，每个方法执行时都会创建一个栈帧用于存储局部变量、操作数栈、动态链表、方法出口等信息，每一个方法从调用到执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 Java虚拟机栈中包含了局部变量表，而局部变量表中存的是：编译器可知的基本数据类型、对象引用类型和returnAddress类型。 局部变量表所需的内存空间在编译期间就可以完成分配，当进入一个方法时，这个方法需要多少局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 3. 本地方法栈 本地方法栈和虚拟机栈所发挥的作用非常相似，虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则为虚拟机使用到的Native方法服务。 4.Java堆 Java堆是Java虚拟机管理的最大的一片内存区域。被所有线程共享，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象。所有的对象实例和数组都要在堆上分配。 Java堆是垃圾收集器的主要区域。 5. 方法区 方法区也是各个线程共享的区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码。 6.运行时常量池 它是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 以下探究HotSpot虚拟机在Java堆中对象分配、布局和访问的过程： 1. 对象的创建(例如克隆、反序列化) 从语言层面，创建对象仅仅是一个new关键字而已，而从Java虚拟机来看，创建一个对象(这里仅仅指普通对象，不包括数组和Class对象)的过程如下： 虚拟机遇到一条new指令时，首先去检查这个指令的参数能否在常量池中定位到一个类的符号引用，并检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，则必须先执行相应类的加载过程。 类加载检查通过后，然后虚拟机将为新生对象分配内存。对象所需要的内存大小在类加载完后便可以完全确定。为对象分配内存其实就是将一块确定大小的内存从Java堆中划分出来。 根据Java堆是否规整，在分配内存时是会采用不同的策略的，一般采用：指针碰撞(Bump the Pointer)、空闲列表(Free List)。而Java堆是否规整又是由所采用的垃圾收集器是否带有压缩整理功能决定的。 需要注意的是，由于Java对象的创建是非常常见的，比如仅仅是修改一个指针所指向的位置，在并发情况下也可能存在线程安全问题，可能出现正在给对象A分配内存，内存已经在Java堆中划分出来了，但是还没来得及将指针指向这块内存，另一个线程中的对象B又同时使用了原来这个指针来分配内存。以上这个过程是存在问题的，解决办法有两种，一是对分配内存的动作进行同步处理，保证这个操作的原子性。另一种是把内存分配的动作按照线程划分在不同的空间中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲(TLAB)，那个线程需要分配内存，就在哪个线程的TLAB上分配，只有当TLAB使用完了并分配新的TLAB时，才需要同步锁定。 内存分配完成后，虚拟机会将分配到的内存空间都初始化为零值(不包括对象头)。然后虚拟机要对对象进行一些设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息，这些信息存放在对象的对象头中。 到此，从虚拟机的视角，一个对象已经产生了，但是从Java程序的视角来看，对象的创建才刚开始(才仅仅分配了内存、初始化了一些类数据)，方法还没有执行，对象中所有的字段都还为零。执行new指令之后会接着执行方法，把对象按照程序员的意向进行初始化，这样一个真正可用的对象才算真正产生出来。 2. 对象的内存布局 对象在内存中的布局可以分为3块区域：对象头(Head)、实例数据(Instance Data)、对齐填充(Padding)。 对象头，用于存储对象自身的运行时数据，如哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳。对象头的另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据部分是对象真正存储的有效信息，也是程序代码中定义的各种类型的字段内容。 3. 对象的访问定位 建立对象是为了使用对象，而在Java程序中需要通过栈(一般指虚拟机栈)上的reference数据来操作堆上的具体对象。由于reference在Java虚拟机规范中只规定了一个指向对象的引用，并没有规定这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方式要看虚拟机具体如何实现，一般有两种方式：使用句柄、直接指针。 1.使用句柄访问的话，Java堆中会 分出一块内存当做句柄池，reference中存储的就是对象的句柄地址，句柄中则包含了对象实例数据与类型数据各自的具体地址信息。 2.使用直接指针访问的话，那Java堆对象的布局就必须考虑如何放置访问类型数据的相关信息，这里reference中存储的直接就是对象的地址。 句柄访问好处：存储稳定 (常用)直接指针访问好处：访问速度快 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-09 10:10:29 "},"notes/Java 基础/Java中HashMap底层原理.html":{"url":"notes/Java 基础/Java中HashMap底层原理.html","title":"Java 中 HashMap 底层原理","keywords":"","body":"1. 首先看几个问题 什么时候会使用HashMap?它有什么特点？ HashMap的工作原理是什么？ HashMap中put和get的原理，equals()和hashCode()函数都有什么作用？ hash如何实现？为什么要这样实现？ 当HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？ 当执行下面的操作时： HashMap map = new HashMap(); map.put(\"语文\",1); map.put(\"数学\",2); map.put(\"英语\",3); map.put(\"历史\",4); map.put(\"政治\",5); map.put(\"地理\",6); map.put(\"生物\",7); map.put(\"化学\",8); for(Entry entry : map.entrySet()){ System.out.println(entry.getKet() + \":\" + entry.getValue()); } 执行结果： 政治: 5生物: 7历史: 4数学: 2化学: 8语文: 1英语: 3地理: 6 为什么不是按照循序打印出来呢？看下面这张图来对HashMap结构有一个感性认识： 你可以看到这些entry在内存中既不是连续的、也不是按照put的循序排列的。 官方文档描述HashMap: Hash table based implementation of the Map interface . This implementation provides all of the optional map operations, and permits null values and the null key. (The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.) This class ++makes no guarantees as to the order of the map++; in particular, it does ++not guarantee that the order will remain constant over time++. 注意点：基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的循序)、不保证序列不随时间变化。 2. 两个重要参数 HashMap中需要注意两个重要的参数是：容量(Capacity)和负载因子(Load factor) Initial capacity The capacity is the number of buckets in the hash table, The initial capacity is simply the capacity at the time the hash table is created. Load factor The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased. Capacity其实就是buckets的数目，Load factor就是buckets填满程度的最大比例。当HashMap中元素的个数大于capacity*load factor时就需要调整buckets的数目为当前的2倍。 3. put函数的实现 put函数的大致思路是： 利用hashCode()函数得到key的hash值，然后再计算这个hash值的index； 如果没有碰撞就直接放在bucket中； 如果碰撞了就以链表的形式放在buckets的后面 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD),就把链表转换成红黑树； 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket满了，就resize. 具体代码如下： public V put(K key, V value){ // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict){ Node[] tab; Node p; int n, i; // tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 计算index，并对null做处理 if ((p = tab[i = (n -1) & hash]) == null) tab[i] = newNode(hash, key, value, null); else{ Node e; K k; // 节点存在 if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k)))) e = p; // 该链为树 else if (p instanceof TreeNode) e = ((TreeNode)p).putTreeVal(this, tab, hash, key, value); // 该链为链表 else { for (int binCount = 0; ; ++binCount){ if ((e = p.next) == null){ p.next = newNode(hash, key, value, null); if(binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 当链表长度超过了一定值时将链表转成红黑树 break; } if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) break; // 说明节点已存在 p = e; } } // 写入 if (e != null){ // 也就是说已经存在匹配这个key的值 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size > threshold) resize(); afterNodeInsertion(evict); return null; } 4. get函数的实现 bucket里面第一个节点，直接命中 如果有冲突，则通过key.equals(k)去查找对应的entry，如果为树，则在树中通过key.equals(k)查找，O(logn);如果是链表，则在链表中通过key.equals(k)查找，O(n). public V get(Object key){ Node e; return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node getNode(int hash, Object key){ Node[] tab; Node first, e; int n; K k; if ((tab = table) != null && (n = tab.length) > 0 && (first = tab[(n - 1) & hash]) != null){ // 直接命中 if (first.hash == hash && ((k = first.key) == key || (key != null && key.equals(k)))) return first; // 未命中 if ((e = first.next) != null){ // 在树中get if (first instanceof TreeNode) return ((TreeNode)first).getTreeNode(hash, key); // 在链表中get do { if(e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 5. hash函数的实现 在get和put过程中，计算下标时，首先对hashCode进行hash操作获取到hash值，然后通过hash值进一步计算下标。 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); } 计算hash值其实就是：高16bit不变，底16bit和高16bit做了一个异或。在设计hash函数时，因为table长度n为2的幂，而计算下标时，是使用&位操作(按位与操作)，而非%求余。 (n-1) & hash 设计者认为这方法很容易发生碰撞，比如在n-1为15(0x1111)，其实散列真正生效的只是低4bit，因为除了低4bit其它的位都是0，通过按位与操作之后也都是0，所以当然容易碰撞了。 因此，设计者想了一个顾全大局的方法(综合考虑了速度、作用、质量)，就是把高16bit和低16位异或了一下。设计者还解释到因为现在大多数的hashCode的分布已经很不错了，就算发生碰撞也用O(logn)的tree去做了。仅仅异或一下，既减少了系统的开销，也不会造成因为高位没有参与下标的计算(table长度比较小时)而引起的碰撞。 如果还是产生了频繁的碰撞会发生什么问题？设计者注释说，他们使用树来处理频繁的碰撞。 Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class. 回想一下get函数过程： 首先根据key.hashCode()值通过hash()函数获取到hash值，然后利用hash值确定bucket的index； 如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。 在Java 8之前是用链表来解决冲突的，所以产生冲突时，get的时间复杂度就是O(1)+O(n),所以当碰撞很厉害的时候n很大，时间复杂度比较高。 所以在Java 8中，利用红黑树替换了链表，这样使得复杂度变成了O(1)+O(logn),降低了时间复杂度。 6. resize的实现 在put时，如果发现目前的bucket占用程序以及超过了Load Factor所希望的比例，那么就会发生resize，resize的过程就是把bucket扩充为2倍，扩充之后需要重新计算每个节点的index，然后把节点再放到新的bucket中。resize的注释的描述： Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table. 就是说，当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展，所以元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。 resize函数代码实现： final Node[] resize(){ Node[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap > 0){ // 超过最大值就不再扩充，就让它碰撞 if (oldCap >= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap = DEFAULT_INITIAL_CAPACITY) newThr = oldThr 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 计算新的resize上限 if (newThr == 0){ float ft = (float)newCap * loadFactor; newThr = (newCap [] newTab = (Node[])new Node[newCap]; table = newTab; if (oldTab != null){ // 把每个bucket都移动到新的buckets中 for (int j = 0; j e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash & (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNodee).split(this, newTab, j, oldCap); else{ // preserve order Node loHead = null, loTail = null; Node hiHead = null, hiTail = null; Node next; do { next = e.next; // 原索引 if ((e.hash & oldCap) == 0){ if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } // 原索引+oldCap else{ if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } }while((e = next) != null); // 原索引放到bucket里 if (loTail != null){ loTail.next = null; newTab[j] = loHead; } // 原索引+oldCap放到bucket里 if (hiTail != null){ hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 7. 总结 回到开始的几个问题： 1.什么时候会使用HashMap?它有什么特点？ HashMap是基于Map接口实现的，它存储键值对，允许存储null的键值，它是非同步的，HashMap存储着Entry(hash, key, value, next)对象。 2.HashMap的工作原理？ 通过hash的方法，通过put和get存储和获取对象。存储对象时，将K/V传给put方法，它调用hashCode计算hash从而得到bucket位置，HashMap还会根据当前bucket的占用情况自动调整容量。获取对象时，将K传给get,它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。如果发生碰撞，会通过链表的方式将碰撞冲突的元素组织起来，Java 8中，如果碰撞冲突的元素超过某个限制，则用红黑树来替换链表，提高速度。 3.get和put的原理？equals()和hashCode()都有什么作用？ 通过对key的hashCode()进行hashing,并计算下标(n-1 & hash),从而获得buckets的位置。如果产生碰撞，则利用key.equals()方法去链表或树中查找对应的节点。 4.hash怎么实现？为什么这样实现？ Java 8是通过hashCode()的高16bit异或低16bit实现的: ==(h = k.hashCode() ^ (h >>> 16)==,主要是从速度、功效、质量来考虑，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大开销。 5.当HashMap大小超过负载因子定义的容量，怎么办？ 如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap,并且重新调用hash方法。 来自江南白衣： iterator()时是顺着哈希桶数组来遍历的，看起来是个乱序。 本文来自：Java-HashMap工作原理及实现 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2019-11-28 15:48:59 "},"notes/Java 基础/垃圾收集器与内存分配策略.html":{"url":"notes/Java 基础/垃圾收集器与内存分配策略.html","title":"JVM 垃圾收集器与内存分配策略","keywords":"","body":"概述 Java垃圾收集机制是为了避免内存溢出异常而做的努力 垃圾收集(Garbage Collection)需要完成的3件事情： 哪些内存需要回收？ 什么时候回收？ 如何回收？ 目前其实内存的动态分配、内存的回收技术已经相当成熟，那么为什么要了解GC和内存分配呢？因为当排查各种内存溢出、内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，就需要了解GC和内存如何分配。 1. 对象已死吗？ 使用引用计数法(很难判断对象之间相互循环引用的问题) 可达性分析算法(GC Roots为起点，通过引用链 看对象是否可达) 2. 再谈引用 什么是引用？就是某一块区域中的数据是另一块内存的起始地址。JDK1.2之后分为强引用、软引用、弱引用、虚引用。 3. 回收方法区 在方法区中进行垃圾回收一般性价比很低，而在堆中，尤其是在新生代中，进行一次垃圾收集一般可以回收70％~95％的空间，而方法区(永久代)的垃圾收集效率远低于此。 永久代一般收集：废弃常量、无用的类。无用的类： 该类所有的实例都已被回收，即Java堆中不存在该类的任何实例。 加载该类的ClassLoader已被回收。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-06 20:47:50 "},"notes/SUMMARY/Java 并发.html":{"url":"notes/SUMMARY/Java 并发.html","title":"Java 并发","keywords":"","body":"Java 并发的一些知识记录 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-11 11:35:05 "},"notes/Java 并发/负载均衡三种架构.html":{"url":"notes/Java 并发/负载均衡三种架构.html","title":"负载均衡三种架构","keywords":"","body":"1.负载均衡 负载均衡指的是通过一组后端服务器来有效的分发输入进来的网络请求，这里的服务器组其实就是 server pool. 总的来说，load balancer有以下功能： 将客户端的所有请求以及网络负载有效(这里涉及负载策略)的分发到各个服务器那里去。 确保这个 client-server 架构是 high availability and reliability 的，这些客户端发来的请求只会被分发到这些 online 的 server 那里去。 可以根据需求来灵活的增、减任意服务器。 Session Persistence 也就是 session 的持久性问题。一个用户的 session 一般都是直接存储在本地浏览器中，但是如果在分布式架构中，你去改变接收客户端请求的服务器，这个动作其实是会带来 performance issues 和 transaction failure 的。如果要保证性能不受影响、又保证传输成功的话，那就要做到： duration of the session， 来自于同一台客户端的所有请求都应该是被发送给同一台服务器。(load balancer 是可以处理这种问题的) 还有就是上游服务器会在它的缓存中直接存储用户要求的信息，通过这种方式来提高性能。但是如果你换了一台服务器来处理同一个客户端的请求，那么第二次这些用户要求的信息就需要从客户端那里重新 fetched 过来，这就造成了性能的 inefficiencies. 2.高并发负载均衡 -- LVS 模式 整个互联网是建立在下一跳的模式下，IP 是逻辑上的两个端点，MAC 是物理上连接的两个节点。 端点间 TCP 传输过程注意： 确认机制 状态机制 不可分割 解析数据包需要成本： 交换机：二层，只关心 MAC 地址 路由器：三层，只关心 IP 和路由表 LVS 服务器：四层，只关心 PORT,状态 Nginx：七层，关心 socket 对应关系(也就是说这里已经关注了应用层了!)利用负载均衡器的三种通信模型 第一种：source_net 模型 这是源NET，但是从互联网的角度出发，如果外面的机器想访问这个局域网中的某一台机器，如何访问？？？ 因为即便你知道它的公网地址18.18.18.8，你也不知道它的私有地址。。没有公网和私网地址的转换。。你最多访问到这个路由器的地址。。所以还是需要一个地址转换表，把公网转私网。。 第二种：DR 模型 VIP：虚拟服务器地址 DIP：转发的网络地址 和 RIP 通信：ARP 协议，获取 real server 的 RIP：MAC 地址 转发 client 的数据包到 RIP 上(其实是到 real server 内核里面的 VIP) RIP：后端真实主机 CIP：客户端 IP 地址 转成CIP_RIP之后，这时Server RIP才会接收这个包。 注意这里是目标地址转换，也就是D_NAT 然后，服务器端的RIP_PORT要返回数据包给客户端。。规则就是：RIP_PORT:CIP_PORT,但是如果服务器端返回RIP_CIP,这时客户端是会直接把它丢弃的。（其实就是客户端没有请求RIP，别人只是请求的VIP，现在返回一个RIP，这时客户端肯定不要啊。。）原因如下： 所以要规避这个问题，这样做： 不要把RIP_CIP直接返回给客户端，而是先交给负载均衡服务器，负载均衡服务器再恢复成VIP 给CIP返回就行了。。。。 为了把Server RIP服务器返回的所有数据包都给负载均衡服务器，所以需要把Server RIP的默认网关指向lvs 也就是负载均衡服务器。。 DR模型的第二种架构(最常用) 问题：由于客户端发送的请求数据相比服务器端返回的数据是很少的，所以可能5万个请求，只能返回1万个相应给客户端。。。因为服务器端都再次通过负载均衡给客户端传输相应数据太慢了。。。所以产生了以下这种模型。。。能不能直接从服务器端连接一跟光纤到客户端，这时：客户端发送请求还是通过负载均衡服务器发送给服务器端，但是服务器端返回的相应数据直接通过光纤传输，这样返回的数据传输就大大加快了！！！！！ 对于客户端来说，后面的负载均衡服务器和Server RIP都是透明的。。不管这些怎么变化，客户端还是CIP想访问VIP（这样套接字也就是：CIP_PORT:VIP_PORT），。。。。。。然后Server RIP需要返回一个VIP_CIP的数据包（也就是返回一个VIP包给CIP这个客户端。。） 但是！这就说明Server这台机器中必须要有一个VIP： VIP地址不能再在网络当中出现！！我们可以走擦边球，也就是给它持有这个VIP地址，但是别人问他有没有VIP地址时，他会返回没有。。。在真实的网络中真正有VIP的只有负载均衡服务器那里的VIP。 （下面图中我画的VIP_CIP反了，应该是CIP_VIP） 但是！！！！还有一个问题，就是：客户端发送一个CIP_VIP，去访问VIP，那么负载均衡器怎么扔给Server???? 解决办法如下： 在外面套一层MAC地址，也就是RIP-MAC。。。 数据包封的时候，在最外面加上RIP-MAC地址。。要有一个约束：就是负载均衡服务器和真正的server在同一个局域网。。。这里涉及到的叫MAC欺骗。。 最后注意一点：右边的几台真正的server，他们其实长得是一样的，也就是配置、资源位置都是一样的，这样面对几万个资源请求是，负载均衡器只要稍微平均一下分发给不同的server就行了。。 IP 背着 IP 架构(隧道技术) 无论翻墙也好还是VPN也好，都是IP背着IP这种机制。。。 比如你租了一台香港的服务器，因为香港的服务器可以访问国外的IP，所以先从你这里传到香港你租的服务器IP地址(这个过程其实就是隧道。。)，然后你的服务器再看到里层你想去的国外的IP地址。。。就比如这里的DIP_RIP背着CIP_VIP。。把这里的负载均衡器看成你租的香港服务器，那么你先要请求VIP，所以你发送一个CIP_VIP先给这个香港服务器，香港服务器知道你真正想访问的是RIP这个真实的服务器地址，然后就组成包DIP_RIP,其中的数据就是CIP_VIP，然后这个大包到达RIP之后，真正的服务器也就知道你是采用这种IP背着IP的技术传过来的数据包，所以他会把外壳脱去，知道真正发来请求的是CIP。。emm...真他妈难。。。受 然后RIP返回相应数据又有两种方式。。一种是继续通过负载均衡器返回数据，还有一种可以直接把数据给CIP。。。可以通过设置选择不同的方式。 参考文章 Nginx Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-21 16:31:56 "},"notes/Java 并发/网络的层次介绍.html":{"url":"notes/Java 并发/网络的层次介绍.html","title":"网络的层次介绍","keywords":"","body":"网络介绍 netstat -natp;虽然就是两台主机的参与，但是这里有4个TCP连接，说明TCP连接的虚拟性， 并不是真实的两条物理线的连接，就比如这里一台主机里面四个端口就相当于4个虚拟连接了 /etc/sysconfig/network-scripts/ifcfg-eth0\" 查看网卡。。。配置 route -n 互联网的传输方式是基于下一跳的方式，而不是基于路径规划的方式。。。 网络层就是决定下一跳。。 总结： 互联网确实是建立在下一跳的机制之上，不光要IP地址就行了，还需要链路层 利用MAC地址不断下一跳。。。。 三层 这是能够知道IP地址的逻辑地址，怎么知道目的机器的网卡地址呢？？ 本质： 这样可以一个数据包传输，那么网络通信无非就是先TCP三次握手，然后客户端和服务器端发送真正的数据，发发发。。。最后TCP4次分手。。。。这就是网络数据通信。。 ARP协议： 网络传输总结： 比如一个浏览器想请求服务器端Tomcat返回一个页面资源，首先不是从最上层应用层开始的，而是最上层这个请求先阻塞。。。先从第四层TCP层开始发送握手包。。， 1.先TCP-->IP-->数据链路层 （ 这当中有申请端口号的、有做路由表判定的、有网络请求下一跳地址的。。）-->物理层 2.然后服务器端的：物理层-->数据链路层-->IP层-->TCP层，这样来回发送三次数据包传输，也就是TCP三次握手，到此C/S两边的TCP打通了。。然后两边开辟资源之后，然后！才会从最上层的应用层传输真正的数据包依次往下。。。到达服务端的物理层-->.......-->应用层。。。 这样就完成了网络数据传输！！！！！！！！！！！！！！！！！！ 也就是：虽然是7层交互，但是要先4层TCP先建立连接，建立的连接都是IP,port连接，很多这样的IP，port连接，但是这些都是虚拟的连接。。。 目的是知道：你最终知道什么是负载均衡服务器，以及它们的性能开销和弊端。。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-11 11:34:01 "},"notes/SUMMARY/Compute-Network.html":{"url":"notes/SUMMARY/Compute-Network.html","title":"Compute-Network","keywords":"","body":"Compute-Network Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-11 11:34:42 "},"notes/Compute-Network/计算机网络介绍.html":{"url":"notes/Compute-Network/计算机网络介绍.html","title":"计算机网络介绍","keywords":"","body":"计算机网络介绍 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-11 11:30:59 "},"notes/SUMMARY/LeetCode.html":{"url":"notes/SUMMARY/LeetCode.html","title":"LeetCode","keywords":"","body":"LeetCode 的一些有意思的题目记录和刷题的感悟、总结 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-23 22:22:46 "},"notes/LeetCode/1_TwoSum.html":{"url":"notes/LeetCode/1_TwoSum.html","title":"1_TwoSum","keywords":"","body":"题目描述（容易） 输入一个数组和一个 target 值，要求输出数组中的两个和为 target 的数，并且一个元素不能用两次。 方法一：暴力循环 class Solution { public int[] twoSum(int[] nums, int target) { int i = 0,j = 0; //int result[2] = 0; int[] result = new int[2]; for(i = 0;i 通过两层 for 循环遍历所有两个元素的组合。时间复杂度：O(n²)空间复杂度：O(1) 方法二： 对于第二个 for 循环找剩下一个满足要求的数时，方法一用的是遍历剩下的元素，这会产生 O(n) 的时间复杂度，那么怎么才可以避免呢？ 有没有想过用 Map 来做，是不是想起了什么？Map 不同于数组的地方就在于它寻找一个元素是通过一个函数，而不是遍历！把 key 带入这个函数得到的数值就是 value 所在的地址，通过这个地址去找到 value，是不是不要傻傻的循环呢。 我们用 hash table 来做，这里需要先将数组的每个元素保存为 hash 的 key，下标保存为 hash 的 value。这样如果你需要找一个 target - nums[j]，这个 target - nums[j] 就是一个 key 了，那么你就先判断 target - nums[j] 在不在 hash map 里面，如果在就可以找到他的 value，这个 value 也就是 target - nums[j] 在数组中的下标。此时的时间复杂度就是O(1)! 但是要注意，因为同一个元素不能用两次，所以要判断找到的元素应该不是当前元素才行。 class Solution { public int[] twoSum(int[] nums, int target) { Map map = new HashMap<>(); for(int i = 0;i 时间复杂度：用了 hash map，所以少了一个 for 循环，变成 O(n)空间复杂度：由于开辟了一个 hash map，用空间换取了时间，空间复杂度由 O(1) 变成 O(n). 方法三 只需要一次循环 + hash map,就可以遍历所有的两两一对，然后找出最终满足条件的结果。比如一个数组[2,3,5,6,7]，最开始 map 中是空的，然后 map.put(2),2 和空的 map 去配比，然后 map.add(3),3 就和 map 中已经存在的 2 去配比，然后 map.add(5),5 就和 map 中存在的 2，3 去配比......这样你会发现，只用了一个 for 循环，就遍历了所有两两一对。 详细举个例子就是：当你 map.add(5) 的时候，这个 5 肯定先去 和 2，3 配比，也就是说 5 前面的就此遍历了一遍，5 后面的每个元素进来 map 的时候肯定会和 5 来一次配比，那么这个 5 就和前面、后面除了自己的元素进行了配比。 class Solution { public int[] twoSum(int[] nums, int target) { Map map = new HashMap<>(); for(int j = 0;j 时间复杂度：照样依次 for 循环，所以为 O(n).空间复杂度：用了 hash map 存放数组元素，O(n). 总结 学了一招用 hash map 来消弱一层 for 循环，因为 for + for 完 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-22 21:24:24 "},"notes/LeetCode/2_AddTwoNumbers.html":{"url":"notes/LeetCode/2_AddTwoNumbers.html","title":"2_AddTwoNumbers","keywords":"","body":"题目描述（一般） 就是给你两个 ListNode，每个都存了一个非负整数，要你把它们两个加起来然后存到一个（新的或者旧的）ListNode 中，并返回。 这是我的代码 // // * // // * Definition for singly-linked list. // public class ListNode { // int val; // ListNode next; // ListNode(int x) { this.val = x; } // }//每个结点就是这个 ListNode 类的一个对象 class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { //传过来的是两个对象（已经赋好了值） ListNode LC = new ListNode(0); ListNode pa = l1; ListNode pb = l2; ListNode pc = LC;//pc 指向要返回的 ListNode 的最后一个结点 System.out.println(\"pc2222:\"+pc.val); System.out.println(\"pc的next:\"+pc.next); int addnum = 0;//两个数相加的结果，存到 LC 中 int co = 0;//0 表示没有进位，1 表示进位 /* 输出l1,l2 */ // while(pa!=null){ // System.out.println(pa.val); // pa = pa.next; // } while((pa !=null) && (pb != null)){ //pc = ; addnum = pa.val + pb.val + co; //System.out.println(\"1111pa:\"+addnum); if(addnum 第一种解法 public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode dummyHead = new ListNode(0); ListNode p = l1, q = l2, curr = dummyHead; int carry = 0; while (p != null || q != null) { int x = (p != null) ? p.val : 0; int y = (q != null) ? q.val : 0; int sum = carry + x + y; carry = sum / 10; curr.next = new ListNode(sum % 10); curr = curr.next; if (p != null) p = p.next; if (q != null) q = q.next;//加了这两句就知道哪个需要进行下一个 } if (carry > 0) { curr.next = new ListNode(carry); } return dummyHead.next; } 其实思想还是挺简单的，就是 l1 和 l2 两个链表，位对位相加，超过 10 则进位，用 co 来记录进位。其实每一次位的相加看成两个 0-9 的数字相加，如果这一位没有就用 0 来代替。我写的代码其实很多代码是冗余的，所以需要在逻辑上进行优化，去除冗余代码。代码优化：A wonderful solution but for the time consumed, just try replace sum%10 with sum>=10 ? sum-10 : sum will extremely speed up! 过程图： 总结 时间复杂度：O（max(m,n)）空间复杂度：O（max(m,n)），但是新的链表的长度是 O（max(m,n)）+ 1. Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-22 21:24:51 "},"notes/LeetCode/3_LongestSubstringWithoutRepeatingCharacters.html":{"url":"notes/LeetCode/3_LongestSubstringWithoutRepeatingCharacters.html","title":"3_LongestSubstringWithoutRepeatingCharacters","keywords":"","body":"题目描述（一般） 要求无重复的一个最长的字符串的长度 法一（自己写的：数组加循环） class Solution { public int lengthOfLongestSubstring(String s) { //简单的就应该是两层for循环，第一层for循环从1-结束，里层for从i-结束，里层判断收来的字符与已收到的字符是否存在。如果存在，则len-1,负责继续收 //复杂在里层循环可以用hash map代替里层循环 int hi = 0,result = 1,current = 0,mapCount=1; boolean newStart = false; int s_len = s.length(); //char[] max = new char[s_len];将数组转成用hash map来存 Map map = new HashMap(); //max[0] = s.charAt(0); if(s.equals(\"\")){ return 0; } for(int i = 0;i result){ // System.out.println(\"这里：\"); result = mapCount; if(result >= 95){ return 95; } // System.out.println(\"result:\"+result); } mapCount++; }else{//已经有了 //System.out.println(\"有了\"); map = new HashMap(); mapCount = 1; break; } } } // if(isExist(max,s.charAt(j-1)) == false){ // //不存在，将这个字符加在最后，maxlen++ // if(newStart == false){ // max[current] = s.charAt(j-1); // current++; // if(current>result){ // result = current; // } // if(result >= 95){ // return 95; // } // //System.out.println(\"xxx\"); // }else{//重新开始往字符数组加元素 // max[hi] = s.charAt(j-1); // hi++; // if(hi>result){ // result = hi; // } // if(result >= 95){ // return 95; // } // //System.out.println(\"yyy\"); // } // }else{ // //存在，这次找子串到此结束，先清空该字符数组（这里我直接用一个新的），继续下一次 // hi = 0; // max = new char[s_len]; // newStart = true; // //System.out.println(\"zzz\"); // break; // } // } // //max[i] = s.charAt(i); // } //System.out.println(\":\"+max[1]+\":\");//空字符而不是null return result; } // public boolean isExist(char[] max,char ch){ // //System.out.println(\"调用\"); // boolean flag = false; // for(int i = 0;i 这些注释的代码就是自己最开始想到的，前面两层循环，第三层是一个 isExist 函数，同样是一层循环，来判断 max[] 数组中是否存在当前字符。只不过后面换成了用 hashmap。这种是仅仅需要判断里面存不存在的，用 hash map 简直不要太好。 一个看不懂的答案 the basic idea is, keep a hashmap which stores the characters in string as keys and their positions as values, and keep two pointers which define the max substring. move the right pointer to scan through the string , and meanwhile update the hashmap. If the character is already in the hashmap, then move the left pointer to the right of the same character last found. Note that the two pointers can only move forward. public int lengthOfLongestSubstring(String s) { if (s.length()==0) return 0; HashMap map = new HashMap(); int max=0; for (int i=0, j=0; i Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-22 21:25:12 "},"notes/LeetCode/15_3Sum.html":{"url":"notes/LeetCode/15_3Sum.html","title":"15_3Sum","keywords":"","body":"题目描述（一般） ​ 方法一之我写的代码（暴力 for 循环） 由于 3 个元素的组合，所以用三层嵌套 for 循环来遍历所有的三元素组合，但是很遗憾，最后花了 5、6 个小时成功运行，而且理论上可以得出正确结果，但是由于 3 个 for 循环一般时间复杂度达到 O(n^3)基本就凉了，所以必须改进。 class Solution { public List> threeSum(int[] nums) { List> list = new ArrayList<>();//这样声明一个两层的列表 int count=0; int i = 0,j = 0,k = 0,flag=1;//初始化flag=1，表示默认list中没有和myCorrds一样的数组 for(i = 0;i myCoords = new ArrayList(); //myCoords.clear(); myCoords.add(nums[i]); myCoords.add(nums[j]); myCoords.add(nums[k]); System.out.println(\"i:\"+i+\" j:\"+j+\" k:\"+k); System.out.println(count++ +\":\"+nums[i]+\":\"+nums[j]+\":\"+nums[k]); Collections.sort(myCoords, new Comparator() { @Override public int compare(Integer o1, Integer o2) { // 这里是根据当前对象的某一个字段进行排序 if (o1 > o2) { return 1; } else if (o1 == o2) { return 0; } else { return -1; } } }); //Arrays.sort(myCoords); for(int q = 0;q a = new ArrayList(); a = list.get(q);//a 指向list.get(q)这个list同一片空间，a操作了也会使得这篇空间发生变化 // for (int m = 0; m 方法二 用两个标识（lo、hi），来两头遍历，由两个标识在数组中纸箱的数字形成两两对，因为我们一开始就给数组 sort 了，所以这样两头走一遍就可以得到所有情况的两两组合了，判断结束条件是（lo class Solution { public List> threeSum(int[] nums) { Arrays.sort(nums); List> res = new ArrayList<>(); for(int i = 0;i 0 && nums[i] != nums[i-1])){ int lo = i + 1,hi = nums.length -1,sum = 0 - nums[i]; while(lo 时间复杂度：O(n^2),n是指nums.length空间复杂度：O(N) 总结 通过两个指针来从两头遍历，这也依赖了最开始对数组排序了才能用这种方式，两头遍历降低了时间复杂度。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-07-27 17:16:05 "},"notes/LeetCode/回溯、DFS、递归.html":{"url":"notes/LeetCode/回溯、DFS、递归.html","title":"回溯、DFS、递归","keywords":"","body":"回溯、DFS、递归 今天写322题，一看题目想到用回溯法，尽管题目提示用 DP，但是自己在写回溯法的时候脑子里总是感觉和 DFS 有点像，而且回溯和递归是什么关系呢？查看了一下别人写的一些博客，总结一下为了让自己写代码的时候思路更清晰。 回溯和 DFS 都是一种算法思想，而递归则是一种编程的技巧，一般使用递归去实现回溯，但是 DFS 可以用递归去实现，也可以用栈去实现。 我看到别人的博客说 DFS 是一种特殊的回溯，因为回溯可能在任何节点上回溯，这取决于你的回溯条件了，但是 DFS 就是在叶子节点上的回溯。 回溯和 DFS 还有就是：回溯不会保留完整的搜索树结构，而 DFS 则会保留完整的搜索树结构。DFS 有点类似于暴力，而回溯则会进行剪枝、会回头。 下面是我看到的一个比较好的总结： 1. 回溯和 DFS 的相同点： 回溯也是遵循深度优先的，一步步往前，而不是像广度那样往周围。 2. 不同点： （1）访问序 深度优先遍历：目的是遍历，所以本质是“无序”的，也就是访问次序不重要，重要的是都被访问过了，所以在实现上只需要对每个位置记录是否被 visited 就够了。 回溯法：目的是求解过程，本质是有序的，也就是说每一步都必须是要求的次序，所以在实现上不能只是记录是否 visited 就够了，因为同样的内容不同的序访问会造成不同的结果。要使用访问状态来记录，也就是对于每个点记录已经访问过的邻居方向，回溯之后从新的未访问过的方向去访问邻居。至于这点之前有没有被访问过并不重要，重要的是没有以当前的序进行访问。 （2）访问的次数 深度优先遍历：访问过的点不再访问，所有点仅访问一次。 回溯法：已经访问过的点可能再次访问，也可能存在没有访问过的点。 322 题利用 DFS 来做： class Solution { int resultCoin = Integer.MAX_VALUE; public int coinChange(int[] coins, int amount) { // 方法一： // 题意：coins数组是你有的硬币种类，你可以假设每种硬币都有无限个，问你怎么拿硬币 硬币面值和等于amount，要你返回硬币数最少的是几个？如果拼凑不成功就返回-1 // 看上去像找零钱问题 Arrays.sort(coins); // int i = coins.length - 1; // 硬币指针 // 首先你得明白这个回溯函数的作用是什么，它的作用就是返回硬币个数或者-1 // int result = backTracking(coins, amount, i, 0); // return result; for (int i = coins.length - 1; i >=0 ; i--) { DFS(coins, amount, i, 0); } if (resultCoin != Integer.MAX_VALUE) { return resultCoin; } return -1; } // 方法一：应该叫做深度优先搜索 其实也就是回溯法 这里会超时，题解说这种就相当于暴力解法了。。。 public void DFS(int[] coins, int amount, int i, int currCoin) { if (amount == 0) { resultCoin = Math.min(resultCoin, currCoin); return; } for (int j = i; j >= 0; j--) { if (coins[j] 39题 Combination Sum 用回溯来做： class Solution { List> result = null; // 保存满足条件的回溯路线 public List> combinationSum(int[] candidates, int target) { // 用回溯来做，回溯其实就是多叉树的遍历 result = new ArrayList<>(); if (candidates.length == 0) { return result; } // Arrays.sort(candidates); List track = new ArrayList<>(); // 保存当前的回溯路线 int curr = 0; backTrack(candidates, target, track, curr); return result; } public void backTrack(int[] candidates, int target, List track, int curr) { if (target Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-09-18 20:20:17 "},"notes/LeetCode/动态规划（与分治、贪心的区别）.html":{"url":"notes/LeetCode/动态规划（与分治、贪心的区别）.html","title":"动态规划（与分治、贪心的区别）","keywords":"","body":"动态规划（与分治、贪心的区别） 核心： Those who cannot remember the past are condemned to repeat it. 也就是说它的核心在于记录下之前求过的子问题的解。一般动态规划问题开始都是简单的用递归来做，但是简单的用递归做意味着你不会存储计算过程中求得的子问题的解，这样就导致很多小递归是重复计算了的。所以想到用一个空间（也就是一张表或者说一个二维数组）来存储利用递归计算过程中产生的子问题的解，这样当你每次调用递归函数的时候首先去看一下这个二维数组中有没有求过这个子问题，有的话就直接返回结果。 再说一下 DP 适用的场景：1.重叠子问题 2.最优子结构 维基百科上说 DP 在查找很多重叠子问题的情况的最优解时有效。它将问题重新组合成子问题。为了避免多次解决这些子问题，它们的结果都逐渐被计算并保存，从简单的问题直到整个问题都被解决。记住 DP 是一种思想，递归只是一种编程技巧，DP 中用到了递归而已。 动态规划只能适用于有最优子结构的问题，也就是局部最优解能够决定全局最优解。其实就是说大问题可以通过分成小问题来解决。 DP 的两种形式（UpBottom，BottomUp） 一般来说简单递归加上 memorization 技术就变成了自顶向下的 DP，然而相对于自顶向下的动态规划，因为它在递归过程中需要不断的压栈出栈，所以我们会想到用自底向上的动态规划，不断去填充记录结果的二维数组。其实就是逐个将小问题解决，然后在求大问题的时候因为小问题都解决了并且结果已经保存了，所以直接取就行了。这样不需要栈操作，时间消耗更少。 DP 和分治、贪心的区别 参考来源 1.分治 一般步骤都是：分解 --> 解决 --> 合并 2.DP 描述最优解的结构 --> 递归定义最优解的值 --> 按自底向上的方式计算最优解的值 --> 由计算的结果构造一个最优解 分治：子问题独立； DP：子问题独立且重叠 3.贪心 （注意贪心适用的场景，比如下面的 LeetCode322 题就不能用贪心来做） 一般 DP 和贪心都是用来求最优化问题，但是用 DP 就有点杀鸡用牛刀了，简单的用贪心算法就可以。贪心算法是去做选择，它只需要考虑一个选择（也就是基于贪心做出的选择）。 贪心和 DP 相同的是都适用于最优子结构，但是贪心算法中是以自顶向下的方式使用最优子结构，贪心算法会先做选择，在当时看起来是最优的选择，然后再求解一个结果子问题，而不是先求子问题的最优解，然后再做选择。而在动态规划中每一步都要做出选择，这些选择都是依赖于子问题的解，所以动态规划一般都是自底向上来解决，从解决小子问题到解决大子问题。 因此，贪心算法通常是自顶向下地做出贪心选择，不断地将给定的问题实例归约为更小的问题。贪心算法划分子问题的结果，通常是仅存在一个非空的子问题。 动态规划的经典模型（线性模型、区间模型、背包模型） 其实简单点看线性就是用一维数组保存计算结果，区间模型就是用二维数组保存结果咯。但是一维数组也可以看成是只有一行的二维数组，所以维基百科上说在解决动态规划的时候通常用一张表格（也就是一个二维数组）来保存子问题的计算结果。这样看线性模型和区间模型就相通了。 1.线性模型 这里的线性指的是状态的分布是呈线性的，比如 322题 就是一个线性 DP 问题，它的状态转移方程是：F(S) = F(S - C) + 1; // 方法二：用动态规划试试 大问题化解为小问题 这里用的是自顶向下 public int coinChangeHelper(int[] coins, int amount, int[] count) { if (amount = 0 && res = 0} int temp = Integer.MAX_VALUE; for (int coin : coins) { if (i - coin >= 0 && count[i - coin] =0} if (temp != Integer.MAX_VALUE) { count[i] = temp + 1; } } // for循环之后就可以得到一个填充好的count数组，因为初始化count数组的时候我给这个数组都填充的是amount+1，因为硬币至少是一块钱的，所以这就标记了一下，如果count[amount]最后改变了，说明硬币能够换成功 return count[amount] > amount ? -1 : count[amount]; } 再说一个线性模型比较经典的例子： 在一个夜黑风高的晚上，有n（n 1~n 号小朋友，首先 Arrays.sort(T)，也就是 T[1]~T[n] 从小到大排列 这个问题也是用 DP 来做，我们可以将这个问题化简，我们总得送 i 号小朋友过河吧，那么就有两种情况， 1.如果送 n 过河的伙伴送完 n 过河之后立马把手电筒还回去 T1 送 Tn 过河，然后 T1 把手电筒还回去，此时还未过桥的人有 T[1...n-1]，所以花费时间（状态转移方程）： dp[n] = T[n] + T[1] + dp[n-1] 2.如果送 n 过河的伙伴送完 n 过河之后没有立马把手电筒还回去 那总得有人把手电筒送回去吧，那就是第三者，这个第三者此时已经过桥了，而且这个第三者当时过桥的伙伴一定不是 Tn 或者 Tn 的伙伴，但是这个第三者当时不可能一个人过桥，因为得有一个人把手电筒送回过去，所以还存在第四个人，也就是整个过程涉及到四个人。则这种情况下的最佳策略就是： T1（第三者）、T2（第三者当时过河的伙伴）过河，然后 T2 留在那边，T1 回来还手电筒，花费 T1 + T2，然后 Tn 和 Tn-1 一起过河，但是让 T2 拿手电筒回来，此时剩下的人就是 T1~Tn-2，花费时间是：dp[n] = dp[n-2] + 2*T2 + T1 + Tn 这一点还需要仔细考虑：为什么是T0,T1,T{n-2}来陪伴T{n-1}玩这场游戏? 因为如果不是的话，则通过简单替换就可以证明计划不是最优的（算法导论中称之为copy-paste论证） 所以最终递推公式是： 假设 T[0,..,n-1]升序排序，则有 dp(n) = min{dp(n-1), dp(n-2)+2*T1} + T[0]+T[n-1], n>=2, dp(0)=T[0], dp(1)=T1 参考：阿里面试题-小朋友过河 （这里面还有扩展，如果每次允许3个人..4个人..k个人结果又是怎样） 还有另外一个人用堆来做：用堆来做小朋友过河问题 计算的这道题方法其实类似于动态规划，关键在于寻找最优子结构 1）问题的最优子结构是这样推出的 　　1.每一个人都得过河 　　2.由1可以知道cost最大的一个也必须过河 　　3.由2可知必然有一次过河的代价为cost（max） 　　4.由3可知，在将cost最大的人送过河的运输中最优的方案是将cost第二大的人也同时过河 　　因此问题可以转化为如何将cost第一大和第二大的两个人同时送过河 2）最优化问题的解法在于首先将cost最小的两个人先送过河然后选择其一送回手电筒（无论哪个人都一样），然后再使cost最大和第二大的两个人同时过河，再另上一次剩在另一　　岸的cost最小或者次小的人送回手电筒 　　因此每次将一对人送过河的cost=iMax1st+(iMin2nd+2*iMin1st) 3）按总人数的奇数偶数可以将整个问题循环之后分支为两个子问题（显而易见，不多赘述） 4)利用大根堆和小根堆使遍历的时间复杂度从n降低至logn 还有人说：要么是最快者将最慢的两个人送过桥，要么是最快的两个将最慢的两人送过桥 能者多劳 因此可以得出更加细化的解决方案——要么是最快者将最慢的2个送过桥，要么是最快的2个将最慢的2个送过桥。即将过桥的人按其过桥的时间从小到大排列，设为A，B，……Y，Z。其中A和B是最快的二个，Y和Z是最慢的二个。那么就有二种方案： 方案一 最快者将最慢的2个送过桥 第一步：A和Z过桥，花费Z分钟。 第二步：A回来，花费A分钟。 第三步：A和Y过桥，花费Y分钟。 第四步：A回来，花费A分钟。 这四步后总人数就减小2个，花费时间为A + A + Y + Z分钟。 方案二 最快的2个将最慢的2个送过桥 第一步：A和B过桥，花费B分钟。 第二步：A回来，花费A分钟。 第三步：Y和Z过桥，花费Z分钟。 第四步：B回来，花费B分钟。 这四步后总人数同样减小2个，花费时间为A + B + B + Z分钟。 这样，每次比较一下这二种方案就能将总人数减小2。然后我们再考虑一些边界情况： 有三个人过桥设为A，B，C（已经排好序，下同）。应该花费A + B + C分钟。 有二个人过桥设为A，B。那么肯定是花费B分钟。 有一个人过桥设为A。肯定花费A分钟。 所以 只需要比较 (B+B)>?(A+Y) int m=((2B)>(A+Y))?2B:(A+Y) 总时间： B+A+Z+m Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-27 18:26:39 "},"notes/LeetCode/树.html":{"url":"notes/LeetCode/树.html","title":"树","keywords":"","body":"树 在做二叉树题目的时候，如果要从根节点出发，问你达到某种最优值，你可以这样考虑：因为是二叉树，所以将大问题划成小问题，也就是 root.left 或者 root.right 都是一棵小的二叉树，这样你要求从 root 开始的这棵二叉树的最优解只需要考虑分别从 root.left 和 root.right 开始这两棵子二叉树的最优解加上 root 的值就是总的最优解了。（这就是天然的递归结构，必然用递归去做最方便） 而且在二叉树中也可能出现子问题重叠情况，可以考虑用 HashMap 来保存子问题的结果。子问题重叠 + 最优化结构 = DP 了。。 LeetCode337题 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public int rob(TreeNode root) { // 题意：小偷盗窃，一棵二叉树，从根节点出发，为了不惊动警方，同一个晚上不能偷相互连接的两个房子，问一晚最多偷得钱有多少？ 其实就是要间隔咯 // 方法一：简单的用递归来做，也就是只考虑最优子结构 // int result = money(root); // return result; // 方法二：但是你会发现在简单的用递归来做中会用到money(root.left.left)、money(root.left.right)、money(root.right.left)、money(root.right.right)、money(root.left)、money(root.right)；而计算后面两个的时候又会重复计算前面四个函数，也就是会产生重复子问题，所以：最优子结构+重复子问题=DP，所以想到用动态规划来做，那么怎么存储这些子问题呢？用hashmap 存储以某个节点为根节点能偷的最多的钱 // HashMap map = new HashMap<>(); // int result = moneyWithDP(root, map); // return result; // 方法三：在方法一中，money函数定义是返回从root开始这棵二叉树能偷到的最多的钱，但是这个问题的本质是某个节点 偷/不偷；所以我们再重新定义一个函数，它会返回一个两个元素的数组，这两个元素的值是：root节点偷的话最多多少钱/root节点不偷的话最多多少钱 int[] res = robOrNot(root); int result = Math.max(res[0], res[1]); return result; } // 这个函数会返回以root为根节点的树 能够偷到的最多钱的数目 public int money(TreeNode root) { if (root == null) { return 0; } // 偷根节点这栋房子 int leftLeft = 0, leftRight = 0, rightLeft = 0, rightRight = 0; if (root.left != null) { leftLeft = money(root.left.left); leftRight = money(root.left.right); } if (root.right != null) { rightLeft = money(root.right.left); rightRight = money(root.right.right); } int res = leftLeft + leftRight + rightLeft + rightRight; // 也就是偷和不偷根节点 这两种那种情况得到的钱更多； int robMoney = Math.max(res + root.val, money(root.left) + money(root.right)); return robMoney; } public int moneyWithDP(TreeNode root, HashMap map) { if (root == null) { return 0; } if (map.containsKey(root)) { return map.get(root); } // 偷根节点这栋房子 int leftLeft = 0, leftRight = 0, rightLeft = 0, rightRight = 0; if (root.left != null) { leftLeft = moneyWithDP(root.left.left, map); leftRight = moneyWithDP(root.left.right, map); } if (root.right != null) { rightLeft = moneyWithDP(root.right.left, map); rightRight = moneyWithDP(root.right.right, map); } int res = leftLeft + leftRight + rightLeft + rightRight; // 也就是偷和不偷根节点 这两种那种情况得到的钱更多； int robMoney = Math.max(res + root.val, moneyWithDP(root.left, map) + moneyWithDP(root.right, map)); map.put(root, robMoney); return robMoney; } public int[] robOrNot(TreeNode root) { int[] res = new int[2]; if (root == null) { return res; } // 首先你得知道root的两个子节点偷或者不偷的情况 int[] left = robOrNot(root.left); int[] right = robOrNot(root.right); // res[0] 存储root被偷的情况下最多的钱；那left和right就不能被偷 res[0] = root.val + left[1] + right[1]; // res[1] 存储root不被偷的情况最多的钱；那left和right就随便（也就是看偷或者不偷哪种情况钱更多） res[1] = Math.max(left[0], left[1]) + Math.max(right[0], right[1]); return res; } } Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-07-26 10:29:10 "},"notes/LeetCode/二分查找.html":{"url":"notes/LeetCode/二分查找.html","title":"二分查找","keywords":"","body":"二分查找 二分查找针对的是一个区间，必须对这个区间有一个充分的认识，在查找过程中区间会不断被二分（类似于区间的左右边界在变化，至于是左区间还是右区间变化那要根据 target 的值，反正区间不断变小的趋势是向着target方向的）。 // 二分查找基本框架 int binarySearch(int[] nums, int target) { int left = 0; int right = nums.length - 1; // 注意点1 while (left nums[mid]) { } else if (target 搜索区间 这里就提出了搜索区间的概念，如果你是 left=0，right=nums.length-1，那你在while循环当中的判断条件就应该是 left right 才能跳出 while 循环，你才能把这个区间里面的每个元素都比较到。 如果你是left=0，right=nums.length，那你while循环的条件就是left 理解了搜索区间的概念之后，对于普通的二分法查找 target 就很清晰了。但是如果让你找 [1,3,4,4,4,5,5] 这个数组中 4 出现的开始和结束索引呢？ 寻找左侧边界的二分搜索 [1,3,4,4,4,5,5] 这个数组中 4 的左侧边界的本质是什么呢？其实就是找这个数组中比 4 小的数有几个，假如有 x 个，那么 x 的取值区间就是 [0, nums.length]。 // 求左侧边界 int left_bound(int[] nums, int target) { int left = 0, right = nums.length - 1; while (left nums[mid]) { left = mid + 1; } else if (target 寻找右侧边界的二分搜索 [1,3,4,4,4,5,5] 这个数组中 4 的右侧边界的本质是什么呢？其实就是找这个数组中比 4 大的数有几个，假如有 x 个，那么 x 的取值区间就是 [0, nums.length]。 // 求右侧边界 int right_bound(int[] nums, int target) { int left = 0, right = nums.length - 1; while (left nums[mid]) { left = mid + 1; } else if (target Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-09-23 15:55:32 "},"notes/SUMMARY/数据结构和算法之美.html":{"url":"notes/SUMMARY/数据结构和算法之美.html","title":"数据结构和算法之美","keywords":"","body":"数据结构和算法之美 在极客时间上学习的数据结构和算法之美的总结放在这里 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-23 22:20:55 "},"notes/数据结构和算法之美/入门篇.html":{"url":"notes/数据结构和算法之美/入门篇.html","title":"入门篇","keywords":"","body":"10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树； 10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。 这里我要再强调一下，即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。 时间复杂度的全称是渐进时间复杂度，表示的是一个算法执行效率与数据规模增长的变化趋势。 最好情况时间复杂度、最坏情况时间复杂度、平均时间复杂度、均摊时间复杂度。 总结：其实在 CPU 眼中去看一段代码就是一行一行去执行，假设每行代码需要花费一个 unit_time，那么这段代码真正的执行时间就是执行所有行（可能某一行要执行很多遍）需要花费的总的 unit_time，但是我们用大 O 表示法来表示这段代码的时间复杂度，一些常量、低阶项就可以直接忽略。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-29 21:50:45 "},"notes/数据结构和算法之美/数组.html":{"url":"notes/数据结构和算法之美/数组.html","title":"数组","keywords":"","body":"数组 数组：是一种线性表数据结构，用一组连续的存储空间来存储一组具有相同类型的数据。 首先看线性表，链表、队列、栈都是线性表结构，线性表上的数据最多只有前后两个方向。和它对立的是非线性表，比如二叉树、堆、图，这里面的数据并不是简单的前后关系。 再看连续的存储空间和相同的数据类型，就是由于这两个特点它才有随机访问这个绝招。但为了保持数据的连续性，导致插入、删除等操作变得很麻烦。 注意：数组是适合查找，但是说它查找的时间复杂度是 O(1) 就不太对了，就算你数组是有序排列，用二分查找也要 O(logn)，正确的说法是：根据数组下标进行随机访问的时间复杂度是 O(1)。 低效的插入和删除 每次插入都需要将插入位置后面的所有数据往后移动，但是假如这个数组只是用来存储一块数据，它们前后直接并没有什么关系，那么我们可以将插入位置的数据放到最后一个位置，再把插入的数据放到插入位置即可。 删除也是这个道理，如果每次删除都去移动，是低效的，但是如果很多次删除连在一起，我们可以在每次删除的时候进行虚假删除，记录下每次删除的数据，在最后集中删除，这样就只需要将所有数据移动一次就行了。JVM 的标记清除垃圾回收算法就是这个原理。 警惕数组的越界访问问题 在 C 语言中，并没有决定当数组越界之后编译器应该怎么做，因为访问数组的本质就是访问一段连续的内存，只要数组通过偏移得到的访问地址是可用的，程序就不会报错。 int main(int argc, char* argv[]){ int i = 0; int arr[3] = {0}; for(; i 其实更为细节的是，应该去了解在函数调用的时候会用到栈，在这里 main 函数会依次往栈中压入 i、arr[2]、arr[1]、arr[0]，由于栈是向下增长的，所以当访问 a[3] 的时候其实访问的是变量 i ，而且 i 变量的地址是属于当前进程的，所以操作系统不会终止进程。这段代码会无限打印 hello world。 但 Java 在数组越界会：java.lang.ArrayIndexOutOfBoundsException。 容器是否能替代数组 比如 ArrayList，它将数组的很多操作封装起来，且支持动态扩容，每次不够时会扩容至 1.5 倍，但是需要注意每次扩容涉及到空间申请、数据迁移，要花费比较多的时间，所以尽量在创建 ArrayList 的时候就指定大小。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-22 23:10:33 "},"notes/数据结构和算法之美/链表.html":{"url":"notes/数据结构和算法之美/链表.html","title":"链表","keywords":"","body":"链表 链表中比较常见的几个问题：除了环的检测，其它几个都比较简单，利用快慢指针就可以做了。 单链表反转 链表中环的检测 两个有序的链表合并 删除链表倒数第 n 个节点 求链表的中间节点 注意点： 警惕指针丢失和内存泄漏 利用哨兵简化难度，比如要对第一个节点或者最后一个节点操作，我们可以增加两个空节点分别在首尾，这样就躲过了原本需要处理的第一个和最后一个节点的特殊情况。 留意边界条件的处理 1.如果链表为空时，会不会报错？ 2.只包含一个节点、或者只包含两个节点，会不会报错？ 3.代码逻辑在处理首尾节点，有没有问题？ Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-14 18:15:34 "},"notes/数据结构和算法之美/队列.html":{"url":"notes/数据结构和算法之美/队列.html","title":"队列","keywords":"","body":"队列 和栈一样，也是一种操作受限的线性表数据结构，先进先出。也有顺序队列和链式队列。队列中有 head，tail，如果你用的是数组来实现队列，那么当 tail = n 时，就应该执行数据搬移操作，将所有数据向前移至数组第一个元素的位置。 循环队列 如果每次当 tail = n 的时候都要去进行数据搬移，那么会影响入队的性能。所以采用循环队列，那么要注意：用数组实现的非循环队列判断队满条件是：tail = n，队空：head = tail。那么判断循环队列队满的条件：(tail + 1)%n = head，队空：head = tail。 注意循环队列最后一个 tail 是不存数据的，如果最后一个 tail 也存了数据，你就无法判断是队满还是队空。 阻塞队列 就是在队列的基础上增加了阻塞操作，在队列为空的时候往队列中取元素会被阻塞，队列满的时候插入元素会被阻塞。所以这和“生产者-消费者”模型很像，所以你也可以通过协调生产者和消费者的数量来提高数据的处理效率。 这里设置了三个线程去 take，所以会涉及到线程安全问题，线程安全的队列称为并发队列，最简单的方法就是在 enqueue() 和 dequeue() 函数上加上锁，但锁粒度过大会导致并发度低。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-21 22:00:43 "},"notes/数据结构和算法之美/栈.html":{"url":"notes/数据结构和算法之美/栈.html","title":"栈","keywords":"","body":"栈 先进后出，从操作上看是一种“操作受限”的数据结构，当然栈可以用数组和链表实现。那么仔细想想为什么不直接用数据或者链表呢，为什么要使用这种操作受到限制的结构呢？其实会发现数据或者链表过多的暴露了操作的接口，而栈只能从栈顶进行入栈或者出栈操作。 每一种数据结构都是有特定的应用场景的。 栈在函数调用中的应用：一个 main 函数调用一个 add 函数，栈中会存储函数调用时的临时变量。当进入一个函数时，这个函数中的每一个临时变量都会以一个栈帧的形式入栈，当被调用函数执行完成后，返回之后，这个函数对应的所有栈帧都会出栈。 栈在表达式求值时的应用：用两个栈，一个操作数栈、一个操作符栈 栈在括号匹配时的应用：左括号入栈，右括号取栈顶元素进行匹配后将栈顶元素出栈 如何用栈实现浏览器的前进和后退功能呢？ 也是用两个栈 X，Y，当不断的点击网页（前进） 比如 a,b,c，那么依次将 a,b,c 入栈 X，当后退的时候从 c 退回 b，那就需要将 c 从栈 X 出栈然后入栈 Y，但是如果你到网页 b 之后点击了一个新的网页 d，那么此时你无法再返回 c 了，所以你需要将栈 Y 清空。 问题1：为什么要用栈来实现函数的调用，可以用别的数据结构吗？ 因为函数调用的执行顺序符合栈的先进后出的特点，比如函数中局部变量的生命周期就是先定义的生命周期长，后定义的短。函数调用也是满足这个特点，只有当该函数内部调用的函数执行结束之后该函数才会结束。 其实并不是一定要用栈来实现函数调用，函数被调用时数据会发生什么变化呢？其实本质就是作用域，只要能够保证每进入一个新的函数都是一个新的作用域就行了。所以这里用栈很方便，每进入一个新函数，分配一段新的栈空间就行了，当这个被调用函数结束之后，恢复到原来的栈顶就行了。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-21 17:17:20 "},"notes/数据结构和算法之美/排序.html":{"url":"notes/数据结构和算法之美/排序.html","title":"排序","keywords":"","body":"排序 排序算法 时间复杂度 是否基于比较 冒泡、插入、选择 O(n*n) 是 快排、归并 O(n*logn) 是 桶、计数、基数 O(n) 否 1. 冒泡、插入、选择（适合小规模数据量排序） 冒泡和选择都是固定的移动次数，也就是原始数据的逆序度。而插入排序移动次数在实际中更少，虽然这三种排序的时间复杂度都是 O(n*n)，但一般选择的循序是：插入>冒泡>选择。这三种都是原地排序，因为空间复杂度都是 O(1)，都没有利用额外的空间。而插入和冒泡是稳定的排序，但是选择排序由于每次都是将未排序的那一部分中最小的那个元素和第一个元素进行交换，改变了原有的顺序，所以选择排序是不稳定的。 2. 快排、归并（适合大规模数据量排序） 归并排序用到分治思想，分治需要用到递归来实现。分治是一种解决问题的处理思想，递归是一种编程技巧。 可以看出，归并排序先是不断的分治，然后利用 merge() 函数对两个子队列进行合并，那么当子队列1和子队列2中出现相同元素的时候，我们会先把子队列1放到新的合并位置上，所以不会影响原先的顺序，是稳定的排序。 归并排序的执行效率与原始数组的有序程度无关，时间复杂度非常稳定，最好、最坏、平均都是 O(nlogn)。看起来非常优秀，因为快排最坏情况下也要 O(n*n)，但是归并排序也有致命缺点，就是它不是原地排序，在 merge 时它需要 O(n) 的空间来合并两个子队列。 快排也用到分治思想，但是它的核心思想是分区： 如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。我们遍历 p 到 r 之间的数据，将小于 pivot 的数据放到左边，大于 pivot 的数据放到右边，pivot 放到中间。这样就将 p 到 r 之间的数据分成了三部分。 问题：有十个小日志文件，每个 300 MB，你有十个接口去访问这个十个文件，每个文件中的日志都按照时间戳从小到大排好了序，你只有 1 G 的内存，让你合并这十个日志文件成一个，如何比较快速的合并？ 线性排序 下面几种排序因为时间复杂度是线性的，所以称为线性排序。它们不是基于比较的排序算法，不涉及元素之间的比较操作。 3. 桶排序 思想也很好理解，就是先划分成很多个桶，每个桶中放的是固定大小区间的数据，然后如果你要对一大批数据进行排序，你就直接把这批数据逐个放到对应区间的桶里面就行了。然后再利用快排分别对每个桶进行排序，这样从第一个桶到最后一个桶依次取出数据就是最终的排序结果了。 桶排序时间复杂度是 O(nlog(n/m))，当桶的个数接近数的个数时，就变成了 O(n)，但这都基于所有数据能够比较均匀的分布在各个桶之内这个假设，如果所有数据都被分到一个桶内，那就退化成 O(nlogn) 了。 比较适用于外存上的，数据量比较大，内存有限的排序。 4. 记数排序 针对数据量远大于数据所在区间的这种情况，是一种特殊的桶排序。比如高考有 50 万考生，但是成绩都是在 0~750 之间，那么可以设置 751 个桶，把相同分数的放到相同的桶里面。 5. 基数排序 比如你要给十万个 11 位的电话号码排序，你用快排也可以，但是是 O(nlogn)，用桶排序或者记数排序肯定不现实了，因为 11 位代表的数字太大了。用基数排序就是从最后一位开始排序，一直到电话号码的第一位，但是这里针对每一位上的排序要用稳定性排序。我们在每一位上排序可以用桶排序，比如这里的电话号码有 11 位，那么就需要进行 11 次桶排序，这样时间复杂度就是 11*O(n)，也就是 O(n)。 但是如果这些电话号码不都是 11 位的呢？你可以给不是 11 位的那些号码在前面补 0，补齐 11 位，因为这样也不会影响比较。 可以仔细想想，基数排序是需要可以分割出独立的“位”来比较的，而且“位”之间有递进的关系，如果 a 数据的高位比 b 数据大，那么剩下的低位就不用比较了。而且每一位上的数据范围不能太大，否则就不能用线性排序了，最终也就达不到 O(n) 的时间复杂度了。 如何实现一个通用的、高性能的排序算法 由于 O(n) 这类线性排序算法只适用于特定数据，所以不太考虑。一般小数据量选择冒泡、选择、插入这种 O(nn) 的排序，但是当数据量大的时候，肯定还是选择 O(nlogn) 的，那么这里又有归并、快排，堆排序，由于归并不是原地排序，需要耗费额外空间，所以一般用的是快排，那么快排也有缺点就是当最坏情况（也就是当所有的数据都跑到一个分区里面了）下会变成 O(n*n)，这是由于分区点选的不合理导致的，当分区点分成的分区之间数据量差不多才是最理想的。 为了让每个分区数据量都比较平均，也就是你要找到一个 pivot，这个 pivot 越接近中位数越好，那么我们一般可以用： 1.三数取中法（多数取中法） 从首、尾、中间取到三个点，取这三个数的中间值作为 pivot。 2.随机法 也就是从这些数据中随机去一个数作为 pivot，这样也比你每次都取第一个或者最后一个数作为 pivot 遇到最坏情况的可能性要小。 C 语言中的 qsort() 函数 这个函数会优先使用归并排序，因为当数据量少的时候排序更稳定。但数据量大的时候会转而使用快排，而且 qsort() 函数在快排中也是用三数取中法来确定 pivot 的。并且当数据量很小很小时，它会转而使用插入排序，因为小数据量的时候 O(n*n) 并不一定比 O(nlogn) 的算法执行时间长。 而且为了防止堆栈溢出，qsort 实现了一个堆上的栈，手动模拟递归。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-22 23:10:28 "},"notes/SUMMARY/Linux.html":{"url":"notes/SUMMARY/Linux.html","title":"Linux","keywords":"","body":"Linux 知识放在这里 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-20 17:03:09 "},"notes/Linux/Linux 目录介绍.html":{"url":"notes/Linux/Linux 目录介绍.html","title":"Linux 目录介绍","keywords":"","body":"Linux 目录介绍 详细查看了一下买的阿里云服务器上装的 Linux 系统（CentOS 7.6 x64）的目录，记录一下各个目录下一般放什么东西。 1.文件系统层次标准：FHS 2.Linux directory structure explained FHS 定义了 Linux 或者 UNIX-like 的文件系统结构，但是 Linux 系统中还包含了一些至今未被这个标准定义的目录。 / -根目录 Linux 系统所有的文件和目录都在根目录 / 下面，即使这些文件存在于不同的物理或者虚拟盘上。 /bin -基本用户二进制文件 这下面的是单用户模式下安装系统时必须存在的基本用户二进制文件。比如像 Chrome 这样的应用就放在 /usr/bin 目录下，一些重要的系统级程序 比如 bash shell 就放在 /bin 目录。 /boot -静态启动文件 这下面放的是启动系统时需要的文件，比如 GRUB boot loader's files 和 Linux kernels 就在这里。但是 boot loader's configuration files 不放在这里，它们放在 /etc 目录下。 /dev -驱动文件 我们都知道 Linux 系统的思想是“万物皆文件”，在 Linux 系统下，一些外部设备也以文件的形式展示出来，/dev 目录下就放的是这些文件。 /etc -配置文件 它这里说 The /etc directory contains configuration files, which can generally be edited by hand in a text editor，我猜想 etc 会不会是 edited configuration 的缩写:) 注意 /etc 放的是 system-wide configuration files，用户级别的配置文件放在每个用户的 home 目录下。 /home 这个目录下给每一个用户都分了一个 home 文件夹，文件夹的名字就是你的 username，注意 root 用户的 home 目录并不在 /home 下，而是 /root。比如 Linux 系统下有个 bob 用户，那么就有 /home/bob 文件夹，里面放的是 bob 的 user's data files 和 user-specific configuration files。每一个用户只有对他自己的 home 目录 write 的权限。root 用户才有对所有用户的 home 目录 write 的权限。 /lib - Essential Shared Libraries 上面 /bin 目录里面的一些二进制程序所需要的一些库文件就放在 /lib 目录下，当然了 /usr/bin 目录下的二进制程序需要的库就放在 /usr/lib 下咯。 /lost+found -Recovered Files 每个 Linux 文件系统都有一个 lost+found 目录，当文件系统冲突的时候，那么下一次启动的时候会执行一个文件系统 check。这些不要的文件就会放到 lost+found 目录下，可以从这个目录下去尽可能的恢复数据。 /media -可移动媒介 当你插入一张 CD 的时候，就会自动在 /media 目录下自动生成你这张光盘的文件夹，通过这个文件夹就可以访问这张 CD 里面的数据。 /mnt -临时挂载点 系统管理员用这个目录来挂载临时文件系统，比如你要挂载一个 Windows 分区来执行一些文件恢复的操作，你就可以把它挂载到 /mnt/windows 下。 /opt -Optional Packages 这下面放的是可选软件包的子目录。一些不符合标准文件系统层次结构的专有软件一般用的就是 /opt 目录，比如一些专有程序安装的时候会把它的文件放到 /opt/application 下。 /proc -内核和进程文件 /proc 目录和 /dev 目录相似，它也不包含这些标准的文件，它包含的是代表系统和进程信息的特殊文件。 /root 这里是 root 用户的 home 目录，注意 root 用户的 home 目录并不是 /home/root 哦.. /sbin -System Administration Binaries 它和 /bin 目录相似，它放的也是基本二进制文件，但这里的二进制文件是在 root 用户进行系统管理时用到。 /srv -Service Data 这下面放的是这个系统提供的一些服务的数据，比如用 Apache HTTP server 来跑一个网站的时候，你网站的一些文件就可以放在 /srv 目录下面。 /tmp -Tmporary Files Application 的一些临时文件会放在这下面，系统重新启动或者程序运行当中就可能会把这下面的文件给删除。 /usr -User Binaries & Read-Only Data 这下面当然放的是用户的 application 和 files，和系统级 application，files 相对立。比如 non-essential application 会放在 /usr/bin 目录下而不是 /bin 下，non-essential system administraion binaries 会放在 /usr/sbin 而不是 /sbin 下。每一个程序所需要的库都会放在 /usr/lib 下面。 /usr/local 是本地编译的应用程序安装的目录。这样可以防止它们破坏系统的其余部分。 /var -Variable Data Files /var 目录是 /usr 目录的可写副本，在正常操作中，该目录必须为只读。日志文件和在正常操作期间通常会写入 /usr 的所有其它内容都会写入 /var 目录。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-20 17:03:27 "},"notes/Linux/Linux常用命令汇总.html":{"url":"notes/Linux/Linux常用命令汇总.html","title":"Linux 常用命令汇总","keywords":"","body":"创建、删除目录： $mkdir testDir ## rmdir只能删除空目录 $rmdir testDir $rmdir -r testDir # 会将testDir里面的东西删掉，然后再把testDir这个文件夹删掉 # 显示文件夹中的东西 $ls -al （可以加个路径） 检查文件的内容： # cat, tac, more, less, head, tail 修改文件权限： $chmod 777 test.txt 复制： cp [-ai] 来源文件 目标文件 #如果来源文件有两个以上，目标文件一定得是一个目录;i参数是会询问是否覆盖同名文件，a参数（相当于-dr）是指会把:1.如果文件是链接文件（-d），它相当于会再复制一个快捷方式。2.如果来源文件是个文件夹，它会递归持续复制（-r） cp ~/.bashrc /tmp/bashrc cp ~/.bashrc . #将文件复制到当前目录 cp -r /etc/ /tmp #将etc这个目录下所有内容复制到/tmp目录下面，注意-r复制出来的文件的权限可能会被改变，所有用cp时一般用-a 压缩、解压缩： # zip、unzip zip test.zip test.txt # 讲test.txt压缩成test.zip zip /root/test.zip test.txt unzip test.zip #默认将文件解压到当前目录（就是把这个压缩包里面的东西拿到当前目录） unzip test.zip -d /root/testDir #将压缩包里面的东西放到testDir这个指定的目录中 软链接：相当于给原文件创建了一个快捷方式，如果删除了原文件，对应的链接文件也会消失。 ln -s test.txt test_softlink 硬链接：相当于给原文件取了个别名，两者是同一个文件，删除其中一个，另一个不会消失，但是对其中一个修改，另一个也会随之改变。 ln test.txt test_hardlink 观察文件的类型： $file test 指令文件名的搜索：就是找命令对应文件所在的位置（which是在PATH这个环境变量里面找） $which ls 文件文件名的搜索： ## whereis 只是查找某几个目录下面的，所以比find快 $ whereis -[bmsu] 文件或目录名 ## locate用这个命令去查找的原理是通过数据库，所以查找之前可能需要用updatedb命令来更新一下数据库 $ updatedb $ locate test.txt ## find [PATH] [option] [action]; 注意用find找数据的时候相当的操硬盘，所以一般先使用whereis和locate去找 $find / -name passwd $find / -name *passwd* // *通配符 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-02 14:29:49 "},"notes/SUMMARY/研究生学习任务.html":{"url":"notes/SUMMARY/研究生学习任务.html","title":"研究生学习任务","keywords":"","body":"这里是读研时师姐给的一些学习任务 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-02 14:42:49 "},"notes/研究生学习任务/2020-09-25-学习任务-1.html":{"url":"notes/研究生学习任务/2020-09-25-学习任务-1.html","title":"2020-09-25-学习任务-1","keywords":"","body":"第一次学习任务 1. virtualenv 在 Python 中用于环境隔离，因为由于各个 Python 项目所需要的包的版本不相同，所以把聚焦点放到某一个项目上，为每一个项目单独配置一套环境。 virtualenv 虚拟环境的原理就是：执行 source myenv/bin/activate 以后会把 myenv/bin （也就是你程序要用的解释器）塞到 PATH 前面，让这个复制出来的 Python 解释器最优先被搜索到，所以后面再安装包时， 就会是myenv 了，实现安装路径的隔离。 用命令 source venv/bin/activate 进入一个 virtualenv 环境时，virtualenv 会修改相关环境变量，让命令 python 和 pip 均指向当前的 virtualenv 环境。 2. 关于 Python 中安装的第三方包 python 解释器在哪 --> 推导出包的路径 Python3.7 自带了 pip3 # 创建一个虚拟环境 python3 -m virtualenv titanicEnv 参考来源：Python安装包的问题 3. Kaggle 初步学习（机器学习常规步骤） 1.基本步骤 （1）读数据 （2）选取特征 X，拿到 train_data 中的特征数据 X，y （3）选定模型，拿 X 和 y 去训练 model，然后拿 X_test 去预测，得到 prediction 2.对模型进行评估 （1）mean absoluted error（MAE） 3.欠拟合和过拟合 This is a phenomenon called overfitting, where a model matches the training data almost perfectly, but does poorly in validation and other new data. When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called underfitting. we want the low point of the (red) validation curve in.（就是要MAE值最低的那个点） 4. Titanic 问题 1.data science 需要解决的问题 （1）classifying 分类 （2）correlating 相关联 （3）converting 转换（可能需要将文本转成数值） （4）completing 补全缺失值 （5）correcting 将样本中一些可能错误的值进行更正或者排除这些异常样本。如果某个特征没啥用而且可能扭曲最 终结果，我们可以将这个特征直接抛弃。 （6）creating 可以依据已给的特征创造新的特征 （7）charting 画图来看中间结果 总结：基于数据分析去做出 Assumtions。通过初步的看数据（train_df.info, descripe）来观察，观察之后做一些猜想，然后再通过对数据进行分析（可以作图）来验证猜想，再去决定要不要将某个特征放到 model 中训练。（观察 --> 决定） 2.数据分析 （1）单个分析某个特征和 goal 之间的关系（类似于单一变量法），目的是去验证我们的一些猜想和假设。 （2）可以通过作图发现某些特征和 goal 之间并不存在线性关系。 3.整理数据 （1）Correcting by drop features 丢弃一些特征，这样我们可以处理更少的数据，简化分析。但是不能随便丢弃，要基于 assumption and decisions来决定丢弃。 （2）Creating new feature extracting from existing 某些给的特征可能看上去和 goal 之间没有直接联系，但是通过处理之后，可能找到它们之间的关系，从而创造出一个新的特征。 （3）Converting a categorical feature 对于像性别为 female、male 这样的带有字符串的特征，我们需要将它数字化，也就是转成数值型。 （4）Completing a numerical continuous feature 给的 train 或者 test data 中某些数值型样本可能存在缺失，所以需要对其补全。补全一般有三种方式，比如这里对 Age 补全： 一种简单的方法是在均值和标准差之间生成随机数 还可以通过利用其它特征来猜测缺失值， In our case we note correlation among Age, Gender, and Pclass. Guess Age values using median values for Age across sets of Pclass and Gender feature combinations. So, median Age for Pclass=1 and Gender=0, Pclass=1 and Gender=1, and so on... 结合方法1和方法2。因此，不要根据中位数来猜测年龄值，而是使用平均值和标准差之间的随机数，基于一组Pclass和性别组合 但是注意补全得考虑是否会带入 noise，这里的第一种和第三种方法 will introduce random noise into our models，所以这里采用方法二。 （5）对数值型特征转成某个区间来观察 比如这里通过给 Age 划分成一个个的区间，来观察各年龄段（AgeBand）和 survived 之间的关系。但是在模型中用的是数值，所以还需要将 AgeBand 换成序数型特征。通过转成区间的方法，避免了某些不太正常的样本对模型产生噪音。 （6）Create new feature combining existing features 我们还可以通过将 Parch 和 SlibSp 联合起来创建一个新的特征 FamilySize，这样就可以 drop 掉 Parch 和 SlibSp。在 FamilySize 和 survived 的关系表格可以看到其实它和 survived 没有一个线性关系，所以我们创建了一个 IsAlone 特征，这个特征就和 survived 有线性关系了，所以把其它几个特征直接 drop 掉。 4.模型 要搞清你解决的是哪类问题，是分类问题吗？分类又有二分类、多分类，是监督/无监督学习？是回归问题吗？主要看你的特征和 goal 之间的关系。监督学习 + 分类 + 回归问题，可以用以下模型： Logistic Regression KNN or k-Nearest Neighbors Support Vector Machines Naive Bayes classifier Decision Tree Random Forrest Perceptron Artificial neural network RVM or Relevance Vector Machine 5. 总结 主要通过 Titanic Data Science Solutions 学习，对利用 data science 来解决问题有了一个初步的认识，当然，这个帖子在 Kaggle 中并不是得分最高的，但是这却是一个很好的数据分析、用 data science 解决实际问题的帖子。在对这个帖子进行学习中我还产生了很多疑问，比如：这是一个线性回归问题没错，但是在将字符串特征转换数值型特征中，简单的将 female 转成 1，male 转成 0，或者登船口的转换关系为 {'S': 0, 'C': 1, 'Q': 2}，我还不太明白，对训练之后的模型中特征的对应的系数怎么来的也不清楚。 复现过程：点这里 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-02 14:45:54 "},"notes/SUMMARY/安全.html":{"url":"notes/SUMMARY/安全.html","title":"安全","keywords":"","body":"这里是网络安全知识 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-09 14:22:59 "},"notes/安全/SQL注入.html":{"url":"notes/安全/SQL注入.html","title":"SQL注入","keywords":"","body":"1. MySQL注入知识点 select user(); -- 查看当前MySQL登录用户名 select database(); -- 当前使用MySQL数据库名 select version(); -- MySQL版本 select * from admin limit 2,3; -- 从第二行开始查出三条结果 三种注释：--空格 或 # 或 /**/ /*内联注释*/ /*! SQL语句 */ 只有MySQL可以识别，常用来绕过WAF select * from article where id = id -- 下面这条语句执行到id=-1时会报错，然后执行后面的内联语句；使用注释来进行关键字的包含，所以后面的语句可以被MySQL执行 select * from article where id = -1 /*!union*//*!select*/ 1,2,3,4 空格 可以改成 %20 2. SQL注入分类 根据注入位置数据类型可将SQL注入分为：数字型、字符型 3. GET基于报错的SQL注入 通过在URL中修改对应的ID值，为正常数字、大数字、字符（单引号、双引号、双单引号、括号）、反斜杠来探测URL中是否存在注入点。 ## 假如SQL语句如下 select login_name, password from admin where id = ('ID') LIMIT 0, 1; ## 构造URL如下（那个➕可以注释掉后面的SQL） 192.168.1.106/sql/less-3/?id=1') --+ 4. GET基于报错的SQL注入利用 ## 正常URL请求 http://192.168.1.106/sql/less/?id=1 -- 1.利用order by判断字段数(通过增大order by后面的数字来猜测有几个字段) http://192.168.1.106/sql/less/?id=1' order by 3--+ -- 2.利用union select联合查询，获取表名 首先通过第一步知道有3个字段，那么你就可以通过如下联合查询知道是第几个字段： http://192.168.1.106/sql/less/?id=-1' UNION SELECT 1,2,3--+ http://192.168.1.106/sql/less/?id=-1' UNION SELECT 1,user(),database()--+ 5. 利用SQLmap进行SQL注入漏洞利用 不需要自己组织SQL语句来注入 6. 利用MySQL注入读写文件 读取前提： 利用MySQL读取磁盘上的某个文件的内容： select load_file('/User/liuwentao/Desktop/test.txt') 写文件： 7. Cookie注入 利用' or 1=1 --+注入 自己写比较繁琐，所以利用SQLmap进行注入： 8. 总结 无论什么注入都是需要可以进行输入的，用户可以进行修改，然后输入的值会被传递到服务器，并作为SQL语句执行。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-09 09:23:45 "},"notes/安全/XSS.html":{"url":"notes/安全/XSS.html","title":"XSS","keywords":"","body":"1. 什么是XSS攻击 XSS是指恶意攻击者利用网站没有对用户提交数据进行转义处理或者过滤不足的缺点，进而添加一些代码，嵌入到web页面中去。使别的用户访问都会执行相应的嵌入代码。 2. XSS类型 存储型、DOM型、反射型 3. 造成XSS的原因 过于信任客户端提交的数据。攻击者利用网站对客户端提交数据的信任，在数据中插入一些符号以及JS代码，这些数据会成为应用代码的一部分，也就是说插入的一些攻击代码会被执行。 例子： 比如在论坛中，攻击者在留言的input字段中填写alert(‘foolish!’)并提交留言，这样当其它用户访问论坛时查看留言就会获取到这段攻击代码并在网页执行。 Dom型攻击 http://www.vulnerable.site/welcome.html?name=alert(document.cookie) 受害者的浏览器接收到这个链接，发送HTTP请求到www.vulnerable.site并且接受到上面的HTML页。受害者的浏览器开始解析这个HTML为DOM，DOM包含一个对象叫document，document里面有个URL属性，这个属性里填充着当前页面的URL。当解析器到达javascript代码，它会执行它并且修改你的HTML页面。倘若代码中引用了document.URL，那么，这部分字符串将会在解析时嵌入到HTML中，然后立即解析，同时，javascript代码会找到(alert(…))并且在同一个页面执行它，这就产生了xss的条件。 4. 预防XSS 不相信用户提交的数据，对用户提交的信息进行过滤。 1、将重要的cookie标记为http only, 这样的话Javascript 中的document.cookie语句就不能获取到cookie了。 2、表单数据规定值的类型，例如：年龄应为只能为int、name只能为字母数字组合。。。。 4、对数据进行Html Encode 处理 5、过滤或移除特殊的Html标签， 例如: , , for >, &quot for 6、过滤JavaScript 事件的标签。例如 \"onclick=\", \"onfocus\" 等等。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-08 10:59:29 "},"notes/SUMMARY/其它.html":{"url":"notes/SUMMARY/其它.html","title":"其它","keywords":"","body":"其它 这里放一些比较杂的记录，包括但不限于： 环境安装记录 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-20 16:59:13 "},"notes/其它/springboot 和 Django 项目部署到阿里云.html":{"url":"notes/其它/springboot 和 Django 项目部署到阿里云.html","title":"springboot 和 Django 项目部署到阿里云","keywords":"","body":"springboot 和 Django 项目部署到阿里云 因为我的本科毕业设计是 springboot 工程，但是当中需要用到 OpenCV 来处理图片，由于 Java 版本的 OpenCV 不太方便，所以想到搭建一个 Django 服务，这样就可以利用 Python 来对图片进行预处理。 1. springboot 项目部署 我这里用的是 IDEA，所以利用 maven 可以对 springboot 项目直接打包，由于 springboot 项目当中内置了 Tomcat，所以点击右边的 maven package 打包之后在 target 目录下会产生一个 jar 包。 只要把这个 jar 文件上传到服务器上某个目录下，然后在那个目录下运行以下命令： # 简单运行，关闭连接窗口后程序会退出 java -jar winterliu-0.0.1-SNAPSHOT.jar # 让这个程序在后台挂载 nohup java -jar winterliu-0.0.1-SNAPSHOT.jar & 这个就可以让这个程序一直挂载运行，这个端口号就是运行的端口号。 2. Django 项目部署 因为我这里 Django 项目非常简单，没有涉及到数据库和界面方面的操作，只是简单的接收 JSON 和 发送 JSON 数据的服务，所以只需要把 Django 项目文件夹上传到服务器上就行了。 因为在 pycharm 中可以简单的利用 install 来下载需要的包，这里需要利用 pip 安装这个项目当中需要的一些包。比如这里用到腾讯 OCR ： pip3 install tencentcloud-sdk-python 然后到 Django 项目目录下运行以下命令启动 Django 服务： python3 manage.py runserver # 这也是简单运行 # 挂载通用命令 nohup \"这里是运行的命令\" & 3. 遇到的问题 部署 Django 时我遇到的一些问题： (1) django.core.exceptions.ImproperlyConfigured: SQLite 3.8.3 or later is required (found 3.7.17) (2) python中import cv2遇到的错误及安装方法 (3) CentOS 7 Python3.6环境下安装libSM、libXrender、libXext Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-20 17:44:30 "},"notes/其它/Mac 安装 Ruby 及 Jekyll 并利用 GitHub Pages 搭建博客.html":{"url":"notes/其它/Mac 安装 Ruby 及 Jekyll 并利用 GitHub Pages 搭建博客.html","title":"Mac 安装 Ruby 及 Jekyll 并利用 GitHub Pages 搭建博客","keywords":"","body":"官网链接 1 环境准备 安装原因 由于Mac电脑自带的Ruby版本过低（2.3.x），而安装Jekyll要求Ruby版本>2.4.0 利用Homebrew安装Ruby 首先需要安装Homebrew /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 再安装Ruby brew install ruby 然后导入Ruby的环境变量#注意利用export导入这种方式是临时环境变量，重新开一个终端导入的这个环境变量就不存在了 export PATH=/usr/local/opt/ruby/bin:$PATH 检查Ruby版本 ruby -v 安装Jekyll并导入Jekyll环境变量 gem install --user-install bundler jekyll export PATH=$HOME/.gem/ruby/X.X.0/bin:$PATH #用安装的Ruby版本号的前两位替换 X.X 注意点 Every time you update Ruby to a version with a different first two digits, you will need to update your path to match. 由于利用export导入的环境变量是临时变量，所以虽然电脑已经安装了最新版本的Ruby，但是每次使用Ruby是必须重新利用export导入。 总之重新打开终端之后必须依次执行以下两行才能识别到Ruby和Jekyll export PATH=/usr/local/opt/ruby/bin:$PATH export PATH=$HOME/.gem/ruby/X.X.0/bin:$PATH 2 主题安装与配置 下载主题并配置相关参数 自己选择一个喜欢的主题，我选择的是scribble（在GitHub上可以找到，然后安装它的说明下载、配置） Get started Fork the repository Clone the repository: git clone https://github.com/username/scribble Run bundle install Run Jekyll: bundle exec jekyll serve -w Go to http://localhost:4000 for your site. Make it yours Edit _config.yml, adn then rerun jekyll serve -w Change about.md for blog intro 3 域名配置与发布 和Windows类似，可以参见另一篇文章。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-03-29 09:03:32 "}}