{"./":{"url":"./","title":"Introduction","keywords":"","body":"winterliu-notes 我学习过程中记录的一些笔记 记录原则： 切忌假、大、空 根本目的是为了在记录过程中重新理清思路、记录一些容易遗忘的点、让自己的知识形成体系 记录的时候从方便自己出发，因为这并不是要写一本书，这只是我的一些草稿纸，我现在、以后能看懂就行了 记录内容尽量减少照搬，更不能直接复制粘贴，而应该先对知识进行理解，再去记录 并不是任何不懂的东西都要记录，不懂的东西多了去了，记录一样东西是会产生时间的消耗的，当记录带来的价值小于记录产生的消耗时就没有记录的必要了 记录不是目的，目的是更好的掌握知识，方便现在的自己、以后的自己。切记、切记！ zheli这里是 删除线这里是删除线 输入：[toc]+回车，会产生目录 输入：|姓名|性别|学校| + 回车，产生表格 任务列表：- [ ] 任务1 [x] 任务1 [x] 吃饭 算法 [ ] LeetCode + labuladong算法小抄 (300+题) [ ] 剑指offer [ ] 算法第四版 [ ] 左神算法视频（中级、高级课程） [ ] 程序员代码面试指南 基础:rocket::rocket::rocket::rocket: 计算机网络 操作系统 数据库 Java语言基础 Java并发 JVM Linux 设计模式 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-03 23:12:48 "},"1-Java 基础/HashMap在1.7和1.8中的线程不安全问题.html":{"url":"1-Java 基础/HashMap在1.7和1.8中的线程不安全问题.html","title":"HashMap在1.7和1.8中的线程不安全问题","keywords":"","body":"来源：csdn 1.7中： 由于在扩容时采用的前插法，所以可能造成死循环或者数据丢失。（下面的3和7就死循环了，5就被丢失了）；而且在多个线程同时put(key, value)的时候还会有数据被覆盖的问题。 Java中所有的变量存放在主存中，而线程使用变量时会把主内存里面的变量复制到自己的工作内存中，线程读写变量时操作的是自己工作变量中的内存，然后将自己工作内存中的变量刷新到主内存中。因此，当线程A和线程B同时处理一个共享变量时，会存在内存不可见的问题。 其实主要还是因为Java内存模型的问题，每个线程都有自己的本地内存，然后所有线程每次更新值需要更新到主内存，当多个线程用同一个hashmap时，如果多个线程同时put一个值，好巧，此时这些线程拿到的hashmap的size都到了阙值，所以各个线程都需要对hashmap进行扩容，又由于没有加锁，且CPU分片的原因，当一个线程执行了一部分步骤时，这个线程的CPU时间片用完了（注意A线程用完了CPU时间片后会变成就绪状态，但是它执行一部分步骤产生的数据变化还在本地内存），另外一个线程开始执行一个完整的扩容操作，也就是从主内存加载数据，然后在B线程本地内存进行扩容 最后更新到主内存。 然后A线程拿到CPU时间片恢复执行，后面就会发生死循环问题。具体看：csdn和csdn 1.8中： 扩容时将前插改成了尾插，避免了上面的死循环和数据丢失问题。但是数据被覆盖问题仍然存在，1.8的源码没有transfer函数，因为JDK1.8直接在resize函数中完成了数据迁移，1.8中put函数： final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node[] tab; Node p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) & hash]) == null) // 如果没有hash碰撞则直接插入元素 tab[i] = newNode(hash, key, value, null); else { Node e; K k; if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size > threshold) resize(); afterNodeInsertion(evict); return null; } 第六行判断是否出现hash碰撞（也就是看桶节点是否已经有值），假设线程A,B都put，然后A，B线程中hash函数计算出来的插入下标都是一样的，当A执行完第六行代码后CPU时间片用完了（此时A只是定位到插入位置并且发现该位置是空的，还没有进行插入值），转为就绪状态，然后B拿到时间片完成了正常的插入，然后A重新拿到CPU时间片进行第七步插入，这样导致B插入的数据被A的数据覆盖了。 除此之前，还有就是代码的第38行处有个++size，我们这样想，还是线程A、B，这两个线程同时进行put操作时，假设当前HashMap的zise大小为10，当线程A执行到第38行代码时，从主内存中获得size的值为10后准备进行+1操作，但是由于时间片耗尽只好让出CPU，线程B快乐的拿到CPU还是从主内存中拿到size的值10进行+1操作，完成了put操作并将size=11写回主内存，然后线程A再次拿到CPU并继续执行(此时size的值仍为10)，当执行完put操作后，还是将size=11写回内存，此时，线程A、B都执行了一次put操作，但是size的值只增加了1，所有说还是由于数据覆盖又导致了线程不安全。从这里也可以看出：重新拿到CPU时间片后不会重新从主内存加载新数据，用的还是自己线程中的本地内存，其实想想也是，如果会有这种比较操作，其实是用了其它机制（CAS和volatile关键字）。 hashmap为什么容量总是2的N次方？ 其实就是将取模操作换成用位操作，但是效果一样，性能更好。 作者推算出了如果容量为2的N次方的话，那么hash&(length-1) == hash%length; length转为二进制位一个1+N个0，length-1转为二进制位一个0+N个1；则任意的hash值和length-1做位运算，结构都是后面N个位的的二进制，因为length-1的二进制前面都是0，位运算后都是0，相当于舍弃了高位，保留了后面的N位，后面的N位刚好在0-length之间，也就是等于hash%length取余 length是2的N次方，那么你去hash%length，值都散列在[0, length - 1]上； 同样，如果hash&(length-1)，length-1除了最高位是0，后面全是1，也就是：一个hash值去&(length-1)它能表示的最大值用十进制来说其实就是(length-1)，所以散列范围还是：[0, length - 1]。 hashmap1.8中为什么选择6，8两个阙值 当每个桶上节点小于6时会退化成链表，当超过8时会将链表转成红黑树。 理想状态，受随机分布的hashCode影响，链表中节点遵循柏松分布，所以一般情况下，很少很少会出现一个桶上节点数超过8的情况，超过8如果还用链表的话，性能很差，会转成红黑树，但是转成红黑树的操作需要消耗性能，并且树节点占用的空间是普通节点的两倍。 正常情况下，都是用的链表，因为当节点过多时会进行扩容。 参考：csdn Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-22 21:48:51 "},"1-Java 基础/Java中HashMap并发环境下造成死循环.html":{"url":"1-Java 基础/Java中HashMap并发环境下造成死循环.html","title":"Java中HashMap并发环境下造成死循环","keywords":"","body":"参考链接1 参考链接2 主要是由于多线程下扩容，造成链表死循环。扩容源码： /** * Transfers all entries from current table to newTable. */ void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry e : table) { while(null != e) { //（关键代码） Entry next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } // while } } 参考这篇文章 其实主要是：当线程1（假设线程1中节点的连接顺序是：2-->3）中：e指向数组中的某个节点（假如是2节点），然后next指向该数组节点连接的链表的头节点（假如是3节点） 然后这时突然切换到线程2：线程2会执行一整套的扩容，那么在线程2执行完之后，内存空间中节点的连接顺序就变成了（3-->2）因为在1.7中扩容函数resize()调用的transfer函数转移到新数组，采用的是前插法，（千万注意：线程1和2会在各自的内存空间开创各自的新的newTable[]，但是注意hashmap的节点是线程共用的，所以线程2执行完之后节点变成3-->2，然后线程1获得CPU继续执行，此时在线程1中：e指向2，next指向3，然后执行前叉2节点，变成2-->3, 但是现在next是3，最后3的next会指向2，由此形成环） Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-01-23 12:21:40 "},"1-Java 基础/Java中HashMap底层原理.html":{"url":"1-Java 基础/Java中HashMap底层原理.html","title":"Java中HashMap底层原理","keywords":"","body":"1. 首先看几个问题 什么时候会使用HashMap?它有什么特点？ HashMap的工作原理是什么？ HashMap中put和get的原理，equals()和hashCode()函数都有什么作用？ hash如何实现？为什么要这样实现？ 当HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？ 当执行下面的操作时： HashMap map = new HashMap(); map.put(\"语文\",1); map.put(\"数学\",2); map.put(\"英语\",3); map.put(\"历史\",4); map.put(\"政治\",5); map.put(\"地理\",6); map.put(\"生物\",7); map.put(\"化学\",8); for(Entry entry : map.entrySet()){ System.out.println(entry.getKet() + \":\" + entry.getValue()); } 执行结果： 政治: 5生物: 7历史: 4数学: 2化学: 8语文: 1英语: 3地理: 6 为什么不是按照循序打印出来呢？看下面这张图来对HashMap结构有一个感性认识： 你可以看到这些entry在内存中既不是连续的、也不是按照put的循序排列的。 官方文档描述HashMap: Hash table based implementation of the Map interface . This implementation provides all of the optional map operations, and permits null values and the null key. (The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.) This class ++makes no guarantees as to the order of the map++; in particular, it does ++not guarantee that the order will remain constant over time++. 注意点：基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的循序)、不保证序列不随时间变化。 2. 两个重要参数 HashMap中需要注意两个重要的参数是：容量(Capacity)和负载因子(Load factor) Initial capacity The capacity is the number of buckets in the hash table, The initial capacity is simply the capacity at the time the hash table is created. Load factor The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased. Capacity其实就是buckets的数目，Load factor就是buckets填满程度的最大比例。当HashMap中元素的个数大于capacity*load factor时就需要调整buckets的数目为当前的2倍。 3. put函数的实现 put函数的大致思路是： 利用hashCode()函数得到key的hash值，然后再计算这个hash值的index； 如果没有碰撞就直接放在bucket中； 如果碰撞了就以链表的形式放在buckets的后面 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD),就把链表转换成红黑树； 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket满了，就resize. 具体代码如下： public V put(K key, V value){ // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict){ Node[] tab; Node p; int n, i; // tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 计算index，并对null做处理 if ((p = tab[i = (n -1) & hash]) == null) tab[i] = newNode(hash, key, value, null); else{ Node e; K k; // 节点存在 if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k)))) e = p; // 该链为树 else if (p instanceof TreeNode) e = ((TreeNode)p).putTreeVal(this, tab, hash, key, value); // 该链为链表 else { for (int binCount = 0; ; ++binCount){ if ((e = p.next) == null){ p.next = newNode(hash, key, value, null); if(binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 当链表长度超过了一定值时将链表转成红黑树 break; } if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) break; // 说明节点已存在 p = e; } } // 写入 if (e != null){ // 也就是说已经存在匹配这个key的值 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size > threshold) resize(); afterNodeInsertion(evict); return null; } 4. get函数的实现 bucket里面第一个节点，直接命中 如果有冲突，则通过key.equals(k)去查找对应的entry，如果为树，则在树中通过key.equals(k)查找，O(logn);如果是链表，则在链表中通过key.equals(k)查找，O(n). public V get(Object key){ Node e; return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node getNode(int hash, Object key){ Node[] tab; Node first, e; int n; K k; if ((tab = table) != null && (n = tab.length) > 0 && (first = tab[(n - 1) & hash]) != null){ // 直接命中 if (first.hash == hash && ((k = first.key) == key || (key != null && key.equals(k)))) return first; // 未命中 if ((e = first.next) != null){ // 在树中get if (first instanceof TreeNode) return ((TreeNode)first).getTreeNode(hash, key); // 在链表中get do { if(e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 5. hash函数的实现 在get和put过程中，计算下标时，首先对hashCode进行hash操作获取到hash值，然后通过hash值进一步计算下标。 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); } 计算hash值其实就是：高16bit不变，底16bit和高16bit做了一个异或。在设计hash函数时，因为table长度n为2的幂，而计算下标时，是使用&位操作(按位与操作)，而非%求余。 (n-1) & hash 设计者认为这方法很容易发生碰撞，比如在n-1为15(0x1111)，其实散列真正生效的只是低4bit，因为除了低4bit其它的位都是0，通过按位与操作之后也都是0，所以当然容易碰撞了。 因此，设计者想了一个顾全大局的方法(综合考虑了速度、作用、质量)，就是把高16bit和低16位异或了一下。设计者还解释到因为现在大多数的hashCode的分布已经很不错了，就算发生碰撞也用O(logn)的tree去做了。仅仅异或一下，既减少了系统的开销，也不会造成因为高位没有参与下标的计算(table长度比较小时)而引起的碰撞。 如果还是产生了频繁的碰撞会发生什么问题？设计者注释说，他们使用树来处理频繁的碰撞。 Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class. 回想一下get函数过程： 首先根据key.hashCode()值通过hash()函数获取到hash值，然后利用hash值确定bucket的index； 如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。 在Java 8之前是用链表来解决冲突的，所以产生冲突时，get的时间复杂度就是O(1)+O(n),所以当碰撞很厉害的时候n很大，时间复杂度比较高。 所以在Java 8中，利用红黑树替换了链表，这样使得复杂度变成了O(1)+O(logn),降低了时间复杂度。 6. resize的实现 在put时，如果发现目前的bucket占用程序以及超过了Load Factor所希望的比例，那么就会发生resize，resize的过程就是把bucket扩充为2倍，扩充之后需要重新计算每个节点的index，然后把节点再放到新的bucket中。resize的注释的描述： Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table. 就是说，当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展，所以元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。 resize函数代码实现： final Node[] resize(){ Node[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap > 0){ // 超过最大值就不再扩充，就让它碰撞 if (oldCap >= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap = DEFAULT_INITIAL_CAPACITY) newThr = oldThr 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 计算新的resize上限 if (newThr == 0){ float ft = (float)newCap * loadFactor; newThr = (newCap [] newTab = (Node[])new Node[newCap]; table = newTab; if (oldTab != null){ // 把每个bucket都移动到新的buckets中 for (int j = 0; j e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash & (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNodee).split(this, newTab, j, oldCap); else{ // preserve order Node loHead = null, loTail = null; Node hiHead = null, hiTail = null; Node next; do { next = e.next; // 原索引 if ((e.hash & oldCap) == 0){ if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } // 原索引+oldCap else{ if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } }while((e = next) != null); // 原索引放到bucket里 if (loTail != null){ loTail.next = null; newTab[j] = loHead; } // 原索引+oldCap放到bucket里 if (hiTail != null){ hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 7. 总结 回到开始的几个问题： 1.什么时候会使用HashMap?它有什么特点？ HashMap是基于Map接口实现的，它存储键值对，允许存储null的键值，它是非同步的，HashMap存储着Entry(hash, key, value, next)对象。 2.HashMap的工作原理？ 通过hash的方法，通过put和get存储和获取对象。存储对象时，将K/V传给put方法，它调用hashCode计算hash从而得到bucket位置，HashMap还会根据当前bucket的占用情况自动调整容量。获取对象时，将K传给get,它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。如果发生碰撞，会通过链表的方式将碰撞冲突的元素组织起来，Java 8中，如果碰撞冲突的元素超过某个限制，则用红黑树来替换链表，提高速度。 3.get和put的原理？equals()和hashCode()都有什么作用？ 通过对key的hashCode()进行hashing,并计算下标(n-1 & hash),从而获得buckets的位置。如果产生碰撞，则利用key.equals()方法去链表或树中查找对应的节点。 4.hash怎么实现？为什么这样实现？ Java 8是通过hashCode()的高16bit异或低16bit实现的: ==(h = k.hashCode() ^ (h >>> 16)==,主要是从速度、功效、质量来考虑，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大开销。 5.当HashMap大小超过负载因子定义的容量，怎么办？ 如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap,并且重新调用hash方法。 来自江南白衣： iterator()时是顺着哈希桶数组来遍历的，看起来是个乱序。 本文来自：Java-HashMap工作原理及实现 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-22 21:49:59 "},"1-Java 基础/Java中序列化问题和transient关键字.html":{"url":"1-Java 基础/Java中序列化问题和transient关键字.html","title":"Java中序列化问题和Transient关键字","keywords":"","body":"昨天看hashmap中putval函数看到transient关键字，然后发现transient关键字和Java中的序列化（Serilizable接口）有关系。 关于序列化和transient Java中一个类实现了Serilizable接口，那么这个类的所有对象的属性和方法都可以被自动序列化，我们可以不用关注序列化内部过程。 但是有时候我们会遇到这样的需求：某个类的有些属性需要序列化、其它的属性不需要被序列化（比如一些密码等敏感信息），我们不希望这些敏感信息在网络操作（主要涉及序列化操作，本地序列化缓存也适用）中被传输。那么这种变量就可以加transient关键字。 所以transient关键字就是可以让变量不会被序列化，也就是不会被持久化到磁盘中，让某个字段的生命周期仅存在于调用者的内存中。 比如： read before Serializable: username: Alexia password: 123456 read after Serializable: username: Alexia password: null 将User对象序列化之后写入到文件中，但是password属性加了transient关键字，那么它就不能被序列化，所以再次从文件中读取对象进行反序列化后，对应的password就是null。（password只在内存中存在，不能写入到文件） transient使用小结 1.变量被transient修饰，该变量不能被序列化，不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。 2.transient只能修饰成员变量，不能修饰方法和类。也不能修饰本地变量（就是方法中的形参和方法体中声明的参数）。 3.静态变量（也就是类变量，加了static的）不管是否被transient修饰，均不能被序列化。反序列化后类中static型变量username的值为当前JVM中对应static变量的值，这个值是JVM中的不是反序列化得出的。 所以从上面三点来看，能够序列化的变量一般是指new出一个对象，这个对象所拥有的那些属性。 HashMap中如何使用transient关键字？ 首先看一下hashmap中存在的问题，然后再看如何用transient关键字来解决这个问题。 hashmap存储键值对，它的存储其实是依赖于hashcode()方法的，但是当我们把一个hashmap进行序列化/反序列化的时候，我们本身是不会保存计算出来的hashcode值的，而计算hashcode值调用的hashcode()方法是Native方法，也就是说它和底层实现相关，不同虚拟机可能有不同的HashCode算法，比如同一个key值在虚拟机A上的hashcode值为1，在虚拟机B上的hashcode值为2，在虚拟机C上的hashcode值为3，这样就失去了Java的跨平台性。 总结：其实就是利用不同虚拟机计算的HashCode值不同，如果采用Java自带的序列化，反序列化方法（ObjectInputStream, ObjectOutputStream），那么在两台不同的虚拟机上虽然hashmap里面的entry的内存分布一模一样，但是就是这个一模一样带来了问题，因为到新的机器上，比如key=\"abc\"，然后计算得到的是一个新的hashcode值，那么通过这个hashcode值去get对应的value肯定不是一样的啊。所以 所以HashMap类重写了序列化，反序列化（hashmap类中反序列化其实是重新hash，用字节流中的key, value数据重构一个新的hashmap，就是将所有key, value键值对一个一个执行putValue方法放到新的hashmap中，这样你通过key=“abc\"去get值，肯定可以拿到对应的值了 ）的方法，也就是writeObject, readObject。 HashMap仍然可以像通常那样处理非transient字段，但是它们一个接一个地在字节数组的末尾写入存储的键值对。在反序列化时，它会通过默认的反序列化过程处理非transient变量，然后逐个读取键值对。对于每个键，哈希和索引再次计算并插入到表中的正确位置，以便可以再次检索它而不会出现任何错误。 为什么hashmap要重写序列化和反序列化方法： 下文是摘自《Effective Java》： For example, consider the case of a hash table. The physical representation is a sequence of hash buckets containing key-value entries. The bucket that an entry resides in is a function of the hash code of its key, which is not, in general, guaranteed to be the same from JVM implementation to JVM implementation. In fact, it isn’t even guaranteed to be the same from run to run. Therefore, accepting the default serialized form for a hash table would constitute a serious bug. Serializing and deserializing the hash table could yield an object whose invariants were seriously corrupt. writeObject: readObject: 参考： 图解HashMap Java transient关键字使用示例 以下是effective Java第二版十一章关于序列化的内容 对象序列化API，提供了一个框架，用来将对象编码成字节流（序列化），并从字节流编码中重新构建对象（反序列化）。 一旦对象被序列化之后，它的编码就可以从一台正在运行的虚拟机被传递到另一台虚拟机上，或者被存储到磁盘上，供以后反序列化时用。 序列化技术为远程通信提供了标准的线路级对象表示法，也为JavaBeans组件结构提供了标准的持久化数据格式。 关于该不该实现序列化接口 序列化接口提供了一些好处：如果一个类将要加入到某个框架中，并且该框架依赖于序列化来实现对象传输或者持久化,那对于这个类来说，实现Serializable接口就很有必要。 虽然只要在某个类的声明中加入“implements Serializable”就可以让这个类的实例被序列化（加了这个只是说明这个类可以序列化，序列化和反序列化真正用的是Java自带的ObjectOutputStream.putFields和ObjectInputStream.readFields方法，或者你也可以自己写writeObject, readObject方法来序列化，反序列化，像HashMap一样），但是实现这个接口付出的最大的代价是，一旦一个类被发布，就大大降低了“改变这个类的实现”的灵活性。 这里其实就像项目当中使用到Entity层，因为每一个Entity类的属性都会与数据库中的字段对应，但是一旦项目发布，你就不能随便改（增加或者删除，修改）Entity层中的属性了（其实序列化的作用之一就是容易持久化到数据库），灵活性降低。 关于序列版本ID 序列化会使类的演变受到限制，也就是每一个实现序列化接口的类会有一个唯一的与这个类对应的序列版本UID（其实有点像文件的md5码），如果你没有在一个名为serialVersionUID的私有静态final的long域中显式的指定该标识号，系统会自动根据（该类的名称、所实现接口的名称、所有的公有的和受到保护的成员的名称）并调用复杂运算来在运行时产生该标识号。 UID其实就是一个号码，对应某个类的状态，当该类发生变化那么通过计算产生的UID也会变化，所以如果你没有声明一个显式的序列版本UID，兼容性将会遭到破坏，在运行时导致InvalidClassException异常。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-03-31 18:01:07 "},"1-Java 基础/Java中的反射.html":{"url":"1-Java 基础/Java中的反射.html","title":"Java中的反射","keywords":"","body":"Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-06-09 17:47:49 "},"1-Java 基础/Java中的泛型.html":{"url":"1-Java 基础/Java中的泛型.html","title":"Java中的泛型","keywords":"","body":"为什么要有泛型？ Java编程思想中说有很多原因，但是一个重要原因是为了创建容器类。C++中的模板就是泛型的思想，模板的精神：参数化类型。 泛型的本质就是参数化类型，也就是将原来具体的类型参数化。泛型的出现避免了强转操作，可以在编译器中完成类型的转化，避免运行时强制类型转换而出现ClassCastException类型转换异常。注意Java泛型也是一种语法糖，在JDK1.5时增加了泛型，很大程度上方便在集合上的使用。 泛型的使用 三种使用方式：泛型类、泛型方法、泛型接口。 1.泛型类：把泛型定义在类上 // 注意泛型类型必须是引用类型 public class 类名 { } 2.泛型方法：把泛型定义在方法上 public 返回类型 方法名 (泛型类型 变量名) { } class Demo{ public T fun(T t){ // 可以接收任意类型的数据 return t ; // 直接把参数返回 } } // 注意：当调用fun()方法时，根据传入的实际对象，编译器就会判断出类型形参T所代表的实际类型，所以在上面的fun函数中会根据传来的t这个形参的类型返回不同的数据类型。 public class GenericsDemo26{ public static void main(String args[]){ Demo d = new Demo() ; // 实例化Demo对象 String str = d.fun(\"汤姆\") ; // 传递字符串 int i = d.fun(30) ; // 传递数字，自动装箱 System.out.println(str) ; // 输出内容 System.out.println(i) ; // 输出内容 } } 3.泛型接口：把泛型定义在接口 public interface 接口名 { } // 泛型接口 public interface Inter { public abstract void show(T t); } // 子类是泛型类 public class InterImpl implements Inter { @Override public void show(E t) { System.out.println(t); } } // 注意：这里左边可以用接口，但是右边new肯定是实例类了，比如常用List list = new LinkedList(); 这里的List其实就是一个接口 Inter inter = new InterImpl(); inter.show(\"hello\"); 源码中泛型的使用： //定义接口时指定了一个类型形参，该形参名为E public interface List extends Collection { //在该接口里，E可以作为类型使用 public E get(int index) {} public void add(E e) {} } //定义类时指定了一个类型形参，该形参名为E public class ArrayList extends AbstractList implements List { //在该类里，E可以作为类型使用 public void set(E e) { ....................... } } 泛型类派生子类 父类派生子类的时候不能再包含类型形参，需要传入具体的类型 错误：public class A extends Container {} 正确：public class A extends Container {} 也可以不指定具体的类型，这样系统就会把K, V形参当成Object类型处理：public class A extends Container {} 泛型构造器、高级通配符 。。。 泛型擦除 指编译器编译带类型说明的集合时会去掉类型信息。 public class GenericTest { public static void main(String[] args) { new GenericTest().testType(); } public void testType(){ ArrayList collection1 = new ArrayList(); ArrayList collection2= new ArrayList(); System.out.println(collection1.getClass()==collection2.getClass()); //两者class类型一样,即字节码一致 System.out.println(collection2.getClass().getName()); //class均为java.util.ArrayList,并无实际类型参数信息 } } // 输出 true java.util.ArrayList 分析：1.这是因为不管为泛型的类型形参传入哪一种类型实参，对于Java来说，它们依然被当成同一类处理，在内存中也只占用一块内存空间。从Java泛型的这一概念提出的目的来看，其只是作用于代码编译阶段，在编译过程中，对于正确检验泛型结果后，会将泛型的相关信息擦出，也就是说，成功编译过后的class文件中是不包含任何泛型信息的。泛型信息不会进入到运行时阶段。 2.在静态方法、静态初始化块或者静态变量的声明和初始化中不允许使用类型形参。由于系统中并不会真正的生成泛型类，所以instanceof运算符后不能使用泛型类。 泛型就是定义一种模板，例如ArrayList,然后在代码中为用到的类创建对应的ArrayList; ArrayList strList = new ArrayList(); 泛型实现了编写一次，万能匹配，通过编译器保证了类型安全。 泛型的向上转型 ArrayList实现了List接口，它可以向上转型为List; 但是要注意：不能把ArrayList向上转型为ArrayList或者List。 ArrayList和ArrayList两者完全没有继承关系。 总结 1.泛型就是编写模板代码来适应任意类型； 2.泛型的好处是使用时不必对类型进行强制转换，它通过编译器对类型进行检查； 3.注意泛型的继承关系：可以把ArrayList向上转型为List(T不能变！)，但是不能转成ArrayList。 学习来源： 廖雪峰 掘金 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-11-25 09:15:28 "},"1-Java 基础/Java内存模型.html":{"url":"1-Java 基础/Java内存模型.html","title":"Java内存模型","keywords":"","body":"Java内存模型定义了统一的内存模型，用于屏蔽不同的硬件架构，它定义了在多线程环境中线程对共享内存中值的修改是否对其它线程立即可见。 操作系统有自己的内存模型，c, c++是直接使用操作系统的内存模型，但是Java为了屏蔽各系统差异，定义了统一的内存模型，Java中不再关心每个CPU核心有自己的内存，然后共享主内存，而是把关注点转移到：每个线程都有自己的工作内存，所有线程共享主内存。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-21 16:13:44 "},"1-Java 基础/Java基本数据类型及其封装类.html":{"url":"1-Java 基础/Java基本数据类型及其封装类.html","title":"Java基本数据类型及其封装类","keywords":"","body":"Java.lang(language) package Provides classes that are fundamental to the design of the Java programming language. The most important classes are Object, which is the root of the class hierarchy, and Class, instances of which represent classes at run time. 里面有最重要的类Object类。还包含了基本数据类型的包装类。Math类、Void类、String类、StringBuilder、StringBuffer类。还有类加载（Classes ClassLoader类）、进程类（Process）、ProcessBuilder类、Runtime类、SecurityManager类、还有 System provide \"system operations\"（比如System类）... Void和void void是一个关键字，Void是一种类型。可以看到Void类型不可以继承与实例化。Void如果作为函数的返回结果则该函数只能返回null。泛型出现之前，Void一般用于反射之中。Void也用于无值的Map中，例如Map这样map将和Set有一样的功能。 public final class Void { /** * The {@code Class} object representing the pseudo-type corresponding to * the keyword {@code void}. */ @SuppressWarnings(\"unchecked\") public static final Class TYPE = (Class) Class.getPrimitiveClass(\"void\"); /* * The Void class cannot be instantiated. */ private Void() {} } 八种基本数据类型 1.整型（byte short int long）；字节数（1，2，4，8） 2.浮点型（单精度float，双精度double）；字节数（4， 8） 3.逻辑性（boolean）（This data type represents one bit of information, but its \"size\" isn't something that's precisely defined.） 4.字符型（char）；字节数（1） 八种基本类型的包装类和常量池 其中Byte,Short,Integer,Long,Character,Boolean这五种包装类（注意包装类都加了final，不可被继承）默认创建了数值范围在[-128, 127]的缓存数据，在这个范围之外的才会创建新的对象。注意浮点型float和double的包装类没有实现常量池技术。具体实现比如IntegerCache:可以看到这里的high是可以配置的，创建的缓存对象会放在cache[]数组中。 private static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k = 127; } private IntegerCache() {} } Number类 它是java.lang下面的一个抽象类，提供了将包装类型拆箱成基本类型的方法，八个包装类都继承了Number这个抽象类。 package java.lang; public abstract class Number implements java.io.Serializable { public abstract int intValue(); public abstract long longValue(); public abstract float floatValue(); public abstract double doubleValue(); public byte byteValue() { return (byte)intValue(); } public short shortValue() { return (short)intValue(); } private static final long serialVersionUID = -8742448824652078965L; } 怎么看源码：一个类中，一般最上面是static静态方法，也就是这个类的方法（通过类名.方法直接调用），然后是声明一些变量（属性），然后是构造方法，接下来是一些普通方法（包括重写的方法）。 在Float.java中发现了： public int compareTo(Float anotherFloat) { return Float.compare(value, anotherFloat.value); } public static int compare(float f1, float f2) { if (f1 f2) return 1; // Neither val is NaN, thisVal is larger // Cannot use floatToRawIntBits because of possibility of NaNs. int thisBits = Float.floatToIntBits(f1); int anotherBits = Float.floatToIntBits(f2); return (thisBits == anotherBits ? 0 : // Values are equal (thisBits Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-01-23 12:17:17 "},"1-Java 基础/Java容器.html":{"url":"1-Java 基础/Java容器.html","title":"Java容器","keywords":"","body":" 1. Map.Entry是Map声明的一个内部接口，这个接口是泛型接口，定义为Entry。它表示Map中的一个实体（也就是一个key-value对)。 Java1.8中HashMap：可以看到1.8中里面的节点叫做Node，这个Node是一个内部类，它实现了Map.Entry这个接口。因为1.8开始，当发生哈希冲突时，新放进来的节点会放到Node[] tab这个数组的节点下面的链表上，如果链表长度过长，则会转化成红黑树。（这里的 Node 是一个泛型类）。 java发射机制中，class是什么意思？ Class cla;与Class cl; 前一个表示cla只能指向Integer这种类型，而后一个cl表示可以指向任意类型。 cla = Integer.class 可以，但cla = Double.class就不可以。 但是cl = Integer.class 可以，cl = Double.class也可以 、 ?是通配符。 最好再去了解下泛型的概念，对这个理解起来比较好 1、我们往HashMap中put值的时候，值其实是存在Node里面的。key和value分别会赋值到Node的key和value中。 2、Node中还有一个字段叫 final int hash；存取这个Node的hash值。这个hash值是最终找数据的关键。 由以上可知，Node对象才是HashMap的核心，存取了数据以及数据的唯一编号hash。 /** * Basic hash bin node, used for most entries. (See below for * TreeNode subclass, and in LinkedHashMap for its Entry subclass.) */ static class Node implements Map.Entry { final int hash; final K key; V value; Node next; Node(int hash, K key, V value, Node next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \"=\" + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry e = (Map.Entry)o; if (Objects.equals(key, e.getKey()) && Objects.equals(value, e.getValue())) return true; } return false; } } 2. 一些总结 对于最上面那张容器类图，第一层是Iterator, Collection, Map三个接口，接口就是一种规范，它更加抽象，抽象类抽象程度次之，普通类抽象程度最低。也就是这三个接口最为Java容器中最抽象的东西，其实就是最顶层的规范，接口当中一般是一些方法的声明，变量（属性）按照接口的设计原则来说不应该放到接口当中的。 然后第二层是（List, Set, Queue还是三个接口） AbstractList, AbstractSet, AbstractMap, SortedMap这几个抽象类，在抽象类中已经把第一层对应的接口中定义的方法实现了（不单单是声明了），然后再到第三层的HashSet, ArrayList, HashMap, LinkedHashMap, TreeMap这几个普通的类，把具体的某几个特有的方法分别实现了，也就是抽象程度没有那么高了。 注意： HashMap, TreeMap, LinkedHashMap这三个类和HashSet, TreeSet, LinkedHashSet这三个类在一些操作方法、性能是完全一样的。HashSet是HashMap的一种特殊情况，把key-value去掉value就成了Set，本质上是同一种数据结构。 使用抽象容器类可以方便的定义类，而不用在每个类中都实现容器接口container 中的所有的方法。 Queue queue = new LinkedList<>(); queue.peek(); // 这里其实调用的是LinkedList类中的peek()方法 为什么用LinkedList来实现Queue? Java中Queue是一个接口，Queue这个接口继承至Collection接口，LinkedList采用双向链表，本身就有addFirst, getFirst, getLast等功能的需求，而队列Queue是只是特定功能的LinkedList（也就是说Queue按照功能来说其实是LinkedList的一个子集，所以没必要多写一个类），如下图可以看到从Java1.5开始其实LinkedList中已经为Queue operation提供了对应的方法了。 LinkedList其实是实现了Deque（Double End Queue 双端队列）这个接口中的方法，而Deque这个接口继承了Queue这个接口，其实就是：Queue是单端的add, remove, peek, offer等操作，而Deque就是双端，addFirst, addLast, removeFirst... 3.HashMap和LinkedHashMap Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-20 15:06:16 "},"1-Java 基础/Java对象.html":{"url":"1-Java 基础/Java对象.html","title":"Java对象","keywords":"","body":"Java对象在内存中的布局分为三块区域：对象头、实例数据、对齐填充。 Synchronized用的锁就是存在Java对象头里的，hotspot虚拟机的对象头主要包括两部分数据：Mark Word（标记字段）、Class Pointer（类型指针），Class Pointer是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。Mark Word用于存储对象自身的运行时数据，它是实现轻量级锁和偏向锁的关键。 对象头中的Mark word与线程中Lock Record 线程进入同步代码块的时候，如果此同步对象没有被锁定，即这个同步对象的锁标志位是01，则虚拟机首先会在当前线程的栈中创建我们称之为“锁记录Lock record”的空间，用于存储锁对象的Mark word的拷贝。 Lock record是线程私有数据结构，每一个线程都有一个可用Lock record列表，每一个被锁住的对象的Mark word都会与一个Lock record关联（对象头的Mark Word中的Lock Word指向Lock Record的起始地址），同时Lock Record中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占有。 监视器（monitor） 任何一个对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。synchronized在JVM里的实现都是基于进入和退出monitor对象来实现方法的同步和代码块的同步，都可以通过成对的MonitorEnter和MonitorExit指令来实现。 MonitorEnter指令：插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor的所有权，即尝试获得该对象的锁； MonitorExit指令：插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit； 那什么是Monitor？可以把它理解为 一个同步工具，也可以描述为 一种同步机制，它通常被 描述为一个对象。 与一切皆对象一样，所有的Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。 也就是通常说Synchronized的对象锁，MarkWord锁标识位为10，其中指针指向的是Monitor对象的起始地址。在Java虚拟机（HotSpot）中，Monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的）： ObjectMonitor() { _header = NULL; _count = 0; // 记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; // 处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; // 处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; } Monitor对象存在于每个Java对象的对象头Mark Word中（存储的指针的指向），Synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时notify/notifyAll/wait等方法会使用到Monitor锁对象，所以必须在同步代码块中使用。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-03-26 17:28:29 "},"1-Java 基础/Java数组底层实现原理.html":{"url":"1-Java 基础/Java数组底层实现原理.html","title":"Java数组底层实现原理","keywords":"","body":"数组 参考Java语言规范。Java中数组是动态创建的对象，数组对象可以赋值给Object类型的变量，Object类的所有方法都可以在数组上调用。 数组对象包含大量的变量。数组元素类型自身可以是数组类型。 有些情况下，数组的成员可以是数组：如果成员类型是Object、Cloneable或java.io.Serializable，那么全部或部分成员可以是数组，因为任何数组对象都可以赋值给这些类型的变量。 数组类型 数组的长度不是数组类型的一部分。 数组的元素类型可以是任何类型，可以是简单类型、引用类型，特别的： 以接口类型作为元素类型的数组是允许的 （这种数组的元素的值可以是空引用，也可以是实现该接口的任意类型的实例） 以abstract类类型作为数组的元素类型也是可以的（这种数组的元素可以是空引用，也可以是自身不是abstract的该abstract类的任意子类的实例） 数组类型的超类型关系与超类关系不同。Integer[]的直接超类型是Number[]，但是根据Integer[]的Class对象，Integer[]的直接超类是Object。因为Object是所有数组类型的超类型。 一旦数组对象被创建，它的长度就永远不能改变。 数组类型的单个变量可以包含对不同长度的数组的引用，因为数组的长度不是其类型的一部分。 Animal[] animal = new Animal[]; Dog[] dog = new Dog[]; // 如果Dog类可以赋值给Animal类（也就是Dog类是Animal类的子类），那么animal可以持有对任意数组类型为B[]的实例的引用。这可能会在随后的赋值中导致运行时异常。 // 也就是这里的animal可以持有dog animal = dog; 数组创建 数组是由数组创建表达式int[] a = new int[3]或数组初始化器int[] a = {1, 2, 3}创建的。 数组初始化器 数组初始化器可以在域声明或局部变量声明中指定。（也就是可以在方法外面或者方法里面，但是用数组创建表达式int[] a = new int[3]则必须在方法里面。 数组初始化器是用逗号分隔的表达式列表，用花括号括起来。 数组成员 数组类型的成员包括： public final 域 length，它包含了数组的元素数量。 public 方法clone，它覆盖了Object类中同名的方法，并且不会抛出任何受检异常。数组类型T[]的clone方法的返回值是T[]。多维数组的克隆是浅复制，即它只创建单个新数组，里面的子数组是共享的。 所有从Object类继承而来的成员，Object中唯一没有被继承的方法就是clone方法。 数组的Class对象 每个数组都与一个Class对象关联，并与其他具有相同元素类型的数组共享该对象。尽管数组类型不是类，但是每一个数组的Class对象起到的作用看起来都像是： 每个数组类型的直接超类都是Object 每个数组类型都实现了Cloneable接口和java.io.Serializable接口 深入分析数组对象 数组的是 Object 的直接子类,它属于“第一类对象”，但是它又与普通的 Java 对象存在很大的不同，从它的类名就可以看出：[I，这是什么东东？？在 JDK 中我就没有找到这个类，话说这个”[I”都不是一个合法标识符。怎么定义成类啊？所以我认为 sun 那帮天才肯定对数组的底层肯定做了特殊的处理。 public class Test { public static void main(String[] args) { int[] array_00 = new int[10]; System.out.println(\"一维数组：\" + array_00.getClass().getName()); int[][] array_01 = new int[10][10]; System.out.println(\"二维数组：\" + array_01.getClass().getName()); int[][][] array_02 = new int[10][10][10]; System.out.println(\"三维数组：\" + array_02.getClass().getName()); } } -----------------Output: 一维数组：[I 二维数组：[[I 三维数组：[[[I 通过这个实例我们知道：[代表了数组的维度，一个[表示一维，两个[表示二维。可以简单的说数组的类名由若干个’[‘和数组元素类型的内部名称组成。不清楚我们再看: public class Test { public static void main(String[] args) { System.out.println(\"Object[]:\" + Object [].class); System.out.println(\"Object[][]:\" + Object[][].class); System.err.println(\"Object[][][]:\" + Object[] [][].class); System.out.println(\"Object:\" + Object.class); } } ---------Output: Object[]:class [Ljava.lang.Object; Object[][]:class [[Ljava.lang.Object; Object[][][]:class [[[Ljava.lang.Object; Object:class java.lang.Object 从这个实例我们可以看出数组的“庐山真面目”。同时也可以看出数组和普通的 Java 类是不同的，普通的 Java 类是以全限定路径名 + 类名来作为自己的唯一标示的，而数组则是以若干个 [+L+ 数组元素类全限定路径+类来最为唯一标示的。这个不同也许在某种程度上说明了数组也普通 Java 类在实现上存在很大的区别，也许可以利用这个区别来使得 JVM 在处理数组和普通 Java 类时作出区分。 我们暂且不论这个[I 是什么东东，是由谁来声明的，怎么声明的（这些我现在也不知道！但是有一点可以确认：这个是在运行时确定的）。先看如下 public class Test { public static void main(String[] args) { int[] array = new int[10]; Class clazz = array.getClass(); System.out.println(clazz.getDeclaredFields ().length); System.out.println(clazz.getDeclaredMethods ().length); System.out.println(clazz.getDeclaredConstructors().length); System.out.println(clazz.getDeclaredAnnotations().length); System.out.println(clazz.getDeclaredClasses().length); } } ----------------Output： 0 0 0 0 0 从这个运行结果可以看出，我们亲爱的 [I 没有生命任何成员变量、成员方法、构造函数、Annotation 甚至连 length 成员变量这个都没有，它就是一个彻彻底底的空类。没有声明 length，那么我们 array.length 时，编译器怎么不会报错呢？确实，数组的 length 是一个非常特殊的成员变量。我们知道数组的是 Object 的直接之类，但是 Object 是没有 length 这个成员变量的，那么 length 应该是数组的成员变量，但是从上面的示例中，我们发现数组根本就没有任何成员变量，这两者不是相互矛盾么？ public class Main { public static void main(String[] args) { int a[] = new int[2]; int i = a.length; } } 打开class文件，可以看到main方法的字节码： 0 iconst_2 //将int型常量2压入操作数栈 1 newarray 10 (int) //将2弹出操作数栈，作为长度，创建一个元素类型为int, 维度为1的数组，并将数组的引用压入操作数栈 3 astore_1 //将数组的引用从操作数栈中弹出，保存在索引为1的局部变量(即a)中 4 aload_1 //将索引为1的局部变量(即a)压入操作数栈 5 arraylength //从操作数栈弹出数组引用(即a)，并获取其长度(JVM负责实现如何获取)，并将长度压入操作数栈 6 istore_2 //将数组长度从操作数栈弹出，保存在索引为2的局部变量(即i)中 7 return //main方法返回 在这个字节码中我们还是没有看到 length 这个成员变量，但是看到了这个:arraylength ,这条指令是用来获取数组的长度的，所以说 JVM 对数组的长度做了特殊的处理，它是通过 arraylength 这条指令来实现的。 其实就是说你在Java代码中用到了arr.length，那么到字节码中会翻译成执行arraylength这条指令，由JVM去执行这条指令来获取数组长度。（所以说到底还是没有声明length这个属性） 参考来源： Java语言规范 极客学院 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-11-25 09:36:07 "},"1-Java 基础/Java特性-封装继承多态.html":{"url":"1-Java 基础/Java特性-封装继承多态.html","title":"Java特性 封装继承多态","keywords":"","body":"1.接口interface：参考来源 在interface里面的变量都是public static final 的。所以你可以这样写： public static final int i=10; 或则 int i=10；（可以省略掉一部分） 注意在声明的时候要给变量赋予初值 解释： 首先你要弄清接口的含义.接口就是提供一种统一的’协议’,而接口中的属性也属于’协议’中的成员.它们是公共的,静态的,最终的常量.相当于全局常量. 抽象类是不’完全’的类,相当于是接口和具体类的一个中间层.即满足接口的抽象,也满足具体的实现. 如果接口可以定义变量，但是接口中的方法又都是抽象的，在接口中无法通过行为来修改属性。有的人会说了，没有关系，可以通过实现接口的对象的行为来修改接口中的属性。这当然没有问题，但是考虑这样的情况。如果接口A中有一个public访问权限的静态变量a。按照java的语义，我们可以不通过实现接口的对象来访问变量a，通过A.a = xxx;就可以改变接口中的变量a的值了。正如抽象类中是可以这样做的，那么实现接口A的所有对象也都会自动拥有这一改变后的a的值了，也就是说一个地方改变了a，所有这些对象中a的值也都跟着变了。这和抽象类有什么区别呢，怎么体现接口更高的抽象级别呢，怎么体现接口提供的统一的协议呢，那还要接口这种抽象来做什么呢？所以接口中不能出现变量，如果有变量，就和接口提供的统一的抽象这种思想是抵触的。所以接口中的属性必然是常量，只能读不能改，这样才能为实现接口的对象提供一个统一的属性。 通俗的讲，你认为是要变化的东西，就放在你自己的实现中，不能放在接口中去，接口只是对一类事物的属性和行为更高层次的抽象。对修改关闭，对扩展（不同的实现implements）开放，接口是对开闭原则的一种体现。 2.接口放在另一个接口（或者类）中 由于嵌套接口不能直接访问，使用它们的主要目的是通过将相关接口（或相关接口和类）分组在一起来解析命名空间。This way, we can only call the nested interface by using outer class or outer interface name followed by dot( . ), followed by the interface name.所以，你要访问一个接口中的接口，只能通过 外部接口.内部接口 的方式，比如Map.Entry; // 接口放在接口中 interface MyInterfaceA{ void display(); interface MyInterfaceB{ void myMethod(); } } class NestedInterfaceDemo1 implements MyInterfaceA.MyInterfaceB{ public void myMethod(){ System.out.println(\"Nested interface method\"); } public static void main(String args[]){ MyInterfaceA.MyInterfaceB obj= new NestedInterfaceDemo1(); obj.myMethod(); } } // class MyClass{ interface MyInterfaceB{ void myMethod(); } } class NestedInterfaceDemo2 implements MyClass.MyInterfaceB{ public void myMethod(){ System.out.println(\"Nested interface method\"); } public static void main(String args[]){ MyClass.MyInterfaceB obj= new NestedInterfaceDemo2(); obj.myMethod(); } } 3.接口可以继承接口吗，抽象类可以继承接口吗，抽象类可以继承实体类吗？ 1、接口可以继承接口，抽象类不可以继承接口，但可以实现接口。 2、抽象类可以继承实体类。抽象类可以实现(implements)接口，抽象类可以继承实体类，但前提是实体类必须有明确的构造函数。 3、抽象类可以继承实体类，就是因为抽象类可以有继承性和有方法。 4、一个接口可以继承多个接口. interface C extends A, B {}是可以的. 一个类可以实现多个接口: class D implements A,B,C{} 但是一个类只能继承一个类,不能继承多个类 class B extends A{} 在继承类的同时,也可以继承接口: class E extends D implements A,B,C{} 这也正是选择用接口而不是抽象类的原因。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-03-31 18:00:52 "},"1-Java 基础/Java虚拟机内存区域.html":{"url":"1-Java 基础/Java虚拟机内存区域.html","title":"Java虚拟机内存区域","keywords":"","body":"前言 Java虚拟机在执行Java程序的过程中会把它管理的内存区域划分成若干个不同的数据区域。有的区域属于所有线程共享的(这些区域随着虚拟机进程的启动而存在)、有些区域属于线程隔离的(这些区域则依赖于用户线程的启动和结束)。划分成以下区域： 1. 程序计数器 程序计数器是一个很小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个程序计数器来完成。 每条线程都需要一个独立的程序计数器，各个线程之间程序计数器互不影响，独立存储，程序计数器这片小内存叫做“线程私有”的内存。 如果线程正在执行的是一个Java方法，那么这个程序计数器记录的就是正在执行的虚拟机字节码指令的地址。 2. Java虚拟机栈 这片区域也是线程私有的，它的生命周期和线程相同。虚拟机栈描述的是Java方法执行的内存模型(也就是说虚拟机栈是对于Java方法而言，而方法区则存储的是一些Class基本信息，即针对的是类)，每个方法执行时都会创建一个栈帧用于存储局部变量、操作数栈、动态链表、方法出口等信息，每一个方法从调用到执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 Java虚拟机栈中包含了局部变量表，而局部变量表中存的是：编译器可知的基本数据类型、对象引用类型和returnAddress类型。 局部变量表所需的内存空间在编译期间就可以完成分配，当进入一个方法时，这个方法需要多少局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 3. 本地方法栈 本地方法栈和虚拟机栈所发挥的作用非常相似，虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则为虚拟机使用到的Native方法服务。 4.Java堆 Java堆是Java虚拟机管理的最大的一片内存区域。被所有线程共享，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象。所有的对象实例和数组都要在堆上分配。 Java堆是垃圾收集器的主要区域。 5. 方法区 方法区也是各个线程共享的区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码。 6.运行时常量池 它是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 以下探究HotSpot虚拟机在Java堆中对象分配、布局和访问的过程： 1. 对象的创建(例如克隆、反序列化) 从语言层面，创建对象仅仅是一个new关键字而已，而从Java虚拟机来看，创建一个对象(这里仅仅指普通对象，不包括数组和Class对象)的过程如下： 虚拟机遇到一条new指令时，首先去检查这个指令的参数能否在常量池中定位到一个类的符号引用，并检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，则必须先执行相应类的加载过程。 类加载检查通过后，然后虚拟机将为新生对象分配内存。对象所需要的内存大小在类加载完后便可以完全确定。为对象分配内存其实就是将一块确定大小的内存从Java堆中划分出来。 根据Java堆是否规整，在分配内存时是会采用不同的策略的，一般采用：指针碰撞(Bump the Pointer)、空闲列表(Free List)。而Java堆是否规整又是由所采用的垃圾收集器是否带有压缩整理功能决定的。 需要注意的是，由于Java对象的创建是非常常见的，比如仅仅是修改一个指针所指向的位置，在并发情况下也可能存在线程安全问题，可能出现正在给对象A分配内存，内存已经在Java堆中划分出来了，但是还没来得及将指针指向这块内存，另一个线程中的对象B又同时使用了原来这个指针来分配内存。以上这个过程是存在问题的，解决办法有两种，一是对分配内存的动作进行同步处理，保证这个操作的原子性。另一种是把内存分配的动作按照线程划分在不同的空间中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲(TLAB)，那个线程需要分配内存，就在哪个线程的TLAB上分配，只有当TLAB使用完了并分配新的TLAB时，才需要同步锁定。 内存分配完成后，虚拟机会将分配到的内存空间都初始化为零值(不包括对象头)。然后虚拟机要对对象进行一些设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息，这些信息存放在对象的对象头中。 到此，从虚拟机的视角，一个对象已经产生了，但是从Java程序的视角来看，对象的创建才刚开始(才仅仅分配了内存、初始化了一些类数据)，方法还没有执行，对象中所有的字段都还为零。执行new指令之后会接着执行方法，把对象按照程序员的意向进行初始化，这样一个真正可用的对象才算真正产生出来。 2. 对象的内存布局 对象在内存中的布局可以分为3块区域：对象头(Head)、实例数据(Instance Data)、对齐填充(Padding)。 对象头，用于存储对象自身的运行时数据，如哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳。对象头的另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据部分是对象真正存储的有效信息，也是程序代码中定义的各种类型的字段内容。 3. 对象的访问定位 建立对象是为了使用对象，而在Java程序中需要通过栈(一般指虚拟机栈)上的reference数据来操作堆上的具体对象。由于reference在Java虚拟机规范中只规定了一个指向对象的引用，并没有规定这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方式要看虚拟机具体如何实现，一般有两种方式：使用句柄、直接指针。 1.使用句柄访问的话，Java堆中会 分出一块内存当做句柄池，reference中存储的就是对象的句柄地址，句柄中则包含了对象实例数据与类型数据各自的具体地址信息。 2.使用直接指针访问的话，那Java堆对象的布局就必须考虑如何放置访问类型数据的相关信息，这里reference中存储的直接就是对象的地址。 句柄访问好处：存储稳定 (常用)直接指针访问好处：访问速度快 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-21 16:07:02 "},"1-Java 基础/垃圾收集器与内存分配策略.html":{"url":"1-Java 基础/垃圾收集器与内存分配策略.html","title":"垃圾收集器与内存分配策略","keywords":"","body":"概述 Java垃圾收集机制是为了避免内存溢出异常而做的努力 垃圾收集(Garbage Collection)需要完成的3件事情： 哪些内存需要回收？ 什么时候回收？ 如何回收？ 目前其实内存的动态分配、内存的回收技术已经相当成熟，那么为什么要了解GC和内存分配呢？因为当排查各种内存溢出、内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，就需要了解GC和内存如何分配。 1. 对象已死吗？ 使用引用计数法(很难判断对象之间相互循环引用的问题) 可达性分析算法(GC Roots为起点，通过引用链 看对象是否可达) 2. 再谈引用 什么是引用？就是某一块区域中的数据是另一块内存的起始地址。JDK1.2之后分为强引用、软引用、弱引用、虚引用。 3. 回收方法区 在方法区中进行垃圾回收一般性价比很低，而在堆中，尤其是在新生代中，进行一次垃圾收集一般可以回收70％~95％的空间，而方法区(永久代)的垃圾收集效率远低于此。 永久代一般收集：废弃常量、无用的类。无用的类： 该类所有的实例都已被回收，即Java堆中不存在该类的任何实例。 加载该类的ClassLoader已被回收。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-16 10:45:07 "},"1-Java 基础/对Java中Class类理解.html":{"url":"1-Java 基础/对Java中Class类理解.html","title":"对Java中Class类理解","keywords":"","body":"先看四个小点： 1.JVM为每个加载的class及interface创建了对应的Class实例来保存class及interface的所有信息。 2.获取一个class对应的Class实例后，就可以获取class的所有信息。 3.通过Class实例获取class信息的方法称为反射。 4.JVM总是动态加载class，可以在运行期根据条件来控制加载class。 除了八种基本数据类型外，Java的其它类型全部都是class（包括interface）。仔细思考可以得出结论：class（包括interface）的本质是数据类型（Type）。JVM在执行过程中遇到某一种class类型时，才会把它加载到内存。 每加载一种class，JVM就为其创建一个Class类型的实例，并关联起来。可以看一下Class这个class: public final class Class { private Class() {} } 以String类为例，我们会把String.java文件编译成String.class文件，然后只有当用到这个String类的时候，JVM才会把它加载到内存，在这里JVM会首先读取String.class文件到内存，然后为String类创建一个Class实例并关联起来。 Class cls = new Class(String); 注意这个cls是由JVM内存创建的，看JDK源码就可以发现Class的构造方法是private的，所以只有JVM能创建Class实例，自己的Java程序无法创建。 private Class(ClassLoader loader) { // Initialize final field for classLoader. The initialization value of non-null // prevents future JIT optimizations from assuming this final field is null. classLoader = loader; } 所以JVM持有的每个Class实例都指向一个数据类型（class或interface） JVM会为每个加载的class创建对应的Class实例，并会在实例中保存该class的所有信息，包括类名、包名、父类、实现的接口、所有方法、字段...所以只要拿到某个Class实例就可以通过实例获取到这个实例对应的class的所有信息（反射）。 // 如何拿到一个类的Class实例？ Class cls = String.class; String s = \"Hello\"; Class cls = s.getClass(); Class cls = Class.forName(\"java.lang.String\"); 注意Class实例在JVM中是唯一的，所以不管你用哪一种方法获取Class实例，只要获取的是同一个类，那么就是同一个实例。可以用==来比较一下两种方法获取到的实例。 Class实例比较和instanceof的区别 Integer n = new Integer(123); boolean b1 = n instanceof Integer; // true，因为n是Integer类型 boolean b2 = n instanceof Number; // true，因为n是Number类型的子类 boolean b3 = n.getClass() == Integer.class; // true，因为n.getClass()返回Integer.class boolean b4 = n.getClass() == Number.class; // false，因为Integer.class!=Number.class 一些小细节 注意到数组（比如String[]）也是一种Class，且不同于String.class，它的类名是[Ljava.lang.String。此外，JVM为每一种基本类型如int也创建了Class，通过int.class访问。 可以通过class实例来创建对应类型的实例： // 获取String的Class实例: Class cls = String.class; // 创建一个String实例: String s = (String) cls.newInstance(); Java动态加载 JVM在执行Java程序的时候，并不是一次性把所有用到的class全部加载到内存，而是第一次需要用到class时才加载。 没用到的类不会进内存，而只是以.class文件的形式躺在那里。 动态加载class的特性对于Java程序非常重要。利用JVM动态加载class的特性，我们才能在运行期根据条件加载不同的实现类。 本文学习来源：廖雪峰 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-11-09 23:57:30 "},"10-安全/SQL注入.html":{"url":"10-安全/SQL注入.html","title":"SQL注入","keywords":"","body":"1. MySQL注入知识点 select user(); -- 查看当前MySQL登录用户名 select database(); -- 当前使用MySQL数据库名 select version(); -- MySQL版本 select * from admin limit 2,3; -- 从第二行开始查出三条结果 三种注释：--空格 或 # 或 /**/ /*内联注释*/ /*! SQL语句 */ 只有MySQL可以识别，常用来绕过WAF select * from article where id = id -- 下面这条语句执行到id=-1时会报错，然后执行后面的内联语句；使用注释来进行关键字的包含，所以后面的语句可以被MySQL执行 select * from article where id = -1 /*!union*//*!select*/ 1,2,3,4 空格 可以改成 %20 2. SQL注入分类 根据注入位置数据类型可将SQL注入分为：数字型、字符型 3. GET基于报错的SQL注入 通过在URL中修改对应的ID值，为正常数字、大数字、字符（单引号、双引号、双单引号、括号）、反斜杠来探测URL中是否存在注入点。 ## 假如SQL语句如下 select login_name, password from admin where id = ('ID') LIMIT 0, 1; ## 构造URL如下（那个➕可以注释掉后面的SQL） 192.168.1.106/sql/less-3/?id=1') --+ 4. GET基于报错的SQL注入利用 ## 正常URL请求 http://192.168.1.106/sql/less/?id=1 -- 1.利用order by判断字段数(通过增大order by后面的数字来猜测有几个字段) http://192.168.1.106/sql/less/?id=1' order by 3--+ -- 2.利用union select联合查询，获取表名 首先通过第一步知道有3个字段，那么你就可以通过如下联合查询知道是第几个字段： http://192.168.1.106/sql/less/?id=-1' UNION SELECT 1,2,3--+ http://192.168.1.106/sql/less/?id=-1' UNION SELECT 1,user(),database()--+ 5. 利用SQLmap进行SQL注入漏洞利用 不需要自己组织SQL语句来注入 6. 利用MySQL注入读写文件 读取前提： 利用MySQL读取磁盘上的某个文件的内容： select load_file('/User/liuwentao/Desktop/test.txt') 写文件： 7. Cookie注入 利用' or 1=1 --+注入 自己写比较繁琐，所以利用SQLmap进行注入： 8. 总结 无论什么注入都是需要可以进行输入的，用户可以进行修改，然后输入的值会被传递到服务器，并作为SQL语句执行。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-15 14:43:21 "},"10-安全/XSS.html":{"url":"10-安全/XSS.html","title":"XSS","keywords":"","body":"1. 什么是XSS攻击 XSS是指恶意攻击者利用网站没有对用户提交数据进行转义处理或者过滤不足的缺点，进而添加一些代码，嵌入到web页面中去。使别的用户访问都会执行相应的嵌入代码。 2. XSS类型 存储型、DOM型、反射型 3. 造成XSS的原因 过于信任客户端提交的数据。攻击者利用网站对客户端提交数据的信任，在数据中插入一些符号以及JS代码，这些数据会成为应用代码的一部分，也就是说插入的一些攻击代码会被执行。 例子： 比如在论坛中，攻击者在留言的input字段中填写alert(‘foolish!’)并提交留言，这样当其它用户访问论坛时查看留言就会获取到这段攻击代码并在网页执行。 Dom型攻击 http://www.vulnerable.site/welcome.html?name=alert(document.cookie) 受害者的浏览器接收到这个链接，发送HTTP请求到www.vulnerable.site并且接受到上面的HTML页。受害者的浏览器开始解析这个HTML为DOM，DOM包含一个对象叫document，document里面有个URL属性，这个属性里填充着当前页面的URL。当解析器到达javascript代码，它会执行它并且修改你的HTML页面。倘若代码中引用了document.URL，那么，这部分字符串将会在解析时嵌入到HTML中，然后立即解析，同时，javascript代码会找到(alert(…))并且在同一个页面执行它，这就产生了xss的条件。 4. 预防XSS 不相信用户提交的数据，对用户提交的信息进行过滤。 1、将重要的cookie标记为http only, 这样的话Javascript 中的document.cookie语句就不能获取到cookie了。 2、表单数据规定值的类型，例如：年龄应为只能为int、name只能为字母数字组合。。。。 4、对数据进行Html Encode 处理 5、过滤或移除特殊的Html标签， 例如: , , for >, &quot for 6、过滤JavaScript 事件的标签。例如 \"onclick=\", \"onfocus\" 等等。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-15 14:43:22 "},"11-分布式/CAP.html":{"url":"11-分布式/CAP.html","title":"CAP","keywords":"","body":"CAP Consistency（一致性）、Availability（可用性）、Partition Tolerance（分区容错性）。 一致性：在分布式系统中，所有节点访问同一份最新的数据副本 可用性：非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应） 分区容错性：分布式系统出现网络分区的时候，仍然能够对外提供服务 网络分区 本来分布式系统中各个节点都是连通的，但是由于某些节点发生故障，导致某些节点之间就不连通了，整个网络就分成了几块区域，即网络分区。 当发生了网络分区的时候，我们必须先要满足P，也就是必须要先实现分区容错性，这是前提，然后如果我们要继续服务，那么一致性和可用性只能2选1。因为在出现分区时，一致性和可用性其实不能同时保证。 举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-03-31 11:59:39 "},"11-分布式/分布式事务.html":{"url":"11-分布式/分布式事务.html","title":"分布式事务","keywords":"","body":"单应用架构的事务 分布式事务出现的意义 分布式事务常用的2PC, 3PC 除了2pc, 3pc,还有什么协议算法？paxos算法，zookeeper的zab算法； Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-05-06 10:44:03 "},"12-其它/Github Action指南.html":{"url":"12-其它/Github Action指南.html","title":"Github Action指南","keywords":"","body":"参考来源：GitHub action指南 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-21 10:20:56 "},"12-其它/Mac 安装 Ruby 及 Jekyll 并利用 GitHub Pages 搭建博客.html":{"url":"12-其它/Mac 安装 Ruby 及 Jekyll 并利用 GitHub Pages 搭建博客.html","title":"Mac 安装 Ruby 及 Jekyll 并利用 GitHub Pages 搭建博客","keywords":"","body":"官网链接 1 环境准备 安装原因 由于Mac电脑自带的Ruby版本过低（2.3.x），而安装Jekyll要求Ruby版本>2.4.0 利用Homebrew安装Ruby 首先需要安装Homebrew /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 再安装Ruby brew install ruby 然后导入Ruby的环境变量#注意利用export导入这种方式是临时环境变量，重新开一个终端导入的这个环境变量就不存在了 export PATH=/usr/local/opt/ruby/bin:$PATH 检查Ruby版本 ruby -v 安装Jekyll并导入Jekyll环境变量 gem install --user-install bundler jekyll export PATH=$HOME/.gem/ruby/X.X.0/bin:$PATH #用安装的Ruby版本号的前两位替换 X.X 注意点 Every time you update Ruby to a version with a different first two digits, you will need to update your path to match. 由于利用export导入的环境变量是临时变量，所以虽然电脑已经安装了最新版本的Ruby，但是每次使用Ruby是必须重新利用export导入。 总之重新打开终端之后必须依次执行以下两行才能识别到Ruby和Jekyll export PATH=/usr/local/opt/ruby/bin:$PATH export PATH=$HOME/.gem/ruby/X.X.0/bin:$PATH 2 主题安装与配置 下载主题并配置相关参数 自己选择一个喜欢的主题，我选择的是scribble（在GitHub上可以找到，然后安装它的说明下载、配置） Get started Fork the repository Clone the repository: git clone https://github.com/username/scribble Run bundle install Run Jekyll: bundle exec jekyll serve -w Go to http://localhost:4000 for your site. Make it yours Edit _config.yml, adn then rerun jekyll serve -w Change about.md for blog intro 3 域名配置与发布 和Windows类似，可以参见另一篇文章。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-03-29 09:03:32 "},"12-其它/springboot 和 Django 项目部署到阿里云.html":{"url":"12-其它/springboot 和 Django 项目部署到阿里云.html","title":"Springboot 和 Django 项目部署到阿里云","keywords":"","body":"springboot 和 Django 项目部署到阿里云 因为我的本科毕业设计是 springboot 工程，但是当中需要用到 OpenCV 来处理图片，由于 Java 版本的 OpenCV 不太方便，所以想到搭建一个 Django 服务，这样就可以利用 Python 来对图片进行预处理。 1. springboot 项目部署 我这里用的是 IDEA，所以利用 maven 可以对 springboot 项目直接打包，由于 springboot 项目当中内置了 Tomcat，所以点击右边的 maven package 打包之后在 target 目录下会产生一个 jar 包。 只要把这个 jar 文件上传到服务器上某个目录下，然后在那个目录下运行以下命令： # 简单运行，关闭连接窗口后程序会退出 java -jar winterliu-0.0.1-SNAPSHOT.jar # 让这个程序在后台挂载 nohup java -jar winterliu-0.0.1-SNAPSHOT.jar & 这个就可以让这个程序一直挂载运行，这个端口号就是运行的端口号。 2. Django 项目部署 因为我这里 Django 项目非常简单，没有涉及到数据库和界面方面的操作，只是简单的接收 JSON 和 发送 JSON 数据的服务，所以只需要把 Django 项目文件夹上传到服务器上就行了。 因为在 pycharm 中可以简单的利用 install 来下载需要的包，这里需要利用 pip 安装这个项目当中需要的一些包。比如这里用到腾讯 OCR ： pip3 install tencentcloud-sdk-python 然后到 Django 项目目录下运行以下命令启动 Django 服务： python3 manage.py runserver # 这也是简单运行 # 挂载通用命令 nohup \"这里是运行的命令\" & 3. 遇到的问题 部署 Django 时我遇到的一些问题： (1) django.core.exceptions.ImproperlyConfigured: SQLite 3.8.3 or later is required (found 3.7.17) (2) python中import cv2遇到的错误及安装方法 (3) CentOS 7 Python3.6环境下安装libSM、libXrender、libXext Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-20 17:44:30 "},"13-研究生学习任务/2020-09-25-学习任务-1.html":{"url":"13-研究生学习任务/2020-09-25-学习任务-1.html","title":"09 25 学习任务 1","keywords":"","body":"第一次学习任务 1. virtualenv 在 Python 中用于环境隔离，因为由于各个 Python 项目所需要的包的版本不相同，所以把聚焦点放到某一个项目上，为每一个项目单独配置一套环境。 virtualenv 虚拟环境的原理就是：执行 source myenv/bin/activate 以后会把 myenv/bin （也就是你程序要用的解释器）塞到 PATH 前面，让这个复制出来的 Python 解释器最优先被搜索到，所以后面再安装包时， 就会是myenv 了，实现安装路径的隔离。 用命令 source venv/bin/activate 进入一个 virtualenv 环境时，virtualenv 会修改相关环境变量，让命令 python 和 pip 均指向当前的 virtualenv 环境。 2. 关于 Python 中安装的第三方包 python 解释器在哪 --> 推导出包的路径 Python3.7 自带了 pip3 # 创建一个虚拟环境 python3 -m virtualenv titanicEnv 参考来源：Python安装包的问题 3. Kaggle 初步学习（机器学习常规步骤） 1.基本步骤 （1）读数据 （2）选取特征 X，拿到 train_data 中的特征数据 X，y （3）选定模型，拿 X 和 y 去训练 model，然后拿 X_test 去预测，得到 prediction 2.对模型进行评估 （1）mean absoluted error（MAE） 3.欠拟合和过拟合 This is a phenomenon called overfitting, where a model matches the training data almost perfectly, but does poorly in validation and other new data. When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called underfitting. we want the low point of the (red) validation curve in.（就是要MAE值最低的那个点） 4. Titanic 问题 1.data science 需要解决的问题 （1）classifying 分类 （2）correlating 相关联 （3）converting 转换（可能需要将文本转成数值） （4）completing 补全缺失值 （5）correcting 将样本中一些可能错误的值进行更正或者排除这些异常样本。如果某个特征没啥用而且可能扭曲最 终结果，我们可以将这个特征直接抛弃。 （6）creating 可以依据已给的特征创造新的特征 （7）charting 画图来看中间结果 总结：基于数据分析去做出 Assumtions。通过初步的看数据（train_df.info, descripe）来观察，观察之后做一些猜想，然后再通过对数据进行分析（可以作图）来验证猜想，再去决定要不要将某个特征放到 model 中训练。（观察 --> 决定） 2.数据分析 （1）单个分析某个特征和 goal 之间的关系（类似于单一变量法），目的是去验证我们的一些猜想和假设。 （2）可以通过作图发现某些特征和 goal 之间并不存在线性关系。 3.整理数据 （1）Correcting by drop features 丢弃一些特征，这样我们可以处理更少的数据，简化分析。但是不能随便丢弃，要基于 assumption and decisions来决定丢弃。 （2）Creating new feature extracting from existing 某些给的特征可能看上去和 goal 之间没有直接联系，但是通过处理之后，可能找到它们之间的关系，从而创造出一个新的特征。 （3）Converting a categorical feature 对于像性别为 female、male 这样的带有字符串的特征，我们需要将它数字化，也就是转成数值型。 （4）Completing a numerical continuous feature 给的 train 或者 test data 中某些数值型样本可能存在缺失，所以需要对其补全。补全一般有三种方式，比如这里对 Age 补全： 一种简单的方法是在均值和标准差之间生成随机数 还可以通过利用其它特征来猜测缺失值， In our case we note correlation among Age, Gender, and Pclass. Guess Age values using median values for Age across sets of Pclass and Gender feature combinations. So, median Age for Pclass=1 and Gender=0, Pclass=1 and Gender=1, and so on... 结合方法1和方法2。因此，不要根据中位数来猜测年龄值，而是使用平均值和标准差之间的随机数，基于一组Pclass和性别组合 但是注意补全得考虑是否会带入 noise，这里的第一种和第三种方法 will introduce random noise into our models，所以这里采用方法二。 （5）对数值型特征转成某个区间来观察 比如这里通过给 Age 划分成一个个的区间，来观察各年龄段（AgeBand）和 survived 之间的关系。但是在模型中用的是数值，所以还需要将 AgeBand 换成序数型特征。通过转成区间的方法，避免了某些不太正常的样本对模型产生噪音。 （6）Create new feature combining existing features 我们还可以通过将 Parch 和 SlibSp 联合起来创建一个新的特征 FamilySize，这样就可以 drop 掉 Parch 和 SlibSp。在 FamilySize 和 survived 的关系表格可以看到其实它和 survived 没有一个线性关系，所以我们创建了一个 IsAlone 特征，这个特征就和 survived 有线性关系了，所以把其它几个特征直接 drop 掉。 4.模型 要搞清你解决的是哪类问题，是分类问题吗？分类又有二分类、多分类，是监督/无监督学习？是回归问题吗？主要看你的特征和 goal 之间的关系。监督学习 + 分类 + 回归问题，可以用以下模型： Logistic Regression KNN or k-Nearest Neighbors Support Vector Machines Naive Bayes classifier Decision Tree Random Forrest Perceptron Artificial neural network RVM or Relevance Vector Machine 5. 总结 主要通过 Titanic Data Science Solutions 学习，对利用 data science 来解决问题有了一个初步的认识，当然，这个帖子在 Kaggle 中并不是得分最高的，但是这却是一个很好的数据分析、用 data science 解决实际问题的帖子。在对这个帖子进行学习中我还产生了很多疑问，比如：这是一个线性回归问题没错，但是在将字符串特征转换数值型特征中，简单的将 female 转成 1，male 转成 0，或者登船口的转换关系为 {'S': 0, 'C': 1, 'Q': 2}，我还不太明白，对训练之后的模型中特征的对应的系数怎么来的也不清楚。 复现过程：点这里 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-15 14:46:10 "},"13-研究生学习任务/2020-10-15-spark基础.html":{"url":"13-研究生学习任务/2020-10-15-spark基础.html","title":"10 15 Spark基础","keywords":"","body":"Spark RDD是弹性分布式数据集，这些数据是分布式存储的，基于内存运算。 1. 单个RDD运算 2.多个RDD“转换”运算 3. 基本动作运算 intRDD.stats() #描述性统计信息 机器学习完成推理性统计信息的获取 4. RDD key_value \"转换\"运算 （上面的都是基于列表的，从这里开始基于键值对） mapValues：针对值进行映射 reduceByKey(lambda x, y: x+y).collect(); 它会按照key将它们汇聚到一起，再执行x+y操作（如果只有一项，后面的y就没有了） 5. 多个RDD key_value \"转换\"运算 RDD中（3，4）这种括号包住的是一个元组，虽然也是key value形式(key, value)，但是这里允许多个key重复，和Python中的字典不一样。 6. Key value 动作运算 kvRDD1.lookup(5) # 对于key-value类型的RDD，该函数可以取出相同的key的value值，组成一个集合队列 r1 = kvRDD1.lookup(5) print(type(r1)) 7. 弹性分布式数据 （广播变量：是执行任务的多台计算机进程共享数据对的方式，分布式共享） 这里就把fruitMap这个字典转成了一个广播变量bcFruitMap; 因为这里是分布式的，分布式的话是在多台机器上做计算，所以得通过广播变量，因为广播变量是写到sc里面去的，写到了这个上下文环境，而n台机器是通过sc去分配任务的，那么它只要在同一个环境当中，这个广播变量就可以共享。多台数据要通信的话，是要通过这个广播变量来实现的。 8. accumulator累加器 (分布式累加) 注意它是分布式的，所以不像单机的累加；这里累加也要在sc中声明一个累加器 9. RDD Persistence持久化 将数据缓存在内存，提高性能的措施，分布式缓存。 10. WordCount程序 spark中主要就是map和reduce函数：map用于分解任务，reduce用于合并、归约 11. Spark数据处理，RDD 转 DataFrame 3.将RDD转成DataFrame (DataFrame其实是spark.sql模块上的) 13. spark获取部分列 14. 增加列、过滤列 15.单个字段排序 RDD也可以用ROW对象构造成一个dataframe对象。然后dataframe可以注册成临时表，然后用类似sql语句可以去操作。 16. 多字段排序 17. 显示不重复数据 18. 预处理邮编数据集 分组数据统计： Join关联数据 邮编数据处理：过滤头部列名所在行 把包含字符串的引号去掉（这里要用转义符\\\")，然后再根据逗号分割，返回一个二维数组（一个列表）。 19. 建立spark临时表 1.先将RDD转成dataframe 2.再将dataframe注册成临时表： 注意这里三种格式的数据：RDD，df, 数据库中一张表 然后将zipcode_table 和 user_table通过u.zipcode = z.zipcode连接起来： 20. pyspark转化成pandas做可视化 然后可以将列向量转成行向量： 绘制饼图： Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-11-27 22:49:08 "},"13-研究生学习任务/2020-10-25-IRP字段.html":{"url":"13-研究生学习任务/2020-10-25-IRP字段.html","title":"10 25 IRP字段","keywords":"","body":"从IRP log提取的数据： IRP： I/O请求数据包（英语：I/O request packets，缩写IRP）是Windows Driver Model（WDM）和Windows NT驱动程序为相互通信以及与操作系统通信而使用的内核模式结构。其是一种描述I/O请求的数据结构，类似“I/O请求描述符”。相比直接将大量小参数（如缓冲区地址、缓冲区大小、I/O函数类型等等）传递给驱动程序，将所有参数以指向此持久数据结构的一个指针传递更为方便。如果I/O请求不能立即执行，IRP及其所有参数可以在队列中等待。 发送到设备驱动程序的大多数请求都打包在I/O请求包（IRP）中。操作系统组件或驱动程序通过调用IoCallDriver将IRP发送给驱动程序，IoCallDriver有两个参数：指向DEVICE_对象的指针和指向IRP的指针。设备对象有一个指向关联的驱动程序对象的指针。当一个组件调用IoCallDriver时，我们说该组件将IRP发送到设备对象或将IRP发送到与设备对象关联的驱动程序。有时使用短语传递IRP或转发IRP而不是发送IRP。 IRP 各个字段含义： Opr SeqNum PreOp_Time PostOp_Time Process_Thrd PPID Process_Name Major_Operation Minor_Operation IrpFlags DevObj FileObj Transactn status_inform Arg1 Arg2 Arg3 Arg4 Arg5 Arg6 BufferLength Entropy Name IRP 0x00000009 08:07:18:975 08:07:18:975 2868.356 1192 C:\\wtygcdcv\\bin\\inject-x86.exe IRP_MJ_QUERY_SECURITY 0x00000000 ---- 0xFFFFFA8002072A10 0xFFFFFA8002E2A420 0x0000000000000000 0x00000000:0x0000000000000098 0x000000000000001F 0x0000000000000108 0xFFFFF8A002ECF3D0 0x0000000000000000 0x0000000000000000 0x00000000 0 0 \\Device\\HarddiskVolume2\\Users\\John\\AppData\\Local\\Temp\\2a1f53bafa180dabd5cfb38dc2e298cf1468a12042a047977f1c27498b54a267.exe 操作名字 这个I/O请求数据包的序列号 这个I/O请求开始时间 这个I/O请求结束时间 发起这个I/O请求对应的进程号_线程号 发起这个I/O请求的进程的父进程 发起这个I/O请求的进程名字（也就是哪一个程序发起的I/O请求） 这个I/O请求中包含的主要操作。 这个I/O请求中包含的次要操作。 这个I/O请求中的返回值。（用来标记请求是否成功） 这个IRP包发送到的设备驱动程序的指针。 这个IRP包是对哪个文件在进行操作。FileObj就是这个文件的指针 这个I/O请求的交易序号 I/O请求的状态信息 I/O请求包中带的几个参数。 发起这个I/O请求设置的缓存区大小 熵 产生的日志位置 IRP数据包中进行的几种Major_Operation操作： 参考来源 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-26 17:21:11 "},"13-研究生学习任务/2020-10-27-HTTPS隐蔽信道流量.html":{"url":"13-研究生学习任务/2020-10-27-HTTPS隐蔽信道流量.html","title":"10 27 HTTPS隐蔽信道流量","keywords":"","body":"通过Metasploit创造木马，远程控制另一台电脑，中间用HTTPS进行通信，通过这种方式来产生HTTPS隧道流量（在被攻击方用wireshark抓通信包，注意在wireshark中通过监听端口这一条件来筛选要的那部分流量）。 用MSF进行后渗透测试： Metasploit入门 How to use msfvenom https://www.cnblogs.com/backlion/p/9484949.html https://www.cnblogs.com/backlion/p/9484949.html meterpreter会话渗透常用命令：https://blog.csdn.net/qq_34450601/article/details/80207959 https://xz.aliyun.com/t/2380 使用msfvenom生成木马 Kali(渗透工具):10---Meterpreter远程控制方式 Msfvenom命令总结大全 我按照论文里面说的全部利用虚拟机，但是发现并不能监听到被攻击端的连接，所以换成了把木马放到实验室局域网的另外一台电脑，这样才成功监听。 Shadowsocks-libev + simple-obfs流量获取 总体流程： 搭建服务器端、客户端环境： 服务器搭建：https://gist.github.com/zgpeace/62cd97d627e2a2f37cb75da820cf62ee 客户端：https://github.com/itrump/ssfree/blob/master/cn/ss_android_obfs_%E6%95%99%E7%A8%8B.md Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-12-02 17:29:24 "},"13-研究生学习任务/2020-10-30-DGA和DNS机器学习模型学习.html":{"url":"13-研究生学习任务/2020-10-30-DGA和DNS机器学习模型学习.html","title":"10 30 DGA和DNS机器学习模型学习","keywords":"","body":"1.DGA (域名生成算法)是一种利用随机字符来生成C&C域名，从而逃避域名黑名单检测的技术手段。 这个模型通过提取出最后一级域名，对最后一级域名进行特征提取。 特征工程的总体规划：1.只对最后一级域名进行字符分析（分析随机性） 2.增加无空格文本分词特征 统计维度，共4维：std_dev, avg, max, min TLD + SLD: 共五维 - is_com = 0/1 - is_net = 0/1 - is_cn = 0/1 - is_club = 0/1 - is_org = 0/1 域名长度：共一维 text_dns_qry_name_len 随机性和熵：共一维 域名可读性：域名中包含的元音数目、包含的元音字母占整个域名的比例、域名中包含的数字数目、包含的数字占整个域名的比例、域名中包含的重复字母组合数。。。。 马尔科夫链转移概率： WHOIS域名注册信息（谨慎使用）： DNS Binding Record (未实现)：合法的DNS域名都会有对应的有效IP绑定记录。。非法的dga域名除了绑定了少量真实域名之外，其它的都是不存在的空域名。 ALEAX_RANK: n-gram平均排名： 以上都是一些可以选择的特征，但是为了提高模型训练效率，需要进行特征选择。 PCA降维 （放弃） 特征重要性评估：使用GBDT算法进行特征重要性评估 第一轮 - 二分类， 最后还可以进行规则过滤，这里采用了好几种过滤方式：白名单、cdn、domain_levels过滤。。白名单也就是看域名在不在白名单里面，这里用的是Alexa-top排名，一般排名比较高的域名是没有问题的。 最最后设置一个阙值。 2.DNS Tunnel模型 计算的全是聚合特征，输入可以理解为数组，所要计算的特征：ip_type_ratio, dubdomain_avg_len, distinct_queries, distinct_query_ratio, entropy, meaningful_word_max_avglen。 首先从中心流量中提取请求域名字段, 根据注册域名进行分组，再根据时间窗口1h进行分组.孤立森林模型将根据每一行的六维特征给出预测结果, 并打上标签predict：1/-1 过滤脏数据： 从中心所提取的特征中, 发现有不少局域网域名混入在 dns 流量中. 现已尽可能的过滤该部分流量. 过滤规则如下: 过滤 subdomain_avg_len == 0 的流量 过滤解析出错的流量 (即非正常流量) 过滤结尾为 .arpa 的流量 总结：这个模型前部分和dga类似，都是从请求域名中获取需要的字段来作为特征（一部分特征），然后这里还多了一项提取隧道特征（另一部分特征）。 拿到了上面的特征之后然后开始预测： 隧道模型预测 过滤模型判白的流量 再过滤提供正常服务的域名的数据 过滤在aleaxtop中的域名数据 最后把过滤后的数据保存。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-11-27 22:50:30 "},"13-研究生学习任务/FTP协议.html":{"url":"13-研究生学习任务/FTP协议.html","title":"FTP协议","keywords":"","body":"Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-11-03 10:56:09 "},"2-Java 并发/1-ThreadLocal.html":{"url":"2-Java 并发/1-ThreadLocal.html","title":"ThreadLocal","keywords":"","body":"static ThreadLocal localVariable = new ThreadLocal<>(); localVariable.get(); // 获取当前线程本地内存中localVariable变量的值 localVariable.remove(); // 清除当前线程的本地内存中localVariable变量 Thread threadOne = new Thread(new Runnable() { public void run() { localVariable.set(\"threadOne\"); } }); Thread threadTwo = new Thread(new Runnable() { public void run() { localVariable.set(\"threadTwo\"); } }); 如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会去复制这个变量，保存到自己线程的内存中，成为一个本地副本（这样别的线程操作threadLocal变量时不会影响这个线程中的threadLocal变量），比如线程one操作这个变量时，其实操作的是线程one的本地内存中的副本。从而避免了线程安全问题。 你不是开了很多个线程吗，但是每个线程的本地变量不是存放在ThreadLocal实例里面，而是存放在调用线程的threadLocals变量（Thread类的一个属性）里面。 ThreadLocal就是一个工具壳（包住了Thread类），调用threadLocal变量的set和get方法时再去拿当前线程（Thread）的threadLocals这个属性的值。 因为每个线程（Thread）可以关联很多个threadLocal变量，所以把threadLocals属性设计为ThreadLocalMap（一个定制化的HashMap）。threadLocals是一个HashMap结构，其中key就是当前线程的ThreadLocal的实例对象引用，value是通过set方法传递的值。 如果当前线程不消亡，那么这些本地变量会一直存在当前线程的threadLocals这个map型变量中，所以可能造成内存溢出，因此使用完毕后记得调用threadLocal.remove()，删除当前线程threadLocals中的本地变量。 ThreadLocal不支持继承性 同一个ThreadLocal变量在父线程中被设置值后，在子线程中是获取不到的。还是和上面说的一样，因为各个线程中的threadLocal变量是相互独立的，存在于各自线程实例的threadLocals属性中。 InheritableThreadLocal类 用这个类之后，子线程就可以访问父线程中设置的本地变量。这个类继承于ThreadLocal类。它重写了ThreadLocal中的三个方法，它重写了createMap方法，所以当第一次调用set方法时，创建的是当前线程的inheritableThreadLocals变量的实例而不再是threadLocals。当get方法获取当前线程内部的map变量时，获取的也是inheritableThreadLocals而不再是threadLocals。 所以，在InheritableThreadLocal的世界里，变量inheritableThreadLocals代替了threadLocals。当用的是InheritableThreadLocal类时，创建map的ThreadLocalMap构造函数内部会把父线程的inheritableThreadLocals成员变量的值复制到新的ThreadLocalMap对象（也就是子线程的inheritableThreadLocals）中。 总结： InheritableThreadLocal类通过重写getMap(Thread t){ return t.inheritableThreadLocals;}和createMap(Thread t, T firstValue) { t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);}方法让本地变量保存到了具体线程的inheritableThreadLocals变量中。 当父线程创建子线程时，构造函数会把父线程中inheritableThreadLocals变量里面的本地变量复制一份保存到子线程的inheritableThreadLocals变量里面。所以重点是在创建子线程时（在Thread类的构造方法中），复制了一份一模一样的给子线程。 详细说明：创建子线程就需要调用Thread的构造方法，而且你还需要帮子线程new一个inheritableThreadLocals变量，因为这个变量是ThreadLocalMap类型的，所以需要调用ThreadLocalMap类的构造方法（最终就是在这个构造方法中将父线程的inheritableThreadLocals的所有值复制给子线程的inheritableThreadLocals变量的）。 public static ThreadLocal threadLocal = new InheritableThreadLocal(); 什么时候需要子线程可以获取父线程的threadlocal变量呢？比如子线程需要使用存放在threadlocal变量中的用户登录信息，再比如一些中间件需要把统一的id追踪的整个调用链路记录下来。 我们还可以手动去做，比如创建线程时传入父线程中的变量，并将其复制到子线程中，或者直接在父线程中将threadLocal中的值存到一个map中，将这个map作为参数传给子线程。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-16 14:23:54 "},"2-Java 并发/2-并发编程的其它基础知识.html":{"url":"2-Java 并发/2-并发编程的其它基础知识.html","title":"并发编程的其它基础知识","keywords":"","body":"共享变量的内存不可见问题 在多线程下处理共享变量时Java的内存模型： 实际中线程的工作内存模型： Synchronized关键字 synchronized块是Java提供的一种原子性内置锁，Java中的每个对象都可以把它作为一个同步锁来使用。内置锁是排它锁，当一个线程获取这个锁后，其它线程必须等待该线程释放锁后才能获取该锁。 Java中的线程是与操作系统中的原生线程一一对应的，所以当阻塞一个线程时，需要从用户态切换到内核态执行阻塞操作，这很耗时，而synchronized的使用就会导致上下文切换。 synchronized的内存语义 共享变量的内存可见性问题主要是由于线程的工作内存导致的，而synchronized的内存语义就可以解决共享变量内存可见性问题。 重点：进入synchronized块的内存语义是把synchronized块内使用到的变量从线程的工作内存（也就是该线程的本地内存）中清除，这样在在synchronized块内使用到该变量时就不会从线程的工作内存中获取，而是直接从主内存获取。退出synchronized块的内存语义是把在synchronized块内对共享变量的修改（也就是该线程的本地内存中对共享变量的修改）刷新到主内存。 也就是说用了synchronized之后，各个线程拿数据、写数据的对象本质上是主内存。 这也是加锁（进入synchronized块）和释放锁（退出synchronized块）的语义。 除了可以解决内存可见性问题外，synchronized还被用来实现原子性操作。 Java中的volatile关键字 使用锁太笨重，造成线程上下文切换开销。所以Java还提供了一种弱形式的同步，即使用volatile关键字。该关键字可以确保对一个变量的更新对其他线程马上可见。 当一个变量被声明为volatile时，线程在写入变量时不会把值缓存在寄存器或者其它地方，而是直接把值刷新回主内存。当其它线程要读取该共享变量时，会从主内存重新获取最新值，而不是使用当前线程的工作内存中的值。 但是注意：synchronized可以保存操作的原子性，因为它是独占锁，但是volatile虽然提供了可见性保证，但是不能保证操作的原子性。（所以一般get或者set的时候可以直接加volatile，但是如果有getAndSet操作时，由于volatile并不能保证操作的原子性，所以遇到getAndSet操作时一般用synchronized加锁） 比如一条：++value;语句，它被编译之后其实有四步，所以线程在执行这条语句时，++value被转换为汇编后就不具有原子性了。 线程安全：内存可见性和原子性。 别忘了synchronized提供的安全性包括内存可见性和原子性，所以如果单单是getCount()去读取某个变量的值时也是要加synchronized的，因为如果不加，可能它读的是自己线程本地内存上的变量的值（可能和主内存不一样）。 Java中的CAS操作 在内部使用非阻塞CAS算法实现原子性操作类AtomicLong. CAS即Compare and Swap，它是JDK提供的非阻塞原子性操作。它通过硬件保证了比较-更新操作的原子性。 Unsafe、Java指令重排序 伪共享 由于存放到cache行的是内存块而不是单个变量，所以可能会把多个变量存放在同一个cache行中。当多个线程同时修改一个缓存行里面的多个变量时，由于同时只能有一个线程操作缓存行，所以相比将每个变量放到一个缓存行，性能会有所下降，这就是伪共享。 也就是说当线程1使用CPU1对变量x更新时，首先会修改CPU1的一级缓存变量x所在的缓存行，这时在缓存一致性协议下，CPU2中变量x对应的缓存行会失效。所以线程2在写入变量x时只能去二级缓存里查找，这就破坏了一级缓存。性能下降。 说明多个线程不可能同时去修改自己所使用的的CPU中相同缓存行里面的变量。 伪共享的产生是因为多个变量被放入了一个缓存行中，并且多个线程同时去写入缓存行中不同的变量。 缓存与内存交换数据的单位就是缓存行。其实在单线程情况下，有缓存行对代码执行是有利的。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-21 16:30:52 "},"2-Java 并发/3-Java并发包中ThreadLocalRandom类原理剖析.html":{"url":"2-Java 并发/3-Java并发包中ThreadLocalRandom类原理剖析.html","title":"Java并发包中ThreadLocalRandom类原理剖析","keywords":"","body":"Random类及其局限性 Random random = new Random(); 我们一般上面这行代码来获得随机数，这里声明一个random对象，如果构造函数中不传递参数则使用默认的种子，这个种子就是一个long类型的数字，有了种子之后。 在单线程下都是先根据老种子生成新种子，然后用新种子传递到一个固定的函数中得到一个随机数。但是如果是多线程，多个线程可能都拿到同一个老的种子去执行步骤4以计算新的种子，导致多个线程得到的新种子是一样的。因为步骤5根据种子获取随机数的算法是固定的，这样就导致多个线程产生相同的随机值。 所以我们要保证步骤四（产生新种子）的原子性，也就是说当有多个线程根据同一个老种子计算新种子时，第一个线程的新种子被计算出来之后，第二个线程要丢弃自己老的种子，而使用第一个线程产生的新种子来计算自己的新种子。这样保证了多个线程产生的随机数是随机的。在这里，Random函数使用了一个原子变量实现这个效果。 ThreadLocalRandom 这个就是为了弥补多线程高并发情况下Random的缺陷产生的。和之前说的ThreadLocal类似，这里也是让每个线程都维护一个种子变量，这样每个线程都是根据自己线程上的种子来计算随机数的。 可以看到ThreadLocalRandom和之前的ThreadLocal一样，它只是一个工具类，真正的种子threadLocalRandomSeed变量是在Thread对象中。 ThreadLocalRandom的中种子放在线程里面，ThreadLocalRandom的实例里面只包含与线程无关的通用算法，所以它是线程安全的。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-12-21 11:46:26 "},"2-Java 并发/4-Java并发包中原子操作类原理剖析.html":{"url":"2-Java 并发/4-Java并发包中原子操作类原理剖析.html","title":"Java并发包中原子操作类原理剖析","keywords":"","body":"Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-06 16:31:54 "},"2-Java 并发/5-Java并发包中并发list源码剖析.html":{"url":"2-Java 并发/5-Java并发包中并发list源码剖析.html","title":"Java并发包中并发List源码剖析","keywords":"","body":"如果让你做一个写时复制的线程安全的list该怎么做？ 何时初始化list，初始化list的元素个数多少？list是有限大小吗？ 如何保证线程安全，比如多个线程进行读写时如何保证线程是安全的？ 如何保证使用迭代器遍历list时的数据一致性？ Java并发包中并发list：CopyOnWriteArrayList 1.添加元素add（删除元素类似） 比如对这个list进行add时，会先去获取独占锁，这样其它线程如果也去add时就会被阻塞挂起。CopyOnWriteArrayList进行add时，由于加了锁，所以整个add过程是原子性操作，并且：它添加一个元素并不是直接在原数组进行，而是首先复制一个快照，在快照中添加这个元素，然后将新数组替换原数组。 2.获取指定元素 会有写时复制策略产生的弱一致性问题。 3.修改指定元素 也是先获取独占锁，防止其他线程对其进行修改，然后获取array，看看要修改的元素和array中元素值是不是一样，不一样则创建新数组、复制、重新指向。 4.弱一致性的迭代器 所谓弱一致性迭代器，是指返回迭代器后，其他线程对list的增删改对迭代器是不可见的。如果在这个线程进行遍历期间，其他线程没有对这个list进行增删改，那么snapshot本身就是list的array，因为它们是引用关系，但是一旦在遍历期间有别的线程对list进行了增删改，那么这时snapshot就是快照了，因为别的线程增删改之后list里面的数组被新数组替换了，这时候老数组被snapshot引用。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-16 15:56:18 "},"2-Java 并发/6-Java并发包中锁原理剖析.html":{"url":"2-Java 并发/6-Java并发包中锁原理剖析.html","title":"Java并发包中锁原理剖析","keywords":"","body":"1. LockSupport工具类 JDK中的rt.jar包里面的LockSupport是一个工具类，主要作用是挂起和唤醒线程，该工具类是创建锁和其它同步类的基础。（其实锁的本质就是挂起和唤醒线程） LockSupport类和每个使用它的线程都会关联一个许可证，但是默认情况下调用LockSupport类的方法的线程是不持有许可证的。所以说呢：如果你某个线程拿到了许可证，那调用比如LockSupport.park()时会马上返回，但是如果没拿到许可证，那么调用线程会被禁止参与线程的调度，即阻塞挂起。 LockSupport工具类中的park(), unpark(thread) 方法理解： 假设有thread1,thread2，在thread1中调用LockSupport.park()那么线程1会被挂起，然后需要在thread2中调用LockSupport.park(thread1)，这样线程1会被唤醒（因为调用unpark之后会让thread1持有与LockSupport的许可证）。如果thread1之前没调用park,则在thread2中调用LockSupport.unpark(thread1)之后，thread1再去调用park会立刻返回（因为thread1已经拿到了许可证了啊）。 需要注意：因为调用park方法而被阻塞的线程被其它线程中断而返回时并不会抛出InterruptedException异常。 调用LockSupport.park(this); // 这样当打印线程堆栈排查问题时就能知道是哪个类被阻塞了。 Thread类中有个变量volatile Object parkBlocker,用来存放park方法传递的对象，也就是说当你在thread1中调用LockSupport.park(blocker)时，blocker变量会放到thread1这个线程的成员变量里。 LockSupport.park()方法其实是调用的UNSAFE类中的UNSAFE.park()方法实现的，而UNSAFE.park()是一个native方法，也就是说它会去调用C语言的代码。 2. 抽象同步队列（AQS -- 锁的底层支持）概述 AQS（AbstractQueuedSynchronizer)抽象同步队列，是实现同步器的基础组件，并发包中锁的底层就是使用AQS实现的。 这是一个双向队列，其中Node放的是thread变量，Node节点中有：SHARED, EXCLUSIVE, waitStatus, prev, next. 对于AQS来说，线程同步的关键是对状态值state进行操作，根据state是否属于同一个线程，操作state的方式分为独占式和共享方式。独占方式获取的资源是与具体线程绑定的，某个线程获取到了资源，就会标记是这个线程获取到了，那么其它线程再次尝试操作state获取资源时会发现当前该资源不是自己持有，就会在获取失败后被阻塞。共享方式的资源与具体线程是不相关的，多个线程通过CAS方式去竞争获取资源，一个线程获取资源后，另外的线程再次去获取时，只要当前资源还能满足需要，另外的线程只要使用CAS方式进行获取即可，不满足的话则把这个线程放到阻塞队列。 条件变量 3. 独占锁ReentrantLock的原理 ReentrantLock是可重入独占锁。 4. 读写锁ReentrantReadWriteLock原理 ReentrantLock是独占锁，某时只能有一个线程可以获取该锁，而实际中会有写少读多的场景，所以提出ReentrantReadWriteLock，它采用读写分离，允许多线程同时获取该锁。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-11-04 21:47:22 "},"2-Java 并发/7-负载均衡三种架构.html":{"url":"2-Java 并发/7-负载均衡三种架构.html","title":"负载均衡三种架构","keywords":"","body":"1.负载均衡 负载均衡指的是通过一组后端服务器来有效的分发输入进来的网络请求，这里的服务器组其实就是 server pool. 总的来说，load balancer有以下功能： 将客户端的所有请求以及网络负载有效(这里涉及负载策略)的分发到各个服务器那里去。 确保这个 client-server 架构是 high availability and reliability 的，这些客户端发来的请求只会被分发到这些 online 的 server 那里去。 可以根据需求来灵活的增、减任意服务器。 Session Persistence 也就是 session 的持久性问题。一个用户的 session 一般都是直接存储在本地浏览器中，但是如果在分布式架构中，你去改变接收客户端请求的服务器，这个动作其实是会带来 performance issues 和 transaction failure 的。如果要保证性能不受影响、又保证传输成功的话，那就要做到： duration of the session， 来自于同一台客户端的所有请求都应该是被发送给同一台服务器。(load balancer 是可以处理这种问题的) 还有就是上游服务器会在它的缓存中直接存储用户要求的信息，通过这种方式来提高性能。但是如果你换了一台服务器来处理同一个客户端的请求，那么第二次这些用户要求的信息就需要从客户端那里重新 fetched 过来，这就造成了性能的 inefficiencies. 2.高并发负载均衡 -- LVS 模式 整个互联网是建立在下一跳的模式下，IP 是逻辑上的两个端点，MAC 是物理上连接的两个节点。 端点间 TCP 传输过程注意： 确认机制 状态机制 不可分割 解析数据包需要成本： 交换机：二层，只关心 MAC 地址 路由器：三层，只关心 IP 和路由表 LVS 服务器：四层，只关心 PORT,状态 Nginx：七层，关心 socket 对应关系(也就是说这里已经关注了应用层了!)利用负载均衡器的三种通信模型 第一种：source_net 模型 这是源NET，但是从互联网的角度出发，如果外面的机器想访问这个局域网中的某一台机器，如何访问？？？ 因为即便你知道它的公网地址18.18.18.8，你也不知道它的私有地址。。没有公网和私网地址的转换。。你最多访问到这个路由器的地址。。所以还是需要一个地址转换表，把公网转私网。。 第二种：DR 模型 VIP：虚拟服务器地址 DIP：转发的网络地址 和 RIP 通信：ARP 协议，获取 real server 的 RIP：MAC 地址 转发 client 的数据包到 RIP 上(其实是到 real server 内核里面的 VIP) RIP：后端真实主机 CIP：客户端 IP 地址 转成CIP_RIP之后，这时Server RIP才会接收这个包。 注意这里是目标地址转换，也就是D_NAT 然后，服务器端的RIP_PORT要返回数据包给客户端。。规则就是：RIP_PORT:CIP_PORT,但是如果服务器端返回RIP_CIP,这时客户端是会直接把它丢弃的。（其实就是客户端没有请求RIP，别人只是请求的VIP，现在返回一个RIP，这时客户端肯定不要啊。。）原因如下： 所以要规避这个问题，这样做： 不要把RIP_CIP直接返回给客户端，而是先交给负载均衡服务器，负载均衡服务器再恢复成VIP 给CIP返回就行了。。。。 为了把Server RIP服务器返回的所有数据包都给负载均衡服务器，所以需要把Server RIP的默认网关指向lvs 也就是负载均衡服务器。。 DR模型的第二种架构(最常用) 问题：由于客户端发送的请求数据相比服务器端返回的数据是很少的，所以可能5万个请求，只能返回1万个相应给客户端。。。因为服务器端都再次通过负载均衡给客户端传输相应数据太慢了。。。所以产生了以下这种模型。。。能不能直接从服务器端连接一跟光纤到客户端，这时：客户端发送请求还是通过负载均衡服务器发送给服务器端，但是服务器端返回的相应数据直接通过光纤传输，这样返回的数据传输就大大加快了！！！！！ 对于客户端来说，后面的负载均衡服务器和Server RIP都是透明的。。不管这些怎么变化，客户端还是CIP想访问VIP（这样套接字也就是：CIP_PORT:VIP_PORT），。。。。。。然后Server RIP需要返回一个VIP_CIP的数据包（也就是返回一个VIP包给CIP这个客户端。。） 但是！这就说明Server这台机器中必须要有一个VIP： VIP地址不能再在网络当中出现！！我们可以走擦边球，也就是给它持有这个VIP地址，但是别人问他有没有VIP地址时，他会返回没有。。。在真实的网络中真正有VIP的只有负载均衡服务器那里的VIP。 （下面图中我画的VIP_CIP反了，应该是CIP_VIP） 但是！！！！还有一个问题，就是：客户端发送一个CIP_VIP，去访问VIP，那么负载均衡器怎么扔给Server???? 解决办法如下： 在外面套一层MAC地址，也就是RIP-MAC。。。 数据包封的时候，在最外面加上RIP-MAC地址。。要有一个约束：就是负载均衡服务器和真正的server在同一个局域网。。。这里涉及到的叫MAC欺骗。。 最后注意一点：右边的几台真正的server，他们其实长得是一样的，也就是配置、资源位置都是一样的，这样面对几万个资源请求是，负载均衡器只要稍微平均一下分发给不同的server就行了。。 IP 背着 IP 架构(隧道技术) 无论翻墙也好还是VPN也好，都是IP背着IP这种机制。。。 比如你租了一台香港的服务器，因为香港的服务器可以访问国外的IP，所以先从你这里传到香港你租的服务器IP地址(这个过程其实就是隧道。。)，然后你的服务器再看到里层你想去的国外的IP地址。。。就比如这里的DIP_RIP背着CIP_VIP。。把这里的负载均衡器看成你租的香港服务器，那么你先要请求VIP，所以你发送一个CIP_VIP先给这个香港服务器，香港服务器知道你真正想访问的是RIP这个真实的服务器地址，然后就组成包DIP_RIP,其中的数据就是CIP_VIP，然后这个大包到达RIP之后，真正的服务器也就知道你是采用这种IP背着IP的技术传过来的数据包，所以他会把外壳脱去，知道真正发来请求的是CIP。。emm...真他妈难。。。受 然后RIP返回相应数据又有两种方式。。一种是继续通过负载均衡器返回数据，还有一种可以直接把数据给CIP。。。可以通过设置选择不同的方式。 参考文章 Nginx Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-22 21:54:22 "},"2-Java 并发/8-网络的层次介绍.html":{"url":"2-Java 并发/8-网络的层次介绍.html","title":"网络的层次介绍","keywords":"","body":"网络介绍 netstat -natp;虽然就是两台主机的参与，但是这里有4个TCP连接，说明TCP连接的虚拟性， 并不是真实的两条物理线的连接，就比如这里一台主机里面四个端口就相当于4个虚拟连接了 /etc/sysconfig/network-scripts/ifcfg-eth0\" 查看网卡。。。配置 route -n 互联网的传输方式是基于下一跳的方式，而不是基于路径规划的方式。。。 网络层就是决定下一跳。。 总结： 互联网确实是建立在下一跳的机制之上，不光要IP地址就行了，还需要链路层 利用MAC地址不断下一跳。。。。 三层 这是能够知道IP地址的逻辑地址，怎么知道目的机器的网卡地址呢？？ 本质： 这样可以一个数据包传输，那么网络通信无非就是先TCP三次握手，然后客户端和服务器端发送真正的数据，发发发。。。最后TCP4次分手。。。。这就是网络数据通信。。 ARP协议： 网络传输总结： 比如一个浏览器想请求服务器端Tomcat返回一个页面资源，首先不是从最上层应用层开始的，而是最上层这个请求先阻塞。。。先从第四层TCP层开始发送握手包。。， 1.先TCP-->IP-->数据链路层 （ 这当中有申请端口号的、有做路由表判定的、有网络请求下一跳地址的。。）-->物理层 2.然后服务器端的：物理层-->数据链路层-->IP层-->TCP层，这样来回发送三次数据包传输，也就是TCP三次握手，到此C/S两边的TCP打通了。。然后两边开辟资源之后，然后！才会从最上层的应用层传输真正的数据包依次往下。。。到达服务端的物理层-->.......-->应用层。。。 这样就完成了网络数据传输！！！！！！！！！！！！！！！！！！ 也就是：虽然是7层交互，但是要先4层TCP先建立连接，建立的连接都是IP,port连接，很多这样的IP，port连接，但是这些都是虚拟的连接。。。 目的是知道：你最终知道什么是负载均衡服务器，以及它们的性能开销和弊端。。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-01 10:10:09 "},"2-Java 并发/9-Java并发各个知识点.html":{"url":"2-Java 并发/9-Java并发各个知识点.html","title":"Java并发各个知识点","keywords":"","body":"wait(), notify(), notifyAll() 和 synchronized关键字 和 锁 的关系 wait(), notify(), notifyAll()都是Object类的方法，而不是Thread类，因为wait(), notify(), notifyAll()这三个本质上等待的是对象monitor，由于Java中每个对象都有一个内置的monitor，自然所有类理应有wait(), notify()方法。 注意这三个方法都要在同步块里面调用，不然会报illegal Monitor State Exception，因为调用这三个方法必须要拿到同步对象的monitor。 再说一下：synchronized是一个关键字，synchronized内置了锁，这个锁是一种对象锁（锁的是对象而非引用变量），粒度是对象，实现对临界资源的同步互斥访问，可重入（可重入避免了死锁）。 synchronized可以把任何一个非null对象作为锁，在HotSpot JVM实现中，锁有个专门的名字：对象监视器（Object monitor）。 synchronized可以加在实例方法（锁住了实例方法对应的实例对象）、静态方法（锁住了静态方法对应的类的class对象）、或者synchronized(object)。可以看到synchronized锁住的都是对象。 我们如果要实现同步，需要依赖锁来实现，那么锁的同步又依赖谁呢？synchronized给出的答案是在软件层面依赖JVM，而j.u.c.Lock给出的答案是在硬件层面依赖特殊的CPU指令。 synchronized同步代码块： synchronized同步方法： 相比于同步代码块，同步方法多了一个ACC_SYNCHRONIZED标识符，JVM根据该标识符实现方法同步。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-23 10:10:21 "},"2-Java 并发/AQS源码解读一.html":{"url":"2-Java 并发/AQS源码解读一.html","title":"AQS源码解读一","keywords":"","body":" AQS是抽象同步队列，注意它并不是简单的队列，它是同步队列，所以这个抽象类里面实现了很多用于线程同步的方法，可以看到AQS这个类在java.util.concurrent.locks包下面，是Java并发包的基础工具类，比如ReentrantLock、CountDownLatch、Semaphore、FutureTask类的实现，里面都用到了AQS这个类。 我们来看看ReentrantLock类： ReentrantLock里面主要定义了一个Sync类，这是一个抽象、静态、内部类，这个类继承了AQS类，AQS主要还是一些同步队列的方法，而ReentrantLock涉及到锁，这个锁本质上还是依赖于AQS同步队列为基础，然后因为Sync也是抽象类，它还增加了一些抽象方法，下面看下Sync类： abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = -5179523762034025860L; /** * Performs {@link Lock#lock}. The main reason for subclassing * is to allow fast path for nonfair version. */ abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc 主要方法：nonfairTryAcquire()，可以看它说的，Sync这个类在trylock时用的是不公平锁，然后在ReentrantLock类中又有NotfairSync, FairSync两个类，这两个类对于release()方法不管你公平不公平，都是一样用的Sync继承来的方法，但是对于tryLock就不一样了。 Performs non-fair tryLock. tryAcquire is implemented insubclasses, but both need nonfair try for trylock method. 这里再对ReentrantLock总结一下： 这是一个可重入锁，但是在trylock的时候可以根据参数选择公平还是非公平，默认是不公平锁，不管你ReentrantLock里面实现的是公平还是非公平，都是通过内部类Sync的对象sync来调用对应的方法。（这里用了多态） /** Synchronizer providing all implementation mechanics */ private final Sync sync; public ReentrantLock() { sync = new NonfairSync(); } public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 前面只讲了ReentrantLock里面的tryAcquire()方法，其实Sync这个类还有一个lock()抽象方法，然后NonFairSync和FairSync对这个lock()方法做了不同的实现，注意两个lock方法里面都用到了acquire()方法，这个方法是AQS类里面的final方法，下面会对这个方法做介绍。 这里介绍一下ReentrantLock类中lock(), tryAcquire()方法的一些实例使用： OK，说回AQS，首先看看AQS有哪些属性： /** * Head of the wait queue, lazily initialized. Except for * initialization, it is modified only via method setHead. Note: * If head exists, its waitStatus is guaranteed not to be * CANCELLED. */ private transient volatile Node head; /** * Tail of the wait queue, lazily initialized. Modified only via * method enq to add new wait node. */ private transient volatile Node tail; /** * The synchronization state. */ private volatile int state; // 这个最重要，代表当前锁的状态，0代表没有被占用，大于0代表有线程持有当前锁，每次重入都会加上1 /** * The current owner of exclusive mode synchronization. */ private transient Thread exclusiveOwnerThread; // 注意这个属性并不是AQS里面的，而是AQS父类AbstractOwnableSynchronizer里面的属性，AQS继承而来；代表当前持有独占锁的线程；reentrantLock.lock()可以嵌套调用多次，所以每次用这个来判断当前线程是否已经拥有了锁；if(currentThread == getExclusiveOwnerThread()) {state++} AQS就是这四个属性，再看下AQS的等待队列： 注意阻塞队列不包含head节点。等待队列中每个线程被包装成一个Node实例，这里用的是双向链表。 static final class Node { // 标识节点当前在共享模式下 static final Node SHARED = new Node(); // 标识节点当前在独占模式下 static final Node EXCLUSIVE = null; // ======== 下面的几个int常量是给waitStatus用的 =========== /** waitStatus value to indicate thread has cancelled */ // 代表此线程取消了争抢这个锁 static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ // 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒 static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ // 本文不分析condition，所以略过吧，下一篇文章会介绍这个 static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ // 同样的不分析，略过吧 static final int PROPAGATE = -3; // ===================================================== // 取值为上面的1、-1、-2、-3，或者0(以后会讲到) // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待， // ps: 半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的。。。 volatile int waitStatus; // 前驱节点的引用 volatile Node prev; // 后继节点的引用 volatile Node next; // 这个就是线程本尊 volatile Thread thread; } Node类中就是thread + waitStatus + pre + next四个属性。 总结：上面介绍了AQS的一些数据结构，其实就是上面这个等待队列，再加上前面稍微介绍了一下ReentrantLock类如何继承自AQS类，并实现了Sync静态内部类，提供了公平锁和非公平锁。下面看下ReentrantLock的使用方式： public class OrderService { private static ReentrantLock reentrantLock = new ReentrantLock(true); // 开一个公平锁 public void createOrder() { // 比如同一时间只能一个线程创建订单 reentrantLock.lock(); // 通常，lock()之后紧跟try语句 try { // 这块代码只能由获取到锁的线程执行，其他线程在lock()方法上阻塞，等拿到锁才能进入try // 执行代码... } finally { // 释放锁 reentrantLock.unlock(); } } } 线程抢锁 再贴一下这张图： 不管是公平还是不公平加锁都用到了AQS类中的acquire()方法，这里看下这个方法： public final void acquire(int arg) { // 此时arg == 1 // 首先调用tryAcquire(1)一下，这个只是试一试，如果直接就成功了，就不需要进入队列排队了 // 对于公平锁的语义就是：本来就没有人持有锁，所以根本就没必要进入队列等待 if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); // tryAcquire()没有成功，就需要把当前线程挂起，并且放入等待队列 } // 注意这里如果tryAcquire(arg)返回true，也就结束了，否则的话acquireQueued()方法会将线程压到队列中 // 这里插入一个细节：这是在ReentrantLock类中调用的tryAcquire()方法，其实AQS类里面也有tryAcquire()方法，但是我们知道ReentrantLock类重写了tryAcquire()方法，所以这里调用的是ReentrantLock类中的tryAcquire()方法。 //-------------------------------------------------------------------------------- // 我们来看一下ReentrantLock类中的tryAcquire()方法： protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); // c == 0则此时没有线程持有锁 if (c == 0) { // 那我们再看看队列中是不是有人等了好久了，因为这是公平锁，得按照队列顺序 if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) { // 没有线程在等待，就用CAS尝试一下，成功了就获取到锁了，不成功的话只能说明就在刚刚几乎同一时刻被另外一个线程抢先了 // 到这里就是获取到了锁，标记一下，告诉大家，现在是我占用了锁 setExclusiveOwnerThread(current); return true; } } // 这里不会存在并发问题 else if (current == getExclusiveOwnerThread()) { // 进入这个分支，说明是重入了，则需要操作state += 1； int nextc = c + acquires; if (nextc This method is always invoked by the thread performing * acquire. If this method reports failure, the acquire method * may queue the thread, if it is not already queued, until it is * signalled by a release from some other thread. This can be used * to implement method {@link Lock#tryLock()}. * * The default * implementation throws {@link UnsupportedOperationException}. * * @param arg the acquire argument. This value is always the one * passed to an acquire method, or is the value saved on entry * to a condition wait. The value is otherwise uninterpreted * and can represent anything you like. * @return {@code true} if successful. Upon success, this object has * been acquired. * @throws IllegalMonitorStateException if acquiring would place this * synchronizer in an illegal state. This exception must be * thrown in a consistent fashion for synchronization to work * correctly. * @throws UnsupportedOperationException if exclusive mode is not supported */ protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } acquireQueued(addWaiter(Node.EXCLUSIVE), arg)方法 如果tryAcquire(arg)尝试拿锁没有成功，就会调用：acquireQueued(addWaiter(Node.EXCLUSIVE), arg)把当前线程加入到阻塞队列中，这里看看里面的addWaiter()方法： /** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ // 此方法的作用是把线程包装成node，同时进入到队列中 // 参数mode此时是Node.EXCLUSIVE，代表独占模式 private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 以下几行代码想把当前node加到链表的最后面去，也就是进到阻塞队列的最后 Node pred = tail; // tail!=null => 队列不为空(tail==head的时候，其实队列是空的，不过不管这个吧) if (pred != null) { // 将当前的队尾节点，设置为自己的前驱 node.prev = pred; // 用CAS把自己设置为队尾, 如果成功后，tail == node 了，这个节点成为阻塞队列新的尾巴 if (compareAndSetTail(pred, node)) { // 进到这里说明设置成功，当前node==tail, 将自己与之前的队尾相连， // 上面已经有 node.prev = pred，加上下面这句，也就实现了和之前的尾节点双向连接了 pred.next = node; // 线程入队了，可以返回了 return node; } } // 仔细看看上面的代码，如果会到这里， // 说明 pred==null(队列是空的) 或者 CAS失败(有线程在竞争入队) // 读者一定要跟上思路，如果没有跟上，建议先不要往下读了，往回仔细看，否则会浪费时间的 enq(node); return node; } 上面这个方法中：如果队列为空(pred != null) 或者队列不为空但是用CAS把自己设置为队尾没成功（说明有其他线程也在用CAS竞争入队，那么就会执行下面的enq(node)方法，采用自旋的方式入队： 自旋在这里的语义是：CAS设置tail过程中，竞争一次竞争不到，就多次竞争，总会排到的 private Node enq(final Node node) { for (;;) { Node t = tail; // 之前说过，队列为空也会进来这里 if (t == null) { // Must initialize // 初始化head节点 // 细心的读者会知道原来 head 和 tail 初始化的时候都是 null 的 // 还是一步CAS，你懂的，现在可能是很多线程同时进来呢 if (compareAndSetHead(new Node())) // 给后面用：这个时候head节点的waitStatus==0, 看new Node()构造方法就知道了 // 这个时候有了head，但是tail还是null，设置一下， // 把tail指向head，放心，马上就有线程要来了，到时候tail就要被抢了 // 注意：这里只是设置了tail=head，这里可没return哦，没有return，没有return // 所以，设置完了以后，继续for循环，下次就到下面的else分支了 tail = head; } else { // 下面几行，和上一个方法 addWaiter 是一样的， // 只是这个套在无限循环里，反正就是将当前线程排到队尾，有线程竞争的话排不上重复排！！！ node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 现在又回到这里： if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); 我们看完了addWaiter(Node.EXCLUSIVE)方法，如果执行成功它会返回最新的tail，那么回过来看acquireQueued()方法： // 下面这个方法，参数node，经过addWaiter(Node.EXCLUSIVE)，此时已经进入阻塞队列 // 注意一下：如果acquireQueued(addWaiter(Node.EXCLUSIVE), arg))返回true的话， // 意味着上面这段代码将进入selfInterrupt()，所以正常情况下，下面应该返回false // 这个方法非常重要，应该说真正的线程挂起，然后被唤醒后去获取锁，都在这个方法里了 final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); // p == head 说明当前节点虽然进到了阻塞队列，但是是阻塞队列的第一个，因为它的前驱是head // 注意，阻塞队列不包含head节点，head一般指的是占有锁的线程，head后面的才称为阻塞队列 // 所以当前节点可以去试抢一下锁 // 这里我们说一下，为什么可以去试试： // 首先，它是队头，这个是第一个条件，其次，当前的head有可能是刚刚初始化的node， // enq(node) 方法里面有提到，head是延时初始化的，而且new Node()的时候没有设置任何线程 // 也就是说，当前的head不属于任何一个线程，所以作为队头，可以去试一试， // tryAcquire已经分析过了, 忘记了请往前看一下，就是简单用CAS试操作一下state if (p == head && tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } // 到这里，说明上面的if分支没有成功，要么当前node本来就不是队头， // 要么就是tryAcquire(arg)没有抢赢别人，继续往下看 if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) interrupted = true; } } finally { // 什么时候 failed 会为 true??? // tryAcquire() 方法抛异常的情况 if (failed) cancelAcquire(node); } } 这里面又涉及到shouldParkAfterFailedAcquire()方法： /** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev * * @param pred node's predecessor holding status * @param node the node * @return {@code true} if thread should block */ // 刚刚说过，会到这里就是没有抢到锁呗，这个方法说的是：\"当前线程没有抢到锁，是否需要挂起当前线程？\" // 第一个参数是前驱节点，第二个参数才是代表当前线程的节点 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; // 前驱节点的 waitStatus == -1 ，说明前驱节点状态正常，当前线程需要挂起，直接可以返回true if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // 前驱节点 waitStatus大于0 ，之前说过，大于0 说明前驱节点取消了排队。 // 这里需要知道这点：进入阻塞队列排队的线程会被挂起，而唤醒的操作是由前驱节点完成的。 // 所以下面这块代码说的是将当前节点的prev指向waitStatus 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus > 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 仔细想想，如果进入到这个分支意味着什么 // 前驱节点的waitStatus不等于-1和1，那也就是只可能是0，-2，-3 // 在我们前面的源码中，都没有看到有设置waitStatus的，所以每个新的node入队时，waitStatu都是0 // 正常情况下，前驱节点是之前的 tail，那么它的 waitStatus 应该是 0 // 用CAS将前驱节点的waitStatus设置为Node.SIGNAL(也就是-1) compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } // 这个方法返回 false，那么会再走一次 for 循序， // 然后再次进来此方法，此时会从第一个分支返回 true return false; } //----------------------------------------------------------------------------------- // private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) // 这个方法结束根据返回值我们简单分析下： // 如果返回true, 说明前驱节点的waitStatus==-1，是正常情况，那么当前线程需要被挂起，等待以后被唤醒 // 我们也说过，以后是被前驱节点唤醒，就等着前驱节点拿到锁，然后释放锁的时候叫你好了 // 如果返回false, 说明当前不需要被挂起，为什么呢？往后看 // 跳回到前面是这个方法 // if (shouldParkAfterFailedAcquire(p, node) && // parkAndCheckInterrupt()) // interrupted = true; // 1. 如果shouldParkAfterFailedAcquire(p, node)返回true， // 那么需要执行parkAndCheckInterrupt(): // 这个方法很简单，因为前面返回true，所以需要挂起线程，这个方法就是负责挂起线程的 // 这里用了LockSupport.park(this)来挂起线程，然后就停在这里了，等待被唤醒======= private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); } // 2. 接下来说说如果shouldParkAfterFailedAcquire(p, node)返回false的情况 // 仔细看shouldParkAfterFailedAcquire(p, node)，我们可以发现，其实第一次进来的时候，一般都不会返回true的，原因很简单，前驱节点的waitStatus=-1是依赖于后继节点设置的。也就是说，我都还没给前驱设置-1呢，怎么可能是true呢，但是要看到，这个方法是套在循环里的，所以第二次进来的时候状态就是-1了。 // 解释下为什么shouldParkAfterFailedAcquire(p, node)返回false的时候不直接挂起线程： // => 是为了应对在经过这个方法后，node已经是head的直接后继节点了。剩下的读者自己想想吧。 } 说到这里，也就明白了，多看几遍 final boolean acquireQueued(final Node node, int arg) 这个方法吧。自己推演下各个分支怎么走，哪种情况下会发生什么，走到哪里。 解锁操作 线程唤醒，正常情况下，如果线程没获取到锁，线程会被LockSupport.park(this)挂起停止，等待被唤醒。 public void unlock() { sync.release(1); } public final boolean release(int arg) { // 往后看吧 if (tryRelease(arg)) { Node h = head; if (h != null && h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } // 回到ReentrantLock看tryRelease方法 protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); // 是否完全释放锁 boolean free = false; // 其实就是重入的问题，如果c==0，也就是说没有嵌套锁了，可以释放了，否则还不能释放掉 if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } /** * Wakes up node's successor, if one exists. * * @param node the node */ // 唤醒后继节点 // 从上面调用处知道，参数node是head头结点 private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; // 如果head节点当前waitStatus 0) { s = null; // 从后往前找，仔细看代码，不必担心中间有节点取消(waitStatus==1)的情况 for (Node t = tail; t != null && t != node; t = t.prev) if (t.waitStatus 唤醒waitStatus private final boolean parkAndCheckInterrupt() { LockSupport.park(this); // 刚刚线程被挂起在这里了 return Thread.interrupted(); } // 又回到这个方法了：acquireQueued(final Node node, int arg)，这个时候，node的前驱是head了 总结 并发环境下，加锁和解锁需要三个部件的协调： 锁状态state。它为0时代表没有线程占有锁，可以去争抢这个锁，用CAS将state设为1，如果CAS成功，说明抢到锁了，那么其他线程就抢不到了，锁重入的话，state需要+1，解锁就是减1，直到state又变为0，代表释放锁，所以lock()和unlock()方法必须配对。然后唤醒等待队列中的第一个线程，让其占有锁。 线程的阻塞和接触阻塞。AQS中采用了LockSupport.park(thread)来挂起线程，用unpark来唤起线程。 阻塞队列。没有抢到锁的线程要等待，放到一个queue中，AQS用的是一个FIFO队列。AQS采用了CLH锁的变体来实现。 示例图解析 首先，第一个线程调用 reentrantLock.lock()，翻到最前面可以发现，tryAcquire(1) 直接就返回 true 了，结束。只是设置了 state=1，连 head 都没有初始化，更谈不上什么阻塞队列了。要是线程 1 调用 unlock() 了，才有线程 2 来，那世界就太太太平了，完全没有交集嘛，那我还要 AQS 干嘛。 如果线程 1 没有调用 unlock() 之前，线程 2 调用了 lock(), 想想会发生什么？ 线程 2 会初始化 head【new Node()】，同时线程 2 也会插入到阻塞队列并挂起 (注意看这里是一个 for 循环，而且设置 head 和 tail 的部分是不 return 的，只有入队成功才会跳出循环) private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 首先，是线程 2 初始化 head 节点，此时 head==tail, waitStatus==0 然后线程 2 入队： 同时我们也要看此时节点的 waitStatus，我们知道 head 节点是线程 2 初始化的，此时的 waitStatus 没有设置， java 默认会设置为 0，但是到 shouldParkAfterFailedAcquire 这个方法的时候，线程 2 会把前驱节点，也就是 head 的waitStatus设置为 -1。 那线程 2 节点此时的 waitStatus 是多少呢，由于没有设置，所以是 0； 如果线程 3 此时再进来，直接插到线程 2 的后面就可以了，此时线程 3 的 waitStatus 是 0，到 shouldParkAfterFailedAcquire 方法的时候把前驱节点线程 2 的 waitStatus 设置为 -1。 这里可以简单说下 waitStatus 中 SIGNAL(-1) 状态的意思，Doug Lea 注释的是：代表后继节点需要被唤醒。也就是说这个 waitStatus 其实代表的不是自己的状态，而是后继节点的状态，我们知道，每个 node 在入队的时候，都会把前驱节点的状态改为 SIGNAL，然后阻塞，等待被前驱唤醒。这里涉及的是两个问题：有线程取消了排队、唤醒操作。其实本质是一样的，可以顺着 “waitStatus代表后继节点的状态” 这种思路去看一遍源码。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-21 15:00:26 "},"2-Java 并发/AQS源码解读二.html":{"url":"2-Java 并发/AQS源码解读二.html","title":"AQS源码解读二","keywords":"","body":"本文主要关注： 深入理解ReentrantLock公平锁和非公平锁的区别 深入分析AQS中的ConditionObject 深入理解Java线程中断和InterruptedException异常 一、ReentrantLock中的公平锁和非公平锁 默认用非公平锁，除非在构造方法中传入参数true。 public ReentrantLock() { // 默认非公平锁 sync = new NonfairSync(); } public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 公平锁的lock()方法： static final class FairSync extends Sync { final void lock() { acquire(1); // 注意这里调用的是AQS类里面的acquire()方法，在acquire()方法中又调用了tryAcquire()方法，但是在ReentrantLock类中两个内部类FairSync, NonFairSync分别对tryAcquire(arg)方法进行了重写。 } // AbstractQueuedSynchronizer.acquire(int arg) public final void acquire(int arg) { if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 1. 和非公平锁相比，这里多了一个判断：是否有线程在等待 if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc 非公平锁的lock()方法： static final class NonfairSync extends Sync { final void lock() { // 2. 和公平锁相比，这里会直接先进行一次CAS，成功就返回了 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } // AbstractQueuedSynchronizer.acquire(int arg) public final void acquire(int arg) { if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); } } /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 这里没有对阻塞队列进行判断 if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc 总结：非公平锁相比公平锁就两处不同： 非公平锁执行lock()方法会先调用一次CAS操作进行一次抢锁，如果恰巧锁没被占用，那么直接就获取到锁并返回。 非公平锁如果在1中的CAS操作失败了，那么和公平锁一样也会进入tryAcquire()方法，在tryAcquire()方法中，如果发现这时候锁被释放了（state==0），非公平锁直接CAS抢锁，公平锁的话会判断等待队列中是否有线程处于等待状态，有的话不会去抢锁，而是排在队列最后。 非公平锁就多了两次CAS操作，如果两次CAS都不成功，那么后面就和公平锁是一样的，都要进入阻塞队列等待唤醒。非公平锁一般来说性能更好，因为其吞吐量大。但是非公平锁获取锁的时间不稳定，可能导致阻塞队列中线程处于长期饥饿状态。 二、Condition 为什么要用condition？？？ 通过condition能够更加精细的控制多线程的休眠与唤醒。 对于一个锁，我们可以为多个线程间建立不同的condition。 如果采用Object类中的wait(), notify(), notifyAll()实现的话，当写入数据之后需要唤醒读线程时，不可能通过notify()或notifyAll()明确的指定唤醒读线程，而只能通过notifyAll唤醒所有线程，但是notifyAll无法区分唤醒的线程是读线程，还是写线程。所以，通过Condition能够更加精细的控制多线程的休眠与唤醒。 Condition的使用场景，用在生产者-消费者的场景中： class BoundBuffer { final Lock lock = new ReentrantLock(); final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putptr, takeptr, count; // 生产 public void put(Object x) throws InterruptedException{ lock.lock(); // 首先上锁 try { // 保证容器不是满的 while (count == items.length) { notFull.await(); // 队列满的话，等待，直到not full才能继续生产 } items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); // 生产成功，队列已经不为空了，告诉notEmpty那边可以继续消费了 } finally { lock.unlock(); } } // 消费 public Object take() throws InterruptedException { lock.lock(); try { while (count == 0) { notEmpty.await(); } Object x = items[takeptr]; if (++takeptr == items.length) takeptr = 0; --count; notFull.signal(); return x; } finally { lock.unlock(); } } } 使用condition时必须持有相对应的锁。和Object类中必须持有对象的监视器锁才能执行wait(), notify(), notifyAll()方法类似。 实际中一般不像上面这样，ArrayBlockingQueue(有界阻塞队列，一旦创建容量就固定了)采用这种方式实现了生产者-消费者，可以直接用。 我们也可以用obj.wait(), obj.notify(), obj.notifyAll() 来实现类似的功能，但是用这些是基于对象的监视器锁的。而用Condition是基于ReentrantLock实现的，ReentrantLock是基于AQS实现的。 强调：condition是依赖于ReentrantLock的，所以不管是调用condition的await进入等待还是signal唤醒，都必须先获取到锁。 ReentrantLock实例可以通过多次调用newCondition方法产生多个ConditionObject的实例： final ConditionObject newCondition() { // 实例化一个 ConditionObject return new ConditionObject(); } Condition的实现类其实就是AQS类中的ConditionObject类： public class ConditionObject implements Condition, java.io.Serializable { private static final long serialVersionUID = 1173984872572414699L; // 条件队列的第一个节点 // 不要管这里的关键字 transient，是不参与序列化的意思 private transient Node firstWaiter; // 条件队列的最后一个节点 private transient Node lastWaiter; ...... AQS中的叫阻塞队列，用于保存等待获取锁的线程，这里引入新的一个概念：条件队列 再看一下node的属性： volatile int waitStatus; // 可取值 0、CANCELLED(1)、SIGNAL(-1)、CONDITION(-2)、PROPAGATE(-3) volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; prex和next用于实现阻塞队列的双向链表，条件队列是单向链表，用nextWaiter就可以了。 解释一下上图： 条件队列和阻塞队列都是Node类节点，因为条件队列的节点是需要转移到阻塞队列中去的。 ReentrantLock的实例可以通过多次调用newCondition()得到多个condition实例，比如这里的condition1，condition2，注意ConditionObject就只有firstWaiter和lastWaiter两个属性。 每个condition就有一个与之关联的条件队列，比如线程1调用condition1.await()就会把当前线程1包装成Node后加入到条件队列中，然后阻塞在这里。 调用condition1.signal()会触发一次唤醒，此时唤醒的是队头，会将condition1对应的条件队列的firstWaiter(队头)移到阻塞队列的队尾，等待获取锁，获取到锁之后await方法才能返回，继续往下执行。 这里2->3->4是最简单的路程，没有考虑中断、signalAll、带超时参数的awai方法。接下来看下条件队列的awai方法： 线程等待awit() // 首先，这个方法是可被中断的，不可被中断的是另一个方法 awaitUninterruptibly() // 这个方法会阻塞，直到调用 signal 方法（指 signal() 和 signalAll()，下同），或被中断 public final void await() throws InterruptedException { // 老规矩，既然该方法要响应中断，那么在最开始就判断中断状态 if (Thread.interrupted()) throw new InterruptedException(); // 添加到 condition 的条件队列中 Node node = addConditionWaiter(); // 释放锁，返回值是释放锁之前的 state 值 // await() 之前，当前线程是必须持有锁的，这里肯定要释放掉 int savedState = fullyRelease(node); int interruptMode = 0; // 这里退出循环有两种情况，之后再仔细分析 // 1. isOnSyncQueue(node) 返回 true，即当前 node 已经转移到阻塞队列了 // 2. checkInterruptWhileWaiting(node) != 0 会到 break，然后退出循环，代表的是线程中断 while (!isOnSyncQueue(node)) { LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 被唤醒后，将进入阻塞队列，等待获取锁 if (acquireQueued(node, savedState) && interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); } 下面具体介绍一下await()方法 1. 将节点加入到条件队列 addConditionWaiter() 是将当前节点加入到条件队列，看图我们知道，这种条件队列内的操作是线程安全的。尽管此处没有任何线程安全的保护，但实际使用时不会出现任何线程安全问题——因为条件队列的使用要求我们在调用await或signal时持有与该条件队列唯一相关的锁。 ReentrantLock和ConditionObject在实现上的区别： ReentrantLock创建的节点初始状态是0；ConditionObject创建的节点初始状态为CONDITION==-2 ReentrantLock使用的是AQS内置的等待队列，由AQS维护；而每个ConditionObject都维护自己的等待队列。 java.util.concurrent.locks.Condition和java.util.concurrent.locks.lock一样，是一个接口，在AQS抽象类中有内部类ConditionObject，这个内部类实现了Conditin接口；而ReentrantLock中有下面方法可以获取ConditionObject对象。 public Condition newCondition() { return sync.newCondition(); } 说回addConditionWaiter()方法： // 将当前线程对应的节点入队，插入队尾 private Node addConditionWaiter() { Node t = lastWaiter; // 如果条件队列的最后一个节点取消了，将其清除出去 // 为什么这里把 waitStatus 不等于 Node.CONDITION，就判定为该节点发生了取消排队？ if (t != null && t.waitStatus != Node.CONDITION) { // 这个方法会遍历整个条件队列，然后会将已取消的所有节点清除出队列 unlinkCancelledWaiters(); t = lastWaiter; } // node 在初始化的时候，指定 waitStatus 为 Node.CONDITION Node node = new Node(Thread.currentThread(), Node.CONDITION); // t 此时是 lastWaiter，队尾 // 如果队列为空 if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; } 当发现lastWaiter指向的节点的waitStatus不等于Node.CONDITION，就认为该节点取消了排队（因为在条件队列中的每个节点在初始化时都会指定waitStatus为Node.CONDITION）,则调用unlinkCancelledWaiters()方法清除队列中所有已经取消等待的节点。 当 await 的时候如果发生了取消操作（这点之后会说），或者是在节点入队的时候，发现最后一个节点是被取消的，会调用一次这个方法。 private void unlinkCancelledWaiters() { Node t = firstWaiter; Node trail = null; while (t != null) { Node next = t.nextWaiter; // 如果节点的状态不是 Node.CONDITION 的话，这个节点就是被取消的 if (t.waitStatus != Node.CONDITION) { t.nextWaiter = null; if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; } else trail = t; t = next; } } 2.完全释放独占锁 回到wait()方法，节点入队之后，需要调用 int savedState = fullyRelease(node);完全释放锁，因为ReentrantLock是可重入的。 考虑一下这里的 savedState。如果在 condition1.await() 之前，假设线程先执行了 2 次 lock() 操作，那么 state 为 2，我们理解为该线程持有 2 把锁，这里 await() 方法必须将 state 设置为 0，然后再进入挂起状态，这样其他线程才能持有锁。当它被唤醒的时候，它需要重新持有 2 把锁，才能继续下去。 // 首先，我们要先观察到返回值 savedState 代表 release 之前的 state 值 // 对于最简单的操作：先 lock.lock()，然后 condition1.await()。 // 那么 state 经过这个方法由 1 变为 0，锁释放，此方法返回 1 // 相应的，如果 lock 重入了 n 次，savedState == n // 如果这个方法失败，会将节点设置为\"取消\"状态，并抛出异常 IllegalMonitorStateException final int fullyRelease(Node node) { boolean failed = true; try { int savedState = getState(); // 这里使用了当前的 state 作为 release 的参数，也就是完全释放掉锁，将 state 置为 0 if (release(savedState)) { failed = false; return savedState; } else { throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; } } 注意： 考虑一下，如果一个线程在不持有 lock 的基础上，就去调用 condition1.await() 方法，它能进入条件队列，但是在上面的这个方法中，由于它不持有锁，release(savedState) 这个方法肯定要返回 false，进入到异常分支，然后进入 finally 块设置 node.waitStatus = Node.CANCELLED，这个已经入队的节点之后会被后继的节点”请出去“。 3. 等待进入阻塞队列 释放掉锁以后，接下来是这段，这边会自旋，如果发现自己还没到阻塞队列，那么挂起，等待被转移到阻塞队列。 int interruptMode = 0; // 如果不在阻塞队列中，注意了，是阻塞队列 while (!isOnSyncQueue(node)) { // 线程挂起 LockSupport.park(this); // 这里可以先不用看了，等看到它什么时候被 unpark 再说 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } isOnSyncQueue(Node node) 用于判断节点是否已经转移到阻塞队列了： // 在节点入条件队列的时候，初始化时设置了 waitStatus = Node.CONDITION // 前面我提到，signal 的时候需要将节点从条件队列移到阻塞队列， // 这个方法就是判断 node 是否已经移动到阻塞队列了 final boolean isOnSyncQueue(Node node) { // 移动过去的时候，node 的 waitStatus 会置为 0，这个之后在说 signal 方法的时候会说到 // 如果 waitStatus 还是 Node.CONDITION，也就是 -2，那肯定就是还在条件队列中 // 如果 node 的前驱 prev 指向还是 null，说明肯定没有在 阻塞队列(prev是阻塞队列链表中使用的) if (node.waitStatus == Node.CONDITION || node.prev == null) return false; // 如果 node 已经有后继节点 next 的时候，那肯定是在阻塞队列了 if (node.next != null) return true; // 下面这个方法从阻塞队列的队尾开始从后往前遍历找，如果找到相等的，说明在阻塞队列，否则就是不在阻塞队列 // 可以通过判断 node.prev() != null 来推断出 node 在阻塞队列吗？答案是：不能。 // 这个可以看上篇 AQS 的入队方法，首先设置的是 node.prev 指向 tail， // 然后是 CAS 操作将自己设置为新的 tail，可是这次的 CAS 是可能失败的。 return findNodeFromTail(node); } // 从阻塞队列的队尾往前遍历，如果找到，返回 true private boolean findNodeFromTail(Node node) { Node t = tail; for (;;) { if (t == node) return true; if (t == null) return false; t = t.prev; } } 回到前面的循环，isOnSyncQueue(node) 返回 false 的话，那么进到 LockSupport.park(this); 这里线程挂起。 4. signal唤醒线程，转移到阻塞队列 刚刚到LockSupport.park(this);把线程挂起了，等待唤醒。 唤醒操作通常由另一个线程来操作，就像生产者-消费者模式中，如果线程因为等待消费而挂起，那么当生产者生产了一个东西后，会调用 signal 唤醒正在等待的线程来消费。 // 唤醒等待了最久的线程 // 其实就是，将这个线程对应的 node 从条件队列转移到阻塞队列 public final void signal() { // 调用 signal 方法的线程必须持有当前的独占锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); } // 从条件队列队头往后遍历，找出第一个需要转移的 node // 因为前面我们说过，有些线程会取消排队，但是可能还在队列中 private void doSignal(Node first) { do { // 将 firstWaiter 指向 first 节点后面的第一个，因为 first 节点马上要离开了 // 如果将 first 移除后，后面没有节点在等待了，那么需要将 lastWaiter 置为 null if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 因为 first 马上要被移到阻塞队列了，和条件队列的链接关系在这里断掉 first.nextWaiter = null; } while (!transferForSignal(first) && (first = firstWaiter) != null); // 这里 while 循环，如果 first 转移不成功，那么选择 first 后面的第一个节点进行转移，依此类推 } // 将节点从条件队列转移到阻塞队列 // true 代表成功转移 // false 代表在 signal 之前，节点已经取消了 final boolean transferForSignal(Node node) { // CAS 如果失败，说明此 node 的 waitStatus 已不是 Node.CONDITION，说明节点已经取消， // 既然已经取消，也就不需要转移了，方法返回，转移后面一个节点 // 否则，将 waitStatus 置为 0 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // enq(node): 自旋进入阻塞队列的队尾 // 注意，这里的返回值 p 是 node 在阻塞队列的前驱节点 Node p = enq(node); int ws = p.waitStatus; // ws > 0 说明 node 在阻塞队列中的前驱节点取消了等待锁，直接唤醒 node 对应的线程。唤醒之后会怎么样，后面再解释 // 如果 ws 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) // 如果前驱节点取消或者 CAS 失败，会进到这里唤醒线程，之后的操作看下一节 LockSupport.unpark(node.thread); return true; } 正常情况下，ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL) 这句中，ws compareAndSetWaitStatus(p, ws, Node.SIGNAL) 会返回 true，所以一般也不会进去 if 语句块中唤醒 node 对应的线程。然后这个方法返回 true，也就意味着 signal 方法结束了，节点进入了阻塞队列。 假设发生了阻塞队列中的前驱节点取消等待，或者 CAS 失败，只要唤醒线程，让其进到下一步即可。 5. 唤醒后检查中断状态 上一步 signal 之后，我们的线程由条件队列转移到了阻塞队列，之后就准备获取锁了。只要重新获取到锁了以后，继续往下执行。 等线程从挂起中恢复过来，继续往下看 int interruptMode = 0; while (!isOnSyncQueue(node)) { // 线程挂起 LockSupport.park(this); // 检查中断状态 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } 先解释下 interruptMode。interruptMode 可以取值为 REINTERRUPT（1），THROW_IE（-1），0 REINTERRUPT： 代表 await 返回的时候，需要重新设置中断状态 THROW_IE： 代表 await 返回的时候，需要抛出 InterruptedException 异常 0 ：说明在 await 期间，没有发生中断 有以下三种情况会让 LockSupport.park(this); 这句返回继续往下执行（也就是取消线程的挂起状态，继续往下执行）： 常规路径。signal -> 转移节点到阻塞队列 -> 获取了锁（unpark） 线程中断。在 park 的时候，另外一个线程对这个线程进行了中断 signal 的时候我们说过，转移以后的前驱节点取消了，或者对前驱节点的CAS操作失败了 假唤醒。这个也是存在的，和 Object.wait() 类似，都有这个问题 假设出现了上面四种里面的一种，那么继续往下执行后第一步就是调用checkInterruptWhileWaiting(node) 这个方法，此方法用于判断是否在线程挂起期间发生了中断，如果发生了中断，是 signal 调用之前中断的，还是 signal 之后发生的中断。 // 1. 如果在 signal 之前已经中断，返回 THROW_IE // 2. 如果是 signal 之后中断，返回 REINTERRUPT // 3. 没有发生中断，返回 0 private int checkInterruptWhileWaiting(Node node) { return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; } Thread.interrupted()：如果当前线程已经处于中断状态，那么该方法返回 true，同时将中断状态重置为 false，所以，才有后续的 重新中断（REINTERRUPT） 的使用。 看看怎么判断是signal之前还是之后发生的中断： // 只有线程处于中断状态，才会调用此方法 // 如果需要的话，将这个已经取消等待的节点转移到阻塞队列 // 返回 true：如果此线程在 signal 之前被取消， final boolean transferAfterCancelledWait(Node node) { // 用 CAS 将节点状态设置为 0 // 如果这步 CAS 成功，说明是 signal 方法之前发生的中断，因为如果 signal 先发生的话，signal 中会将 waitStatus 设置为 0 if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) { // 将节点放入阻塞队列 // 这里我们看到，即使中断了，依然会转移到阻塞队列 enq(node); return true; } // 到这里是因为 CAS 失败，肯定是因为 signal 方法已经将 waitStatus 设置为了 0 // signal 方法会将节点转移到阻塞队列，但是可能还没完成，这边自旋等待其完成 // 当然，这种事情还是比较少的吧：signal 调用之后，没完成转移之前，发生了中断 while (!isOnSyncQueue(node)) Thread.yield(); return false; } 这里再说一遍，即使发生了中断，节点依然会转移到阻塞队列。 到这里，大家应该都知道这个 while 循环怎么退出了吧。要么中断，要么转移成功。 6. 获取独占锁 while循环出来以后，后面是这段代码： if (acquireQueued(node, savedState) && interruptMode != THROW_IE) interruptMode = REINTERRUPT; 由于while循环出来之后，我们已经确定节点已经进入阻塞队列，准备获取锁。 这里的acquireQueued(node, savedState)的第一个参数node之前已经经过enq(node)进入了队列，参数savedState是之前释放锁前的state，这个方法返回的时候，**代表当前线程获取了锁，而且state == savedState了。 前面说过，不管有没有发生中断，节点都会进入阻塞队列，而acquireQueued(node, savedState)的返回值就是代表线程是否被中断。如果返回true，说明被中断了，而且 interruptMode != THROW_IE，说明在 signal 之前就发生中断了，这里将 interruptMode 设置为 REINTERRUPT，用于待会重新中断。 继续往下： if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); 本着一丝不苟的精神，这边说说 node.nextWaiter != null 怎么满足。我前面也说了 signal 的时候会将节点转移到阻塞队列，有一步是 node.nextWaiter = null，将断开节点和条件队列的联系。 可是，在判断发生中断的情况下，是 signal 之前还是之后发生的？ 这部分的时候，我也介绍了，如果 signal 之前就中断了，也需要将节点进行转移到阻塞队列，这部分转移的时候，是没有设置 node.nextWaiter = null 的。 之前我们说过，如果有节点取消，也会调用 unlinkCancelledWaiters 这个方法，就是这里了。 7. 处理中断状态 到这里，我们终于可以好好说下这个 interruptMode 干嘛用了。 0：什么都不做，没有被中断过； THROW_IE：await 方法抛出 InterruptedException 异常，因为它代表在 await() 期间发生了中断； REINTERRUPT：重新中断当前线程，因为它代表 await() 期间没有被中断，而是 signal() 以后发生的中断 private void reportInterruptAfterWait(int interruptMode) throws InterruptedException { if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt(); } * 带超时机制的 await 经过前面的 7 步，整个 ConditionObject 类基本上都分析完了，接下来简单分析下带超时机制的 await 方法。 public final long awaitNanos(long nanosTimeout) throws InterruptedException public final boolean awaitUntil(Date deadline) throws InterruptedException public final boolean await(long time, TimeUnit unit) throws InterruptedException public final boolean await(long time, TimeUnit unit) throws InterruptedException { // 等待这么多纳秒 long nanosTimeout = unit.toNanos(time); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); // 当前时间 + 等待时长 = 过期时间 final long deadline = System.nanoTime() + nanosTimeout; // 用于返回 await 是否超时 boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) { // 时间到啦 if (nanosTimeout = spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; // 得到剩余时间 nanosTimeout = deadline - System.nanoTime(); } if (acquireQueued(node, savedState) && interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; } 不带超时参数的 await 是 park，然后等待别人唤醒。而现在就是调用 parkNanos 方法来休眠指定的时间，醒来后判断是否 signal 调用了，调用了就是没有超时，否则就是超时了。超时的话，自己来进行转移到阻塞队列，然后抢锁。 * 不抛出 InterruptedException 的 await public final void awaitUninterruptibly() { Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean interrupted = false; while (!isOnSyncQueue(node)) { LockSupport.park(this); if (Thread.interrupted()) interrupted = true; } if (acquireQueued(node, savedState) || interrupted) selfInterrupt(); } AbstractQueuedSynchronizer 独占锁的取消排队 怎么取消对锁的竞争？主要看下面这个方法： final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head && tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 首先到这个方法的时候，节点一定是入队成功的。 我把 parkAndCheckInterrupt() 代码贴过来： private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); } 这两段代码联系起来看，是不是就清楚了。 如果我们要取消一个线程的排队，我们需要在另外一个线程中对其进行中断。比如某线程调用lock()很久不返回，我想中断它。一旦对其进行中断，此线程会从 LockSupport.park(this); 中唤醒，然后 Thread.interrupted(); 返回 true。 我们发现一个问题，即使是中断唤醒了这个线程，也就只是设置了 interrupted = true 然后继续下一次循环。而且，由于 Thread.interrupted(); 会清除中断状态，第二次进 parkAndCheckInterrupt 的时候，返回会是 false。 所以，我们要看到，在这个方法中，interrupted 只是用来记录是否发生了中断，然后用于方法返回值，其他没有做任何相关事情。 所以，我们看外层方法怎么处理 acquireQueued 返回 false 的情况。 public final void acquire(int arg) { if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } static void selfInterrupt() { Thread.currentThread().interrupt(); } 所以说，lock() 方法处理中断的方法就是，你中断归中断，我抢锁还是照样抢锁，几乎没关系，只是我抢到锁了以后，设置线程的中断状态而已，也不抛出任何异常出来。调用者获取锁后，可以去检查是否发生过中断，也可以不理会。 来条分割线。有没有被骗的感觉，我说了一大堆，可是和取消没有任何关系啊。 我们来看 ReentrantLock 的另一个 lock 方法： public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } 方法上多了个 throws InterruptedException ，经过前面那么多知识的铺垫，这里我就不再啰里啰嗦了。 public final void acquireInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); } 继续往里： private void doAcquireInterruptibly(int arg) throws InterruptedException { final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head && tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return; } if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) // 就是这里了，一旦异常，马上结束这个方法，抛出异常。 // 这里不再只是标记这个方法的返回值代表中断状态 // 而是直接抛出异常，而且外层也不捕获，一直往外抛到 lockInterruptibly throw new InterruptedException(); } } finally { // 如果通过 InterruptedException 异常出去，那么 failed 就是 true 了 if (failed) cancelAcquire(node); } } 既然到这里了，顺便说说 cancelAcquire 这个方法吧： private void cancelAcquire(Node node) { // Ignore if node doesn't exist if (node == null) return; node.thread = null; // Skip cancelled predecessors // 找一个合适的前驱。其实就是将它前面的队列中已经取消的节点都”请出去“ Node pred = node.prev; while (pred.waitStatus > 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. if (node == tail && compareAndSetTail(node, pred)) { compareAndSetNext(pred, predNext, null); } else { // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; if (pred != head && ((ws = pred.waitStatus) == Node.SIGNAL || (ws 其实这个方法没什么好说的，一行行看下去就是了，节点取消，只要把 waitStatus 设置为 Node.CANCELLED，会有非常多的情况被从阻塞队列中请出去，主动或被动。 三、再说 java 线程中断和 InterruptedException 异常 中断并不是像Linux里面kill -p pid杀死某个进程，不是说中断某个线程，这个线程就停止运行了。中断代表线程状态，是一个boolean值，默认false； 注意：Java线程中的中断和操作系统的中断还不一样，Java的中断是代表这个线程的一个状态，不要和操作系统的中断联系在一起。 关于中断状态，我们需要重点关注 Thread 类中的以下几个方法： // Thread 类中的实例方法，持有线程实例引用即可检测线程中断状态 public boolean isInterrupted() {} // Thread 中的静态方法，检测调用这个方法的线程是否已经中断 // 注意：这个方法返回中断状态的同时，会将此线程的中断状态重置为 false // 所以，如果我们连续调用两次这个方法的话，第二次的返回值肯定就是 false 了 public static boolean interrupted() {} // Thread 类中的实例方法，用于设置一个线程的中断状态为 true public void interrupt() {} 我们说中断一个线程，其实就是设置了线程的 interrupted status 为 true，至于说被中断的线程怎么处理这个状态，那是那个线程自己的事。如以下代码： while (!Thread.interrupted()) { doWork(); System.out.println(\"我做完一件事了，准备做下一件，如果没有其他线程中断我的话\"); } 当然，中断除了是线程状态外，还有其他含义，否则也不需要专门搞一个这个概念出来了。 如果线程处于以下三种情况，那么当线程被中断的时候，能自动感知到： 来自 Object 类的 wait()、wait(long)、wait(long, int)， 来自 Thread 类的 join()、join(long)、join(long, int)、sleep(long)、sleep(long, int) 这几个方法的相同之处是，方法上都有: throws InterruptedException 如果线程阻塞在这些方法上（我们知道，这些方法会让当前线程阻塞），这个时候如果其他线程对这个线程进行了中断，那么这个线程会从这些方法中立即返回，抛出 InterruptedException 异常，同时重置中断状态为 false。 实现了 InterruptibleChannel 接口的类中的一些 I/O 阻塞操作，如 DatagramChannel 中的 connect 方法和 receive 方法等 如果线程阻塞在这里，中断线程会导致这些方法抛出 ClosedByInterruptException 并重置中断状态。 Selector 中的 select 方法，参考下我写的 NIO 的文章 一旦中断，方法立即返回 对于以上 3 种情况是最特殊的，因为他们能自动感知到中断（这里说自动，当然也是基于底层实现），并且在做出相应的操作后都会重置中断状态为 false。 那是不是只有以上 3 种方法能自动感知到中断呢？不是的，如果线程阻塞在 LockSupport.park(Object obj) 方法，也叫挂起，这个时候的中断也会导致线程唤醒，但是唤醒后不会重置中断状态，所以唤醒后去检测中断状态将是 true。 InterruptedException 概述 它是一个特殊的异常，不是说 JVM 对其有特殊的处理，而是它的使用场景比较特殊。通常，我们可以看到，像 Object 中的 wait() 方法，ReentrantLock 中的 lockInterruptibly() 方法，Thread 中的 sleep() 方法等等，这些方法都带有 throws InterruptedException，我们通常称这些方法为阻塞方法（blocking method）。 阻塞方法一个很明显的特征是，它们需要花费比较长的时间（不是绝对的，只是说明时间不可控），还有它们的方法结束返回往往依赖于外部条件，如 wait 方法依赖于其他线程的 notify，lock 方法依赖于其他线程的 unlock等等。 当我们看到方法上带有 throws InterruptedException 时，我们就要知道，这个方法应该是阻塞方法，我们如果希望它能早点返回的话，我们往往可以通过中断来实现。 除了几个特殊类（如 Object，Thread等）外，感知中断并提前返回是通过轮询中断状态来实现的。我们自己需要写可中断的方法的时候，就是通过在合适的时机（通常在循环的开始处）去判断线程的中断状态，然后做相应的操作（通常是方法直接返回或者抛出异常）。当然，我们也要看到，如果我们一次循环花的时间比较长的话，那么就需要比较长的时间才能感知到线程中断了 处理中断 一旦中断发生，我们接收到了这个信息，然后怎么去处理中断呢？本小节将简单分析这个问题。 我们经常会这么写代码： try { Thread.sleep(10000); } catch (InterruptedException e) { // ignore } // go on 当 sleep 结束继续往下执行的时候，我们往往都不知道这块代码是真的 sleep 了 10 秒，还是只休眠了 1 秒就被中断了。这个代码的问题在于，我们将这个异常信息吞掉了。（对于 sleep 方法，我相信大部分情况下，我们都不在意是否是中断了，这里是举例） AQS 的做法很值得我们借鉴，我们知道 ReentrantLock 有两种 lock 方法： public void lock() { sync.lock(); } public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } 前面我们提到过，lock() 方法不响应中断。如果 thread1 调用了 lock() 方法，过了很久还没抢到锁，这个时候 thread2 对其进行了中断，thread1 是不响应这个请求的，它会继续抢锁，当然它不会把“被中断”这个信息扔掉。我们可以看以下代码： public final void acquire(int arg) { if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 我们看到，这里也没做任何特殊处理，就是记录下来中断状态。 // 这样，如果外层方法需要去检测的时候，至少我们没有把这个信息丢了 selfInterrupt();// Thread.currentThread().interrupt(); } 而对于 lockInterruptibly() 方法，因为其方法上面有 throws InterruptedException ，这个信号告诉我们，如果我们要取消线程抢锁，直接中断这个线程即可，它会立即返回，抛出 InterruptedException 异常。 在并发包中，有非常多的这种处理中断的例子，提供两个方法，分别为响应中断和不响应中断，对于不响应中断的方法，记录中断而不是丢失这个信息。如 Condition 中的两个方法就是这样的： void await() throws InterruptedException; void awaitUninterruptibly(); 通常，如果方法会抛出 InterruptedException 异常，往往方法体的第一句就是： public final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); ...... } Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-09 16:00:38 "},"2-Java 并发/Java中Thread类的中断状态.html":{"url":"2-Java 并发/Java中Thread类的中断状态.html","title":"Java中Thread类的中断状态","keywords":"","body":"Java中断 Java中取消一个任务最好的、最合理的办法就是用中断，Java中并没有直接停止一个线程的方法，中断也只是修改线程的中断状态或者抛出一个InterruptException异常，仅此而已，只是向线程发出一个通知，至于采取什么措施要看线程自己如何响应。 Interrupt status, InterruptedException Java的中断机制能够使被中断的线程有机会从当前任务中跳脱出来，中断机制最核心的两个概念就是：Interrupt status, InterruptedException。 Java中对中断的大部分操作无外乎： 设置或者清除中断标志位 抛出InterruptException 1. 关于Interrupt status Java中每个线程都有一个中断标志位，表示当前线程是否被中断，boolean类型变量，中断时将其设置为true，清除中断时设置为false。但是在Thread类中并没有InterruptStatus这个属性，只是提供了访问中断标志位的接口： /** * Tests if some Thread has been interrupted. The interrupted state * is reset or not based on the value of ClearInterrupted that is * passed. */ private native boolean isInterrupted(boolean ClearInterrupted); 先返回当前线程中断状态，然后根据参数来判断是否要重置中断状态。 isInterrupted()：调用native方法isInterrupted(false)，返回线程状态 interrupted()：这是一个静态方法，调用native方法isInterrupted(true)，返回当前线程状态然后重置线程状态为false interrupt()：调用interrupt0()，只是将线程状态改为true 可见，isInterrupted() 和 interrupted() 方法只涉及到中断状态的查询，最多是多加一步重置中断状态，并不牵涉到InterruptedException。 不过值得一提的是，在我们能使用到的public方法中，interrupted()是我们清除中断的唯一方法。 2. 关于InterruptException 如果有其他方法直接或间接的调用了这两个方法，那他们自然也会在线程被中断的时候抛出InterruptedException，并且清除中断状态。例如: wait() wait(long timeout, int nanos) sleep(long millis, int nanos) join() join(long millis) join(long millis, int nanos) 这里值得注意的是，虽然这些方法会抛出InterruptedException，但是并不会终止当前线程的执行，当前线程可以选择忽略这个异常。 也就是说，无论是设置interrupt status 还是抛出InterruptedException，它们都是给当前线程的建议，当前线程可以选择采纳或者不采纳，它们并不会影响当前线程的执行。 至于在收到这些中断的建议后，当前线程要怎么处理，也完全取决于当前线程。 interrupt /** * Interrupts this thread. * * Unless the current thread is interrupting itself, which is * always permitted, the {@link #checkAccess() checkAccess} method * of this thread is invoked, which may cause a {@link * SecurityException} to be thrown. * * If this thread is blocked in an invocation of the {@link * Object#wait() wait()}, {@link Object#wait(long) wait(long)}, or {@link * Object#wait(long, int) wait(long, int)} methods of the {@link Object} * class, or of the {@link #join()}, {@link #join(long)}, {@link * #join(long, int)}, {@link #sleep(long)}, or {@link #sleep(long, int)}, * methods of this class, then its interrupt status will be cleared and it * will receive an {@link InterruptedException}. * * If this thread is blocked in an I/O operation upon an {@link * java.nio.channels.InterruptibleChannel InterruptibleChannel} * then the channel will be closed, the thread's interrupt * status will be set, and the thread will receive a {@link * java.nio.channels.ClosedByInterruptException}. * * If this thread is blocked in a {@link java.nio.channels.Selector} * then the thread's interrupt status will be set and it will return * immediately from the selection operation, possibly with a non-zero * value, just as if the selector's {@link * java.nio.channels.Selector#wakeup wakeup} method were invoked. * * If none of the previous conditions hold then this thread's interrupt * status will be set. * * Interrupting a thread that is not alive need not have any effect. * * @throws SecurityException * if the current thread cannot modify this thread * * @revised 6.0 * @spec JSR-51 */ public void interrupt() { if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) { Interruptible b = blocker; if (b != null) { interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; } } interrupt0(); } 线程可以自己中断自己（不需要检查权限），也可以在一个线程中中断另外一个线程的执行，需要通过checkAccess()检查权限，有可能抛出SecurityException异常。 如果当前线程由于如下方法处于阻塞当中，调用interrupt方法后，线程的中断标志会被清除，并且收到InterruptException异常。 Object的方法 wait() wait(long) wait(long, int) Thread的方法 join() join(long) join(long, int) sleep(long) sleep(long, int) wait, join, sleep方法在定义的时候都能捕捉InterruptException。 如果线程没有因为上面的函数调用而进入阻塞状态的话，那么中断这个线程interrupt仅仅会设置它的中断标志位，不抛出异常。还有就是：中断一个已经终止的线程没有任何影响。 总结：所谓中断线程，并不是让线程停止运行，而仅仅是让线程的中断标志设为true，或者在某些特定情况下抛出一个InterruptedException。 学习来源 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-06-08 11:07:06 "},"2-Java 并发/Java中Thread类的基本方法及六种线程状态.html":{"url":"2-Java 并发/Java中Thread类的基本方法及六种线程状态.html","title":"Java中Thread类的基本方法及六种线程状态","keywords":"","body":"一、Java线程类Thread 1.1 Java线程和os线程关系 一个Java线程会对应一个操作系统线程。操作系统实现线程有三种方式 具体看这里： 内核线程实现 用户线程实现 用户线程加轻量级进程混合实现 Java线程在JDK1.2之前，是基于称为“绿色线程”（Green Threads）的用户线程实现的，而在JDK1.2中，线程模型替换为基于操作系统原生线程模型来实现。 JDK1.2之前，程序员们为JVM开发了自己的一个线程调度内核，而到操作系统层面就是用户空间内的线程实现。而到了JDK1.2及以后，JVM选择了更加稳健且方便使用的操作系统原生的线程模型，通过系统调用，将程序的线程交给了操作系统内核进行调度。 也就是说，现在的Java中线程的本质，其实就是操作系统中的线程，Linux下是基于pthread库实现的轻量级进程，Windows下是原生的系统Win32 API提供系统调用从而实现多线程。 1.2 Java线程类Thread中六种线程状态 调用某个方法后所对应的threadState值（注意这里按照jdk源码中Thread类的六种状态为准） 几种状态之间的转换 NEW, RUNNABLE, WAITING, BLOCKED, TIMED_WAITING, TERMINATED 除去NEW和TERMINATED， Java线程状态RUNNABLE ：操作系统线程的ready和running状态 Java线程WAITING, BLOCKED, TIMED_WAITING ：操作系统线程的waiting 由于不同的操作系统在线程的设计上存在差异，所以JVM在设计上就已经声明：虚拟机中的线程状态，不反应任何操作系统线程状态。 JVM线程： 操作系统线程： 其中阻塞和等待的区别（阻塞就是JVM去调度恢复，等待则是让另外一个线程去发出信号恢复执行） 阻塞 阻塞是尝试进入synchronized块，也就是尝试去获取对象锁，但是该锁被其它线程持有了，那么这个线程就会进入阻塞状态。处于阻塞状态的线程由JVM调度器来决定是否唤醒，不需要由另外一个线程来显式唤醒，不会响应中断。 等待 指的是当一个线程需要等待另一个线程发出信号从而进入可执行状态时，这个时候就是等待状态，等待状态可以响应中断，例如调用：Object.wait(), Thread.join()及等待Lock或者Condition。 需要注意虽然synchronized和JUC里的Lock都实现锁的功能，但线程进入的状态不一样。synchronized会让线程进入阻塞态，而JUC里的Lock是用LockSupport.park()/unpark()来实现阻塞/唤醒的，会让线程进入等待态。 而LockSupport的park和unpark实际调用的是Unsafe类中native方法park, unpark()，与Object类的wait，notify机制相比，park和unpark的两个优点： 它是以thread为操作对象，更加符合阻塞线程的直观定义，不像Object.wait()是通过一个锁资源来表示线程阻塞。 操作更精确，park可以准确唤醒具体某个线程，notify是随机唤醒一个线程。 理解park：关于“许可” 其实park, unpark的设计原理核心是“许可”：park是让线程等待一个许可，而unpark是为线程提供一个许可。 如果LockSupport.park(), 那么除非另外一个线程中调用LockSupport.unpark(threadA)，否则A将阻塞在park操作上（注意这里的threadState是waiting）。 先unpark再park也是可以的 先unpark说明先给了许可，再park就会消费这个许可，然后还可以继续执行。（但是许可不能叠加） Unsafe.park和Unsafe.unpark的底层实现原理 在Linux系统下，是用的Posix线程库pthread中的mutex（互斥量），condition（条件变量）来实现的。 mutex和condition保护了一个_counter的变量，当park时，这个变量被设置为0，当unpark时，这个变量被设置为1。 1.3 Java线程类Thread中常用方法 1. sleep() 这是一个native方法 Causes the currently executing thread to sleep The thread does not lose ownership of any monitors. Thread.sleep() 与 Thread.currentThread().sleep() 有什么区别 没区别，执行效果一样的。一个用类调用静态方法，一个用实例调用静态方法。 sleep函数会让当前函数让出CPU，但是，当前线程仍然持有它所获得的监视器锁，这与同时让出CPU资源和监视器锁资源的wait方法不一样。 对比一下obj.wait()方法：obj.wait()会调用wait(0)这个native方法，其实wait(long timeout, int nanos)和sleep(long millis, int nanos)在实现等待时间上很相似，但是底层分别调用native方法wait(timeout)和sleep(millis)是不一样的。 2. yield()方法 也是native方法 A hint to the scheduler that the current thread is willing to yield its current use of a processor. The scheduler is free to ignore this hint. yield不会让线程退出RUNNABLE状态，最多从running变成ready，但是sleep(millis)会把线程状态转成TIMED_WAITING。 这只是给CPU一个建议说当前线程愿意让出CPU给其它线程，CPU采不采纳取决于不同厂商，可能刚yield让出CPU然后又立马抢夺到CPU。但是sleep一定会让出CPU，并且休眠指定时间不参与CPU竞争。 3. join()方法 方法介绍（sleep, join方法的理解） Waits at most {@code millis} milliseconds for this thread to die. A timeout of {@code 0} means to wait forever. join底层用的是wait方法实现等待，而wait方法一定得先拿到监视器锁，可以发现join是synchronized方法，而且它是非静态的，所以这里的锁是子线程实例的监视器锁。 同时在主线程中会调用isAlive()方法检查子线程是否还存活（注意isAlive是子线程的方法）。如果还子线程还存活，则主线程会执行wait(0)让出监视器锁，进入WAITING状态；然后主线程需要等待子线程的notify才能从wait位置继续执行，注意：**当子线程m yThread停止执行时，会调用this.notifyAll，所以子线程结束，主线程会拿到子线程实例对象的监视器锁，继续往下执行。 学习来源 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-30 10:46:38 "},"2-Java 并发/Java线程上下文切换.html":{"url":"2-Java 并发/Java线程上下文切换.html","title":"Java线程上下文切换","keywords":"","body":"Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-27 17:11:56 "},"2-Java 并发/Java线程中的wait、notify、中断等知识.html":{"url":"2-Java 并发/Java线程中的wait、notify、中断等知识.html","title":"Java线程中的Wait、Notify、中断等知识","keywords":"","body":"参考来源：Threads and locks 每一个Java对象都关联了一个监视器，也关联了一个等待集合，等待集合中的节点都是一个个线程。 向等待集合中添加或者移除线程的操作都是原子的，有哪些操作可以对这个等待集合进行修改呢？如下： Object.wait, Object.notify, Object.notifyAll 等待集合可能受到线程的中断状态的影响，也会受到线程中处理中断的方法的影响。 下面讲解Java线程相关知识： Thread中的sleep, join, interrupt 继承自Object的wait, notify, notifyAll Java中断 一、wait等待, notify通知, interruptions中断 1. 等待wait 方法：wait(), wait(long millisecs), wait(long millisecs, int nanosecs)。如果调用wait方法时没有抛出InterruptedException异常，则表示正常返回。 在线程t中对对象m调用m.wait()方法，n代表加锁编号，同时还没有相匹配的解锁操作，则会发生下面其中之一： 如果n等于0（线程t没有持有m对象的锁），会抛出IllegalMonitorStateException异常。wait或者notify操作必须先要获取到监视器锁才能执行，所以这两个方法必须在同步块中调用，否则会抛出IllegalMonitorStateException异常。 如果调用wait(long millisecs)或者 wait(long millisecs, int nanosecs)，millisecs不能为负数，millisecs要在[0, 999999]，否则抛出IllegalArgumentException异常。 当线程t调用wait方法后，如果t被中断，此时中断状态为true，则wait方法将抛出InterruptException异常，并将中断状态设置为false； 否则会顺序发生如下事件（注意：到这里说明首先拿到了对象的监视器锁，wait参数正常，线程t没有被中断）： 线程t会加入对象m的等待集合中，执行加锁编号n对应的解锁操作 线程t不会执行任何进一步的指令，直到t从m的等待集合中移出（也就是等待唤醒）。以下情况t会从m的等待集合中移出（移出队列并不是马上执行，这个线程还需要重新获取锁才行），然后在之后的某个时间点恢复，继续执行后面的指令。 执行m.notify()，并且在所有等待锁的线程中t被选中从等待集合中移除。 执行m.notifyAll() 线程t发生了interrupt操作 如果t是调用wait(long millisecs)或者 wait(long millisecs, int nanosecs)，millisecs进入等待集合，那么过了millisecs 毫秒或者 (millisecs*1000000+nanosecs) 纳秒后，线程 t 也会从等待集合中移出。 JVM假唤醒 线程t执行编号为n的加锁操作 2中说线程t刚刚从等待集合中移出，那么t需要再次拿到监视器锁才能继续往下执行。 如果t在2的时候由于中断从m的等待集合中移出，那么t的中断状态重置为false，并且wait抛出InterruptException异常。 总结：当线程a由于等待而正在阻塞的时候，如果另外一个线程执行a.interrupt()，那么a线程的中断状态会重置为false，并且抛出InterruptException异常。 2. 通知Notification 方法：notify, notifyAll 在线程t中对对象m调用m.notify()或者m.notifyAll(), n代表加锁编号，同时对应的解锁操作没有执行，则会发生下面其中之一： 如果n等于0，也会抛出IllegalMonitorStateException异常，因为调用notify也要先拿到锁。 n大于0的话，对于notify，如果m对象的等待集合不为空，那么等待集合中的线程u被选中从等待集合中移出。（虚拟机并不保证哪一个线程会被移出，被移出的线程u可以恢复，但是注意这时候锁还在线程t手上，所以u线程此时对m进行加锁不会成功，直到线程t完全释放锁。 被notify唤醒的线程需要重新获取监视器锁。 n大于0，对于notifyAll，等待集合中所有线程都将从等待集合中移出，然后恢复。但是这些线程恢复后只有一个线程可以获得监视器锁。 3. 中断Interruptions 中断发生于Thread.interrupt方法的调用。 令线程t调用线程u上的方法u.interrupt()，其中t和u可以是同一个线程（自己可以中断自己），这个操作会将u的中断状态设置为true。 thread.interrupt()方法并不是暂停线程，这个方法只是设置线程的中断状态。特殊之处在于设置了中断状态为true之后，下面这几个方法会感知到： wait(), wait(long), wait(long, int), join(), join(long, int), sleep(long), sleep(long, int) 这些方法的方法签名都有throws InterruptedException，用来响应中断状态修改。 如果线程阻塞在InterruptibleChannel类的IO操作中，那么这个channel会被关闭。 如果线程阻塞在一个Selector中，那么select方法会立即返回。 如果线程阻塞在以上三种情况，那么当线程感知到中断状态后（此线程的interrupt()方法被调用），会将中断状态重新设置为false，然后执行相应的操作（通常是跳到catch异常处） 如果不是上面三种情况，那么，线程的interrupt()方法被调用，会将线程的中断状态设置为true。 当然，除了这几个方法，我知道的是 LockSupport 中的 park 方法也能自动感知到线程被中断，当然，它不会重置中断状态为 false。我们说了，只有上面的几种情况会在感知到中断后先重置中断状态为 false，然后再继续执行。 下面的不太理解： 另外，如果有一个对象 m，而且线程 u 此时在 m 的等待集合中，那么 u 将会从 m 的等待集合中移出。这会让 u 从 wait 操作中恢复过来，u 此时需要获取 m 的监视器锁，获取完锁以后，发现线程 u 处于中断状态，此时会抛出 InterruptedException 异常。 这里的流程：t 设置 u 的中断状态 => u 线程恢复 => u 获取 m 的监视器锁 => 获取锁以后，抛出 InterruptedException 异常。 这个流程在前面 wait 的小节已经讲过了，这也是很多人都不了解的知识点。如果还不懂，可以看下一小节的结束，我的两个简单的例子。 一个小细节：u 被中断，wait 方法返回，并不会立即抛出 InterruptedException 异常，而是在重新获取监视器锁之后才会抛出异常。 实例方法thread.isInterrupted()可以知道线程的中断状态。 调用静态方法Thread.interrupted()可以返回当前线程的中断状态，同时将中断状态设置为false。 4. 等待、通知、中断三者的交互 如果一个线程在等待期间，同时发生了通知和中断，它将发生下面情况的一种： 从wait方法中正常返回，同时不改变中断状态。（也就是说调用Thread.interrupted方法将会返回true） 这种情况就是说线程虽然因为调用thread.interrupt()让线程的中断状态设置为true，但是这个线程是从notify被唤醒，而不是在wait方法中捕捉到InterruptedException被返回（这样返回就是不正常返回，会把状态设置为false），被notify唤醒会从wait方法中正常返回。 由于抛出InterruptedException异常而从wait方法中返回，中断状态会被设置为false。 总结： 1.wait和notify的关系：wait 方法返回后，需要重新获取监视器锁，才可以继续往下执行。 2.wait和interrupt的关系：如果线程调用 wait 方法，当此线程被中断的时候，wait 方法会返回，然后重新获取监视器锁，然后抛出 InterruptedException 异常。 thread1.wait()方法会释放锁，然后 thread2拿到锁开始执行 -> thread2中调用thread1.interrupt()，那么thread1中的wait方法就会返回，但是thread1返回并不会立即往下执行，而要抢到监视器锁，抢到监视器锁之后在这里也不会向下执行了，因为它得响应中断，所以这里thread1拿到锁之后会立即抛出InterruptedException 异常。 3.interrupt和notify的关系：当线程1在等待的时候，如果另外一个线程执行了thread1.interrupt()操作和object.notify()操作，那么它可能会发生两种情况里面的一种。 看原文例子：第三个例子 有可能发生 线程1 是正常恢复的，虽然发生了中断，它的中断状态也确实是 true，但是它没有抛出 InterruptedException，而是正常返回。此时，thread2 将得不到唤醒，一直 wait。 二、休眠和礼让（Sleep and Yield） Thread.sleep()让当前执行线程休眠，休眠期间不会释放任何的监视器锁。 注意：Thread.sleep和Thread.yield都不具有同步的语义，在Thread.sleep和Thread.yield方法调用之前，不要去虚拟机将寄存器中的缓存刷出到共享内存中，同时也不要求在这两个方法调用之后，重新从共享内存中读取数据到缓存。 例如，我们有如下代码块，this.done 定义为一个 non-volatile 的属性，初始值为 false。 while (!this.done) Thread.sleep(1000); 编译器可以只读取一次 this.done 到缓存中，然后一直使用缓存中的值，也就是说，这个循环可能永远不会结束，即使是有其他线程将 this.done 的值修改为 true。 yield 是告诉操作系统的调度器：我的cpu可以先让给其他线程。注意，调度器可以不理会这个信息。 这个方法太鸡肋，几乎没用。 三、内存模型（JMM) 什么是Java内存模型？ 内存模型主要是为了规范多线程程序中修改（写）或者访问（读）同一个值的时候的行为，定义了对共享内存的写操作对于读操作的可见性。 具体看这里17.4 四、final属性的语义 关于final：用 final 修饰的类不可以被继承，用 final 修饰的方法不可以被覆写，用 final 修饰的属性一旦初始化以后不可以被修改。 看一看final声明的属性： final声明的属性正常情况下初始化之后就不会被改变，final属性的语义和普通属性的语义有些不同，比如对于final属性的读操作，由于final属性值根本就不会变，所以compilers可以自由去除不必要的同步，而且compilers还可以将final属性值直接缓存在寄存器中，而不用像普通属性一样从内存中重新读取。 如果对某个属性加了final，那么我就不需要使用同步就可以实现线程安全的不可变对象。 对象只有在构造方法结束了才被认为完全初始化了。如果一个对象完全初始化以后，一个线程持有该对象的引用，那么这个线程一定可以看到正确初始化的 final 属性的值。 这个隐含了，如果属性值不是 final 的，那就不能保证一定可以看到正确初始化的值，可能看到初始零值。 class FinalFieldExample { final int x; int y; static FinalFieldExample f; public FinalFieldExample() { x = 3; y = 4; } static void writer() { f = new FinalFieldExample(); } static void reader() { if (f != null) { int i = f.x; // 程序一定能得到 3 int j = f.y; // 也许会看到 0 } } } 这个类FinalFieldExample有一个 final 属性 x 和一个普通属性 y。我们假定有一个线程执行 writer() 方法，另一个线程再执行 reader() 方法。 因为 writer() 方法在对象完全构造后将引用写入 f，那么 reader() 方法将一定可以看到初始化后的 f.x : 将读到一个 int 值 3。然而， f.y 不是 final 的，所以程序不能保证可以看到 4，可能会得到 0。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-27 16:29:48 "},"2-Java 并发/Java锁池和等待池.html":{"url":"2-Java 并发/Java锁池和等待池.html","title":"Java锁池和等待池","keywords":"","body":"Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-30 10:59:33 "},"2-Java 并发/synchronized和无锁，偏向锁，轻量级锁，重量级锁的关系.html":{"url":"2-Java 并发/synchronized和无锁，偏向锁，轻量级锁，重量级锁的关系.html","title":"Synchronized和无锁，偏向锁，轻量级锁，重量级锁的关系","keywords":"","body":"Java中加锁一般有两种方式：synchronized关键字、Lock接口的实现类。synchronized就像自动挡，可以满足日常同步的需求，而如果要进行一些特定的操作，就需要用手动挡，也就是各种Lock的实现类。 synchronized锁升级（四种锁状态）：无锁->偏向锁->轻量级锁（就是一种自旋锁）->重量级锁 上面说synchronized是自动挡，其实就是说JVM会负责在不同的速度下帮你调节档位，也就是看线程竞争情况帮你对synchronized锁进行升级，注意：synchronized锁只能按照偏向锁->轻量级锁->重量级锁进行升级（也叫锁膨胀），不能降级。 具体来说这个加油换挡的过程： 偏向锁： 初次执行synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），意思是：“偏向于第一个获得它的线程”的锁。执行完同步代码块后，线程并不会主动释放偏向锁。当第二次到达同步代码块的时候，线程会判断持有锁的线程是否是自己（持有锁的线程ID在对象头里面），如果是则正常往下执行。由于之前没有释放锁，这里就不再需要重新加锁。（如果自始至终使用锁的线程只有一个，很明显偏向锁就不需要重复进行CAS操作来加锁，只需要看一下对象头中的线程ID即可，性能极高） 注意：当一个线程访问同步代码块并获取锁时，会在Mark Word里面存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS操作即可。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 轻量级锁： 一旦有第二个线程加入锁竞争，偏向锁就升级为轻量级锁（自旋锁）。在轻量级锁状态下进行锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能被成功获取（其实就是通过CAS修改对象头里的锁标志位）。 如果一个线程已经拿到了锁，其它线程只能进行自旋（也就是原地空耗CPU，这种现象叫忙等），当竞争比较小的时候会采用轻量级锁，也就是允许短时间的忙等，这是一种折衷的想法，换取线程在用户态和内核态之间切换的开销。 重量级锁： 当自旋操作超过10次，说明竞争比较激烈，那么会升级为重量级锁（依然是CAS修改锁标志位，但不修改持有锁的线程ID），如果后续线程尝试获取锁，发现占用的锁是重量级锁，则直接将自己挂起。 偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 csdn 美团博客 知乎 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-22 10:16:47 "},"2-Java 并发/悲观锁、乐观锁、可重入锁、读写锁.html":{"url":"2-Java 并发/悲观锁、乐观锁、可重入锁、读写锁.html","title":"悲观锁、乐观锁、可重入锁、读写锁","keywords":"","body":"synchronized是Java语言内置的关键字，Lock是一个接口，接口的实现类在代码层面实现了锁的功能。 可重入、读锁、写锁 ReentranReadWriteLock实现了ReadWriteLock接口，同时它还有两个内部静态类ReadLock和WriteLock。 一、悲观锁与乐观锁 这并不是特指Java中Lock接口的实现类的哪个锁，乐观、悲观指的是在并发情况下的两种不同策略。 悲观锁：每次拿数据的时候都认为别人会修改，所以它在拿数据的时候会上锁，这样别人拿数据就会被挡住，直到悲观锁被释放。 乐观锁：拿数据的时候认为别人不会修改，所以不会上锁，但是当更新数据时，则会在更新前检查在读取到更新这段时间别人有没有修改过这个数据，如果修改过，则重新读取，然后再次尝试更新，循环上述步骤直到更新成功。（其实CAS就是一种乐观锁） 悲观锁阻塞事务，乐观锁回滚重试。 二、乐观锁的基础-- CAS(currentValue, oldValue, newValue) compare and swap(set)；其实就是：你要对某个值进行修改对吧，那在你改这个值的前一刻你看看这个值是不是被其它线程修改过了，没有修改过说明你可以修改，修改过了说明其它线程已经拿了这个共享值，那你肯定不能动了，所以\"啥也不干，循环重试\" 我的理解：CAS中，每个线程如果想更新共享资源值，首先都会去读这个共享资源值（这其实相当于每个线程都挂了一个号，这个号没有顺序，只是说明你拥有了修改共享资源值的权利，然后挂了号的这些线程开始抢着去修改，注意下面是一个原子操作：（要修改之前会拿着挂的号也就是oldValue去和当前的currentValue进行比较，如果两者相同，说明这个共享资源值没有被其它线程修改过，那么可以更新为新的值，但是如果两者不相同，说明这个值被其它线程改过了，也就是说当前这个号无效了，那么会重新读取 相当于重新挂号，然后再次尝试更新，一种循环。。。） 比较：读取到了一个值A，在将其更新为B之前，检查原值是否为A（未被其它线程改动） 设置：如果是，将A更新为B，结束，如果不是，什么都不做。 乐观锁没有加锁、解锁，所以乐观锁策略也叫无锁编程，它其实就是一个循环重试CAS算法。 三、自旋锁 Java中并没有自旋锁这个类，自旋说白了就是while(true)无限循环，虽然操作上是一样的，但是应该将自旋和while(true)分开，自旋锁特指自旋锁的自旋，synchronized中锁状态为轻量级锁时，这个轻量级锁就是一种自旋锁，当有少量线程参与竞争锁时，没有抢到锁的线程将自旋，即：不停地循环判断锁是否能够成功被获取，也就是：不停地通过CAS算法修改对象头里的锁标志位，先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，然后线程将当前锁的持有者信息修改为自己。 四、可重入锁（递归锁） Java中所有现成的Lock实现类、synchronized关键字锁都是可重入锁。 五、可中断锁（可以响应中断的锁） 什么是中断？Java并没有提供任何直接中断某线程的方法，只提供了中断机制。 什么是中断机制：线程A向线程B发出“请你停止运行”的请求（B也可以自己给自己发送），但B并不会立刻停止运行，而是自行选择合适的时机以自己的方式响应中断，也可以直接忽略此中断。也就是说：Java中断并不能直接终止线程，而是需要被中断的线程自己决定怎么处理。 synchronized是不可中断锁，也就是它不能响应中断，而Lock的实现类都是可中断锁。 /* Lock接口 */ public interface Lock { void lock(); // 拿不到锁就一直等，拿到马上返回。 void lockInterruptibly() throws InterruptedException; // 拿不到锁就一直等，如果等待时收到中断请求，则需要处理InterruptedException。 boolean tryLock(); // 无论拿不拿得到锁，都马上返回。拿到返回true，拿不到返回false。 boolean tryLock(long time, TimeUnit unit) throws InterruptedException; // 同上，可以自定义等待的时间。 void unlock(); Condition newCondition(); } 六、读写锁、共享锁、互斥锁 读写锁其实是一对锁，一个读锁（共享锁）和一个写锁（互斥锁、排他锁）。 看下Java里的ReadWriteLock接口，它只规定了两个方法，一个返回读锁，一个返回写锁。 public interface ReadWriteLock { Lock readLock(); Lock writeLock(); } 读写锁其实做的事情是一样的，但是策略稍有不同。很多情况下，线程知道自己读取数据后，是否是为了更新它。那么何不在加锁的时候直接明确这一点呢？如果我读取值是为了更新它（SQL的for update就是这个意思），那么加锁的时候就直接加写锁，我持有写锁的时候别的线程无论读还是写都需要等待；如果我读取数据仅为了前端展示，那么加锁时就明确地加一个读锁，其他线程如果也要加读锁，不需要等待，可以直接获取（读锁计数器+1）。 虽然读写锁感觉与乐观锁有点像，但是读写锁是悲观锁策略。因为读写锁并没有在更新前判断值有没有被修改过，而是在加锁前决定应该用读锁还是写锁。乐观锁特指无锁编程。 七：回到乐观锁和悲观锁 观点：我们在Java里使用的各种锁，几乎全都是悲观锁。synchronized从偏向锁、轻量级锁到重量级锁，全是悲观锁。JDK提供的Lock实现类全是悲观锁。其实只要有“锁对象”出现，那么就一定是悲观锁。因为乐观锁不是锁，而是一个在循环里尝试CAS的算法。而你偏向锁、轻量级本质上确实用到了锁，所以它不是乐观锁。 那JDK并发包里到底有没有乐观锁呢？ 有。java.util.concurrent.atomic包里面的原子类都是利用乐观锁实现的。 为什么网上有些资料认为偏向锁、轻量级锁是乐观锁？理由是它们底层用到了CAS？或者是把“乐观/悲观”与“轻量/重量”搞混了？其实，线程在抢占这些锁的时候，确实是循环+CAS的操作，感觉好像是乐观锁。但问题的关键是，我们说一个锁是悲观锁还是乐观锁，总是应该站在应用层，看它们是如何锁住应用数据的，而不是站在底层看抢占锁的过程。如果一个线程尝试获取锁时，发现已经被占用，它是否继续读取数据，等后续要更新时再决定要不要重试？对于偏向锁、轻量级锁来说，显然答案是否定的。无论是挂起还是忙等，对应用数据的读取操作都被“挡住”了。从这个角度看，它们确实是悲观锁。 知乎 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-22 16:07:55 "},"3-Java虚拟机/JVM和Linux的内存关系.html":{"url":"3-Java虚拟机/JVM和Linux的内存关系.html","title":"JVM和Linux的内存关系","keywords":"","body":"JVM内存和操作系统内存的关系 首先看一下Linux与进程内存模型： 硬件上：物理内存不够时，Linux会把一部分不用的数据先放到swap磁盘上，当需要用到swap磁盘上的数据时，必须先将其换回到内存中。 Linux系统上：除了引导系统的BIN区，其他分为内核内存（内核态）和用户内存（用户内存）。 内核内存：是Linux自身使用的内存空间，主要提供给程序调度、内存分配、连接硬件资源等程序逻辑使用。 用户内存：提供给各个进程主要空间，Linux会给每个进程提供相同的虚拟内存空间；这使得各个进程之间互相独立、互不干扰。采用虚拟内存技术：给每一个进程一定的虚拟内存空间，只有当虚拟内存实际被使用时，才分配物理内存。 jvm是以一个进程的方式运行在Linux系统上，jvm本质上就是一个进程，因此其内存空间（也称为运行时数据区）也有进程的一般特点。而jvm又不是一个普通的进程，它在内存空间上有一些新特点： 1.jvm将许多本来属于操作系统管理范畴的东西移植到了jvm内部（比如对象内存的分配），目的在于减少系统调用的次数。 2.Java NIO，目的在于减少用于读写IO的系统调用的开销。 jvm进程和普通进程内存模型比较： 注意这里的jvm代码区和jvm数据区指的是jvm自身的，不是Java程序的。普通进程中的栈区空间，在jvm中一般仅仅用作线程栈。 永久代对于操作系统来说，是堆的一部分；而对于Java程序来说，这是容纳程序本身以及静态资源的空间，使得jvm能够解释执行Java程序。 其次是新生代和老年代，这才是Java程序真正使用的堆空间，用于Java程序中内存对象的存储；但是jvm中的堆和普通进程中的堆在管理方式上有本质的区别。 普通进程在给内存对象分配/释放空间： 比如C++执行new操作时，会触发一次分配内存空间的系统调用，由操作系统的线程根据对象的大小分配好空间后返回；同时，释放对象，比如delete时，也会触发系统调用通知操作系统对象所占用的空间可以回收了。 jvm进程给内存对象分配/释放空间： JVM对内存的使用和一般进程不同。JVM向操作系统申请一整段内存区域（具体大小可以在JVM参数调节）作为Java程序的堆（分为新生代和老年代）；当Java程序申请内存空间，比如执行new操作，JVM将在这段空间中按所需大小分配给Java程序，并且Java程序不负责通知JVM何时可以释放这 个对象的空间，垃圾对象内存空间的回收由JVM进行。 jvm进程相比较普通进程在管理内存上的好处： 减少系统调用次数，jvm在给Java程序分配内存空间时不需操作系统干预，只在整个Java堆大小变化时需要向操作系统申请内存或通知回收，普通进程每次操作内存都需要系统调用参与。 减少内存泄露，普通进程需要自己手动申请、释放，而jvm可以统一管理内存的释放和回收。Java 对于Java NIO java对NIO抽象为channel，channel又可以分为FileChannel(磁盘io)和SocketChannel(网络io)。 NIO抽象为channel是面向缓冲区的、非阻塞IO。channel只负责传输，数据由Buffer负责存储。Buffer又有三种，HeapByteBuffer会分配在jvm堆内，所以受jvm堆大小的限制，创建速度快，但是读写慢，底层实际是一个字节数组。DirectByteBuffer会分配在jvm堆外，但是在jvm这个进程的堆内，不受jvm堆大小的限制，创建速度慢，读写快。还有一种是mmp（memory mapping 内存映射）。 尽管 DirectByteBuffer 是堆外，但是当堆外内存占用达到 -XX:MaxDirectMemorySize 的时候，也会触发 FullGC ，如果堆外没有办法回收内存，就会抛出 OOM。 堆外内存如何回收呢？ DirectByteBuffer类有一个成员变量private final Cleaner cleaner,当触发FullGC的时候，cleaner没有gc root可达，导致cleaner会被回收，回收的时候会触发Clean.clean方法的调用，clean方法中就会调用Unsafe.freeMemory来释放堆外内存。 内存映射 一般的物理磁盘和应用程序数据交换流程： 当应用程序读文件的时候，数据需要从先从磁盘读取到内核空间(第一次读写，没有 page cache 缓存数据)，在从内核空间 copy 到用户空间，这样应用程序才能使用读到的数据。当一个文件的全部数据都在内核的 Page Cache 上时，就不用再从磁盘读了，直接从内核空间 copy 到用户空间去了。 应用程序对一个文件写数据时，先将要写的数据 copy 到内核 的 page cache，然后调用 fsync 将数据从内核落盘到文件上（只要调用返回成功，数据就不会丢失）。或者不调用 fsync 落盘，应用程序的数据只要写入到 内核的 pagecache 上，写入操作就算完成了，数据的落盘交由 内核 的 Io 调度程序在适当的时机来落盘（突然断电会丢数据，MySQL 这样的程序都是自己维护数据的落盘的）。 我们可以看到数据的读写总会经过从用户空间与内核空间的 copy ,如果能把这个 copy 去掉，效率就会高很多，这就是 mmap （内存映射）。将用户空间和内核空间的内存指向同一块物理内存。内存映射 英文为 Memory Mapping ,缩写 mmap。对应系统调用 mmap 这样在用户空间读写数据，实际操作的也是内核空间的，减少了数据的 copy 。 怎么实现的呢，简单来说就是 linux 中进程的地址是虚拟地址，cpu 会将虚拟地址映射到物理内存的物理地址上。mmap 实际是将用户进程的某块虚拟地址与内核空间的某块虚拟地址映射到同一块物理内存上，已达到减少数据的 copy 。 用户程序调用系统调用 mmap 之后的数据的读写都不需要调用系统调用 read 和 write 了。 jvm内存分配问题 SWAP和GC同时发生会导致GC时间很长，JVM严重卡顿，极端的情况下会导致服务崩溃。原因如下：JVM进行GC时，时需要对相应堆分区的已用 内存进行遍历；假如GC的时候，有堆的一部分内容被交换到SWAP中，遍历到这部分的时候就需要将其交换回内存，同时由于内存空间不足，就需要把内存中堆 的另外一部分换到SWAP中去；于是在遍历堆分区的过程中，(极端情况下)会把整个堆分区轮流往SWAP写一遍。Linux对SWAP的回收是滞后的，我 们就会看到大量SWAP占用。上述问题，可以通过减少堆大小，或者增加物理内存解决。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-02 16:58:18 "},"3-Java虚拟机/方法区.html":{"url":"3-Java虚拟机/方法区.html","title":"方法区","keywords":"","body":" 这里的Car.class其实是在硬盘上的，然后通过ClassLoader它就被加载到JVM中了，也就是内存中，car1、car2、car3是Car的三个实例，它们一模一样，是因为它们来自于同一个模板，这个模板存在方法区（方法区其实就是模板工厂！！！），而方法区则存储的是每一个类的结构信息，包含这个类有几个构造方法、有几个字段、方法。 方法区是JVM中的规范，但是规范的具体实现JVM是不管的，所以在Java1.7中叫永久代，1.8中叫元空间。 相关内容： Java hotSpot虚拟机中class对象是在方法区还是堆区？ class对象肯定是在堆区，而类的元数据（元数据并不是类的class对象，class对象是类加载的最终产品，类的元数据指的是类的方法代码，变量名，方法名，访问权限，返回值，这些东西的字节码会放在方法区）才放在方法区。 看上面那张JVM和.class文件的交互图，ClassLoader在类加载时将.class文件加载到JVM内存，然后把里面的类型信息（字节码）放到方法区，并构造一个该类的Class对象（作为这些类信息数据的访问接口）放在堆。 方法区只是JVM的一个概念，它只是一个逻辑上的存储区域，不同JVM实现不同，hotspot通过永久代来实现方法区，不过1.8之后改成元空间了，这样能让JVM加载更多的类。 JVM实现的设计者决定类型信息的内部表现形式，比如多字节变量在class文件中是以big-endian存储的，但是在加载到方法区后，其存放形式则由jvm根据不同平台来具体定义。 jvm在运行的时候要大量使用存储在方法区中的类型信息，那么jvm如何更高效的表示类型信息呢？jvm设计者既要尽可能的提高应用的运行效率，也要考虑空间问题。 方法区是被所有线程共享的，要考虑线程安全问题，比如两个线程都在试图找Java的类，在Java类还没有被加载时，只应该有一个线程去加载，而另一个线程等待。 方法区大小不必固定，jvm可以根据应用动态调整，方法区也不必连续。方法区可以在堆（甚至是虚拟机自己的堆）中分配。 类的信息： 这个类的完整有效名 这个类的直接父类的完整有效名（除了interface，Object） 这个类的修饰符public，abstract，final的某个子集 这个类的直接接口的一个有序列表 除了上面这四个基本信息，jvm还要为每个类保存类的常量池，域信息，方法，除了常量外的所有静态变量 常量池： jvm给每一个已加载的类都维护一个常量池，包括： 实际的常量，也就是字面量（string，integer，和floating point常量） 符号引用 类和接口的全限定名 字段名称和描述符 方法名称和描述符 池中的数据项和数据项一样，也是用索引访问。因为常量池存储了一个类所使用到的所有类型、域和方法的符号引用，所以在Java程序的动态链接中起了核心作用。 符号引用：字符串，能根据这个字符串定位到指定的数据，比如.class文件中java/lang/StringBuilder 直接引用：内存地址 理解：JVM和class文件都有属于自己的数据结构，当class文件被加载到jvm里面时候，jvm会根据class文件的数据结构规则，拆分读取class文件，把对应的数据放入到jvm中：加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中。 类加载之后，常量池的内容会进入运行时常量池，这时候里面的数据也许还保持着符号引用。（因为解析的时机由jvm自己设定） 调用函数时，符号引用怎么转成直接引用：如果在虚拟机栈的 栈帧中，我准备调用 main() 函数，那么会通过栈帧中持有的动态连接，找到运行时常量池， 然后找到main函数的常量 比如 #2 ，如果这个常量没有被解析过，那么就通过这个常量进行解析过程， 其中包括，通过常量 找到 类名 和 nameAndType，通过 nameAndType 找到方法名和返回值。 这时候 我手里有 类名/方法名/方法返回值，下一步，我通过类名和方法名，通过JVM记录的方法列表，找到对应的方法体。 而这个方法体实际上是一段内存地址，那么这时候我就把这段内存地址复制给 #2，并且给 #2设定一个已经解析的 flag。 这样就完成了 符号引用到直接引用的过程。 域信息（也就是字段） jvm必须在方法区中保存所有域的相关信息（域名，域类型，域修饰符）以及域的声明顺序。 方法信息 方法名、方法返回值、方法的修饰符，方法的参数的数量和类型 还有：异常表、常量（被声明为final的类变量），常量的处理方法不太一样，每个常量都会在常量池中有一个拷贝。non-final类变量是被存储在声明它的类信息中的，而final类被存储在所有使用它的类信息内。 对类加载器的引用 jvm必须知道一个类型是由启动类加载器加载的还是由用户类加载器加载的，对于用户类加载器加载的类，jvm会把这个类的类加载器的一个引用作为类型信息的一部分保存在方法区。因为jvm在动态链接的时候需要这个信息，当解析一个类到另一个类的引用的时候，jvm需要保证这两个类的类加载器是相同的。这对jvm区分名字空间的方式是至关重要的。 对Class类的引用 jvm为每个加载的类型（包括类和接口）都创建一个java.lang.Class的实例，jvm必须以某种方式把Class的这个实例和存储在方法区中的类型数据联系起来。 可以通过Class.forName(\"java.lang.Object\")得到与java.lang.Object对应的类对象，可以通过这个函数得到任何包中任何已经加载的类引用，只要这个类能够被加载到当前的名字空间。但是如果jvm不能把类加载到当前的名字空间，就会抛出ClassNotFoundException。 方法表 为了提高访问效率，必须仔细设计存储在方法区中的数据信息结构。除了上面讨论的结构外，jvm实现者还可以添加一些其他的数据结构，比如方法表。jvm对每个加载的非虚拟类的类型信息都添加一个方法表，方法表是一组对类实例方法的直接引用（包括从父类继承的方法）。这样jvm可以通过方法表快速激活实例方法。 这里的方法表与C++中的虚拟函数表一样，但java方法全都 是virtual的，自然也不用虚拟二字了。正像java宣称没有 指针了，其实java里全是指针。更安全只是加了更完备的检查机制，但这都是以牺牲效率为代价的,个人认为java的设计者 始终是把安全放在效率之上的，所有java才更适合于网络开发 jvm如何使用方法区中的信息 为了显示jvm如何使用方法区中的信息，我们据一个例子，我们 看下面这个类： class Lava { private int speed = 5; // 5 kilometers per hour void flow() { } } class Volcano { public static void main(String[] args) { Lava lava = new Lava(); lava.flow(); } } 下面我们描述一下main()方法的第一条指令的字节码是如何被执行的。不同的jvm实现的差别很大，这里只是其中之一。 为了运行这个程序，你以某种方式把“Volcano”传给了jvm。有了这个名字，jvm找到了这个类文件(Volcano.class)并读入，它从类文件提取了类型信息并放在了方法区中，通过解析存在方法区中的字节码，jvm激活了main()方法，在执行时，jvm保持了一个指向当前类(Volcano)常量池的指针。 注意jvm在还没有加载Lava类的时候就已经开始执行了。正像大多数的jvm一样，不会等所有类都加载了以后才开始执行，它只会在需要的时候才加载。 main()的第一条指令告知jvm为列在常量池第一项的类分配足够的内存。jvm使用指向Volcano常量池的指针找到第一项，发现是一个对Lava类的符号引用，然后它就检查方法区看lava是否已经被加载了。 这个符号引用仅仅是类lava的完整有效名”lava“。这里我们看到为了jvm能尽快从一个名称找到一个类，一个良好的数据结构是多么重要。这里jvm的实现者可以采用各种方法，如hash表，查找树等等。同样的算法可以用于Class类的forName()的实现。 当jvm发现还没有加载过一个称为”Lava”的类，它就开始查找并加载类文件”Lava.class”。它从类文件中抽取类型信息并放在了方法区中。 jvm于是以一个直接指向方法区lava类的指针替换了常量池第一项的符号引用。以后就可以用这个指针快速的找到lava类了。而这个替换过程称为常量池解析(constant pool resolution)。在这里我们替换的是一个native指针。 jvm终于开始为新的lava对象分配空间了。这次，jvm仍然需要方法区中的信息。它使用指向lava数据的指针(刚才指向volcano常量池第一项的指针)找到一个lava对象究竟需要多少空间。 jvm总能够从存储在方法区中的类型信息知道某类型对象需要的空间。但一个对象在不同的jvm中可能需要不同的空间，而且它的空间分布也是不同的。(译者：这与在C++中，不同的编译器也有不同的对象模型是一个道理) 一旦jvm知道了一个Lava对象所要的空间，它就在堆上分配这个空间并把这个实例的变量speed初始化为缺省值0。假如lava的父对象也有实例变量，则也会初始化。 当把新生成的lava对象的引用压到栈中，第一条指令也结束了。下面的指令利用这个引用激活java代码把speed变量设为初始值 5。另外一条指令会用这个引用激活Lava对象的flow()方法。 参考来源 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-01 17:59:42 "},"3-Java虚拟机/栈.html":{"url":"3-Java虚拟机/栈.html","title":"栈","keywords":"","body":" 栈管运行，堆管存储。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-16 10:45:40 "},"3-Java虚拟机/类加载器.html":{"url":"3-Java虚拟机/类加载器.html","title":"类加载器","keywords":"","body":" 类装载器子系统 什么是类加载器 有几种（3+1） 双亲委派 Java类加载机制一定是从Bootstrap Class Loader这个加载器开始，先用这个加载器加载Class。比如你写一个Car类，先编译成.Car.class文件，然后会去问System Class Loader加载，但是它会让你去找他的父加载器，也就是Extension Class Loader，然后这个又去让你去找他的父加载器，直到最顶（这个叫双亲委派），用Bootstrap Class Loader这个加载器看看能不能加载，不能再往下（这样保证了先加载Java自带的那些类，比如Java.lang、Java.util包下面的那些，然后如果用户也定义了同名类就会报错，这就是沙箱安全）。 沙箱安全 字节码校验器（bytecode verifier）：确保Java类文件遵循Java语言规范。这样可以帮助Java程序实现内存保护。但并不是所有的类文件都会经过字节码校验，比如核心类。 类装载器（class loader）：其中类装载器在3个方面对Java沙箱起作用 它防止恶意代码去干涉善意的代码； 它守护了被信任的类库边界； 它将代码归入保护域，确定了代码可以进行哪些操作。 Java中线程启动 Thread thread = new Thread(); thread.start(); 执行start方法后这个线程其实是处于就绪状态，因为线程其实是操作系统级别的，并不是说Java这个语言有多线程，所以其实执行start方法底层会去调用start0()方法，这个start0()方法是native方法，native方法（native方法有声明但是无实现）指的是Java会去调用C语言的方法，其实就是因为大部分操作系统是用C语言写的，Java要执行多线程绕不过C语言。这里start之后还要等操作系统给这个线程分配CPU时间片才能真正启动线程。 总结： Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-10-16 10:45:36 "},"4-LeetCode/15_3Sum.html":{"url":"4-LeetCode/15_3Sum.html","title":"15 3Sum","keywords":"","body":"题目描述（一般） ​ 方法一之我写的代码（暴力 for 循环） 由于 3 个元素的组合，所以用三层嵌套 for 循环来遍历所有的三元素组合，但是很遗憾，最后花了 5、6 个小时成功运行，而且理论上可以得出正确结果，但是由于 3 个 for 循环一般时间复杂度达到 O(n^3)基本就凉了，所以必须改进。 class Solution { public List> threeSum(int[] nums) { List> list = new ArrayList<>();//这样声明一个两层的列表 int count=0; int i = 0,j = 0,k = 0,flag=1;//初始化flag=1，表示默认list中没有和myCorrds一样的数组 for(i = 0;i myCoords = new ArrayList(); //myCoords.clear(); myCoords.add(nums[i]); myCoords.add(nums[j]); myCoords.add(nums[k]); System.out.println(\"i:\"+i+\" j:\"+j+\" k:\"+k); System.out.println(count++ +\":\"+nums[i]+\":\"+nums[j]+\":\"+nums[k]); Collections.sort(myCoords, new Comparator() { @Override public int compare(Integer o1, Integer o2) { // 这里是根据当前对象的某一个字段进行排序 if (o1 > o2) { return 1; } else if (o1 == o2) { return 0; } else { return -1; } } }); //Arrays.sort(myCoords); for(int q = 0;q a = new ArrayList(); a = list.get(q);//a 指向list.get(q)这个list同一片空间，a操作了也会使得这篇空间发生变化 // for (int m = 0; m 方法二 用两个标识（lo、hi），来两头遍历，由两个标识在数组中纸箱的数字形成两两对，因为我们一开始就给数组 sort 了，所以这样两头走一遍就可以得到所有情况的两两组合了，判断结束条件是（lo class Solution { public List> threeSum(int[] nums) { Arrays.sort(nums); List> res = new ArrayList<>(); for(int i = 0;i 0 && nums[i] != nums[i-1])){ int lo = i + 1,hi = nums.length -1,sum = 0 - nums[i]; while(lo 时间复杂度：O(n^2),n是指nums.length空间复杂度：O(N) 总结 通过两个指针来从两头遍历，这也依赖了最开始对数组排序了才能用这种方式，两头遍历降低了时间复杂度。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-07-27 17:16:05 "},"4-LeetCode/1_TwoSum.html":{"url":"4-LeetCode/1_TwoSum.html","title":"1 TwoSum","keywords":"","body":"题目描述（容易） 输入一个数组和一个 target 值，要求输出数组中的两个和为 target 的数，并且一个元素不能用两次。 方法一：暴力循环 class Solution { public int[] twoSum(int[] nums, int target) { int i = 0,j = 0; //int result[2] = 0; int[] result = new int[2]; for(i = 0;i 通过两层 for 循环遍历所有两个元素的组合。时间复杂度：O(n²)空间复杂度：O(1) 方法二： 对于第二个 for 循环找剩下一个满足要求的数时，方法一用的是遍历剩下的元素，这会产生 O(n) 的时间复杂度，那么怎么才可以避免呢？ 有没有想过用 Map 来做，是不是想起了什么？Map 不同于数组的地方就在于它寻找一个元素是通过一个函数，而不是遍历！把 key 带入这个函数得到的数值就是 value 所在的地址，通过这个地址去找到 value，是不是不要傻傻的循环呢。 我们用 hash table 来做，这里需要先将数组的每个元素保存为 hash 的 key，下标保存为 hash 的 value。这样如果你需要找一个 target - nums[j]，这个 target - nums[j] 就是一个 key 了，那么你就先判断 target - nums[j] 在不在 hash map 里面，如果在就可以找到他的 value，这个 value 也就是 target - nums[j] 在数组中的下标。此时的时间复杂度就是O(1)! 但是要注意，因为同一个元素不能用两次，所以要判断找到的元素应该不是当前元素才行。 class Solution { public int[] twoSum(int[] nums, int target) { Map map = new HashMap<>(); for(int i = 0;i 时间复杂度：用了 hash map，所以少了一个 for 循环，变成 O(n)空间复杂度：由于开辟了一个 hash map，用空间换取了时间，空间复杂度由 O(1) 变成 O(n). 方法三 只需要一次循环 + hash map,就可以遍历所有的两两一对，然后找出最终满足条件的结果。比如一个数组[2,3,5,6,7]，最开始 map 中是空的，然后 map.put(2),2 和空的 map 去配比，然后 map.add(3),3 就和 map 中已经存在的 2 去配比，然后 map.add(5),5 就和 map 中存在的 2，3 去配比......这样你会发现，只用了一个 for 循环，就遍历了所有两两一对。 详细举个例子就是：当你 map.add(5) 的时候，这个 5 肯定先去 和 2，3 配比，也就是说 5 前面的就此遍历了一遍，5 后面的每个元素进来 map 的时候肯定会和 5 来一次配比，那么这个 5 就和前面、后面除了自己的元素进行了配比。 class Solution { public int[] twoSum(int[] nums, int target) { Map map = new HashMap<>(); for(int j = 0;j 时间复杂度：照样依次 for 循环，所以为 O(n).空间复杂度：用了 hash map 存放数组元素，O(n). 总结 学了一招用 hash map 来消弱一层 for 循环，因为 for + for 完 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-22 21:24:24 "},"4-LeetCode/2_AddTwoNumbers.html":{"url":"4-LeetCode/2_AddTwoNumbers.html","title":"2 AddTwoNumbers","keywords":"","body":"题目描述（一般） 就是给你两个 ListNode，每个都存了一个非负整数，要你把它们两个加起来然后存到一个（新的或者旧的）ListNode 中，并返回。 这是我的代码 // // * // // * Definition for singly-linked list. // public class ListNode { // int val; // ListNode next; // ListNode(int x) { this.val = x; } // }//每个结点就是这个 ListNode 类的一个对象 class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { //传过来的是两个对象（已经赋好了值） ListNode LC = new ListNode(0); ListNode pa = l1; ListNode pb = l2; ListNode pc = LC;//pc 指向要返回的 ListNode 的最后一个结点 System.out.println(\"pc2222:\"+pc.val); System.out.println(\"pc的next:\"+pc.next); int addnum = 0;//两个数相加的结果，存到 LC 中 int co = 0;//0 表示没有进位，1 表示进位 /* 输出l1,l2 */ // while(pa!=null){ // System.out.println(pa.val); // pa = pa.next; // } while((pa !=null) && (pb != null)){ //pc = ; addnum = pa.val + pb.val + co; //System.out.println(\"1111pa:\"+addnum); if(addnum 第一种解法 public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode dummyHead = new ListNode(0); ListNode p = l1, q = l2, curr = dummyHead; int carry = 0; while (p != null || q != null) { int x = (p != null) ? p.val : 0; int y = (q != null) ? q.val : 0; int sum = carry + x + y; carry = sum / 10; curr.next = new ListNode(sum % 10); curr = curr.next; if (p != null) p = p.next; if (q != null) q = q.next;//加了这两句就知道哪个需要进行下一个 } if (carry > 0) { curr.next = new ListNode(carry); } return dummyHead.next; } 其实思想还是挺简单的，就是 l1 和 l2 两个链表，位对位相加，超过 10 则进位，用 co 来记录进位。其实每一次位的相加看成两个 0-9 的数字相加，如果这一位没有就用 0 来代替。我写的代码其实很多代码是冗余的，所以需要在逻辑上进行优化，去除冗余代码。代码优化：A wonderful solution but for the time consumed, just try replace sum%10 with sum>=10 ? sum-10 : sum will extremely speed up! 过程图： 总结 时间复杂度：O（max(m,n)）空间复杂度：O（max(m,n)），但是新的链表的长度是 O（max(m,n)）+ 1. Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-22 21:24:51 "},"4-LeetCode/3_LongestSubstringWithoutRepeatingCharacters.html":{"url":"4-LeetCode/3_LongestSubstringWithoutRepeatingCharacters.html","title":"3 LongestSubstringWithoutRepeatingCharacters","keywords":"","body":"题目描述（一般） 要求无重复的一个最长的字符串的长度 法一（自己写的：数组加循环） class Solution { public int lengthOfLongestSubstring(String s) { //简单的就应该是两层for循环，第一层for循环从1-结束，里层for从i-结束，里层判断收来的字符与已收到的字符是否存在。如果存在，则len-1,负责继续收 //复杂在里层循环可以用hash map代替里层循环 int hi = 0,result = 1,current = 0,mapCount=1; boolean newStart = false; int s_len = s.length(); //char[] max = new char[s_len];将数组转成用hash map来存 Map map = new HashMap(); //max[0] = s.charAt(0); if(s.equals(\"\")){ return 0; } for(int i = 0;i result){ // System.out.println(\"这里：\"); result = mapCount; if(result >= 95){ return 95; } // System.out.println(\"result:\"+result); } mapCount++; }else{//已经有了 //System.out.println(\"有了\"); map = new HashMap(); mapCount = 1; break; } } } // if(isExist(max,s.charAt(j-1)) == false){ // //不存在，将这个字符加在最后，maxlen++ // if(newStart == false){ // max[current] = s.charAt(j-1); // current++; // if(current>result){ // result = current; // } // if(result >= 95){ // return 95; // } // //System.out.println(\"xxx\"); // }else{//重新开始往字符数组加元素 // max[hi] = s.charAt(j-1); // hi++; // if(hi>result){ // result = hi; // } // if(result >= 95){ // return 95; // } // //System.out.println(\"yyy\"); // } // }else{ // //存在，这次找子串到此结束，先清空该字符数组（这里我直接用一个新的），继续下一次 // hi = 0; // max = new char[s_len]; // newStart = true; // //System.out.println(\"zzz\"); // break; // } // } // //max[i] = s.charAt(i); // } //System.out.println(\":\"+max[1]+\":\");//空字符而不是null return result; } // public boolean isExist(char[] max,char ch){ // //System.out.println(\"调用\"); // boolean flag = false; // for(int i = 0;i 这些注释的代码就是自己最开始想到的，前面两层循环，第三层是一个 isExist 函数，同样是一层循环，来判断 max[] 数组中是否存在当前字符。只不过后面换成了用 hashmap。这种是仅仅需要判断里面存不存在的，用 hash map 简直不要太好。 一个看不懂的答案 the basic idea is, keep a hashmap which stores the characters in string as keys and their positions as values, and keep two pointers which define the max substring. move the right pointer to scan through the string , and meanwhile update the hashmap. If the character is already in the hashmap, then move the left pointer to the right of the same character last found. Note that the two pointers can only move forward. public int lengthOfLongestSubstring(String s) { if (s.length()==0) return 0; HashMap map = new HashMap(); int max=0; for (int i=0, j=0; i Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-22 21:25:12 "},"4-LeetCode/二分查找.html":{"url":"4-LeetCode/二分查找.html","title":"二分查找","keywords":"","body":"二分查找 二分查找针对的是一个区间，必须对这个区间有一个充分的认识，在查找过程中区间会不断被二分（类似于区间的左右边界在变化，至于是左区间还是右区间变化那要根据 target 的值，反正区间不断变小的趋势是向着target方向的）。 // 二分查找基本框架 int binarySearch(int[] nums, int target) { int left = 0; int right = nums.length - 1; // 注意点1 while (left nums[mid]) { } else if (target 搜索区间 这里就提出了搜索区间的概念，如果你是 left=0，right=nums.length-1，那你在while循环当中的判断条件就应该是 left right 才能跳出 while 循环，你才能把这个区间里面的每个元素都比较到。 如果你是left=0，right=nums.length，那你while循环的条件就是left 理解了搜索区间的概念之后，对于普通的二分法查找 target 就很清晰了。但是如果让你找 [1,3,4,4,4,5,5] 这个数组中 4 出现的开始和结束索引呢？ 寻找左侧边界的二分搜索 [1,3,4,4,4,5,5] 这个数组中 4 的左侧边界的本质是什么呢？其实就是找这个数组中比 4 小的数有几个，假如有 x 个，那么 x 的取值区间就是 [0, nums.length]。 // 求左侧边界 int left_bound(int[] nums, int target) { int left = 0, right = nums.length - 1; while (left nums[mid]) { left = mid + 1; } else if (target 寻找右侧边界的二分搜索 [1,3,4,4,4,5,5] 这个数组中 4 的右侧边界的本质是什么呢？其实就是找这个数组中比 4 大的数有几个，假如有 x 个，那么 x 的取值区间就是 [0, nums.length]。 // 求右侧边界 int right_bound(int[] nums, int target) { int left = 0, right = nums.length - 1; while (left nums[mid]) { left = mid + 1; } else if (target Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-09-23 15:55:32 "},"4-LeetCode/动态规划（与分治、贪心的区别）.html":{"url":"4-LeetCode/动态规划（与分治、贪心的区别）.html","title":"动态规划（与分治、贪心的区别）","keywords":"","body":"动态规划（与分治、贪心的区别） 核心： Those who cannot remember the past are condemned to repeat it. 也就是说它的核心在于记录下之前求过的子问题的解。一般动态规划问题开始都是简单的用递归来做，但是简单的用递归做意味着你不会存储计算过程中求得的子问题的解，这样就导致很多小递归是重复计算了的。所以想到用一个空间（也就是一张表或者说一个二维数组）来存储利用递归计算过程中产生的子问题的解，这样当你每次调用递归函数的时候首先去看一下这个二维数组中有没有求过这个子问题，有的话就直接返回结果。 再说一下 DP 适用的场景：1.重叠子问题 2.最优子结构 维基百科上说 DP 在查找很多重叠子问题的情况的最优解时有效。它将问题重新组合成子问题。为了避免多次解决这些子问题，它们的结果都逐渐被计算并保存，从简单的问题直到整个问题都被解决。记住 DP 是一种思想，递归只是一种编程技巧，DP 中用到了递归而已。 动态规划只能适用于有最优子结构的问题，也就是局部最优解能够决定全局最优解。其实就是说大问题可以通过分成小问题来解决。 DP 的两种形式（UpBottom，BottomUp） 一般来说简单递归加上 memorization 技术就变成了自顶向下的 DP，然而相对于自顶向下的动态规划，因为它在递归过程中需要不断的压栈出栈，所以我们会想到用自底向上的动态规划，不断去填充记录结果的二维数组。其实就是逐个将小问题解决，然后在求大问题的时候因为小问题都解决了并且结果已经保存了，所以直接取就行了。这样不需要栈操作，时间消耗更少。 DP 和分治、贪心的区别 参考来源 1.分治 一般步骤都是：分解 --> 解决 --> 合并 2.DP 描述最优解的结构 --> 递归定义最优解的值 --> 按自底向上的方式计算最优解的值 --> 由计算的结果构造一个最优解 分治：子问题独立； DP：子问题独立且重叠 3.贪心 （注意贪心适用的场景，比如下面的 LeetCode322 题就不能用贪心来做） 一般 DP 和贪心都是用来求最优化问题，但是用 DP 就有点杀鸡用牛刀了，简单的用贪心算法就可以。贪心算法是去做选择，它只需要考虑一个选择（也就是基于贪心做出的选择）。 贪心和 DP 相同的是都适用于最优子结构，但是贪心算法中是以自顶向下的方式使用最优子结构，贪心算法会先做选择，在当时看起来是最优的选择，然后再求解一个结果子问题，而不是先求子问题的最优解，然后再做选择。而在动态规划中每一步都要做出选择，这些选择都是依赖于子问题的解，所以动态规划一般都是自底向上来解决，从解决小子问题到解决大子问题。 因此，贪心算法通常是自顶向下地做出贪心选择，不断地将给定的问题实例归约为更小的问题。贪心算法划分子问题的结果，通常是仅存在一个非空的子问题。 动态规划的经典模型（线性模型、区间模型、背包模型） 其实简单点看线性就是用一维数组保存计算结果，区间模型就是用二维数组保存结果咯。但是一维数组也可以看成是只有一行的二维数组，所以维基百科上说在解决动态规划的时候通常用一张表格（也就是一个二维数组）来保存子问题的计算结果。这样看线性模型和区间模型就相通了。 1.线性模型 这里的线性指的是状态的分布是呈线性的，比如 322题 就是一个线性 DP 问题，它的状态转移方程是：F(S) = F(S - C) + 1; // 方法二：用动态规划试试 大问题化解为小问题 这里用的是自顶向下 public int coinChangeHelper(int[] coins, int amount, int[] count) { if (amount = 0 && res = 0} int temp = Integer.MAX_VALUE; for (int coin : coins) { if (i - coin >= 0 && count[i - coin] =0} if (temp != Integer.MAX_VALUE) { count[i] = temp + 1; } } // for循环之后就可以得到一个填充好的count数组，因为初始化count数组的时候我给这个数组都填充的是amount+1，因为硬币至少是一块钱的，所以这就标记了一下，如果count[amount]最后改变了，说明硬币能够换成功 return count[amount] > amount ? -1 : count[amount]; } 再说一个线性模型比较经典的例子： 在一个夜黑风高的晚上，有n（n 1~n 号小朋友，首先 Arrays.sort(T)，也就是 T[1]~T[n] 从小到大排列 这个问题也是用 DP 来做，我们可以将这个问题化简，我们总得送 i 号小朋友过河吧，那么就有两种情况， 1.如果送 n 过河的伙伴送完 n 过河之后立马把手电筒还回去 T1 送 Tn 过河，然后 T1 把手电筒还回去，此时还未过桥的人有 T[1...n-1]，所以花费时间（状态转移方程）： dp[n] = T[n] + T[1] + dp[n-1] 2.如果送 n 过河的伙伴送完 n 过河之后没有立马把手电筒还回去 那总得有人把手电筒送回去吧，那就是第三者，这个第三者此时已经过桥了，而且这个第三者当时过桥的伙伴一定不是 Tn 或者 Tn 的伙伴，但是这个第三者当时不可能一个人过桥，因为得有一个人把手电筒送回过去，所以还存在第四个人，也就是整个过程涉及到四个人。则这种情况下的最佳策略就是： T1（第三者）、T2（第三者当时过河的伙伴）过河，然后 T2 留在那边，T1 回来还手电筒，花费 T1 + T2，然后 Tn 和 Tn-1 一起过河，但是让 T2 拿手电筒回来，此时剩下的人就是 T1~Tn-2，花费时间是：dp[n] = dp[n-2] + 2*T2 + T1 + Tn 这一点还需要仔细考虑：为什么是T0,T1,T{n-2}来陪伴T{n-1}玩这场游戏? 因为如果不是的话，则通过简单替换就可以证明计划不是最优的（算法导论中称之为copy-paste论证） 所以最终递推公式是： 假设 T[0,..,n-1]升序排序，则有 dp(n) = min{dp(n-1), dp(n-2)+2*T1} + T[0]+T[n-1], n>=2, dp(0)=T[0], dp(1)=T1 参考：阿里面试题-小朋友过河 （这里面还有扩展，如果每次允许3个人..4个人..k个人结果又是怎样） 还有另外一个人用堆来做：用堆来做小朋友过河问题 计算的这道题方法其实类似于动态规划，关键在于寻找最优子结构 1）问题的最优子结构是这样推出的 　　1.每一个人都得过河 　　2.由1可以知道cost最大的一个也必须过河 　　3.由2可知必然有一次过河的代价为cost（max） 　　4.由3可知，在将cost最大的人送过河的运输中最优的方案是将cost第二大的人也同时过河 　　因此问题可以转化为如何将cost第一大和第二大的两个人同时送过河 2）最优化问题的解法在于首先将cost最小的两个人先送过河然后选择其一送回手电筒（无论哪个人都一样），然后再使cost最大和第二大的两个人同时过河，再另上一次剩在另一　　岸的cost最小或者次小的人送回手电筒 　　因此每次将一对人送过河的cost=iMax1st+(iMin2nd+2*iMin1st) 3）按总人数的奇数偶数可以将整个问题循环之后分支为两个子问题（显而易见，不多赘述） 4)利用大根堆和小根堆使遍历的时间复杂度从n降低至logn 还有人说：要么是最快者将最慢的两个人送过桥，要么是最快的两个将最慢的两人送过桥 能者多劳 因此可以得出更加细化的解决方案——要么是最快者将最慢的2个送过桥，要么是最快的2个将最慢的2个送过桥。即将过桥的人按其过桥的时间从小到大排列，设为A，B，……Y，Z。其中A和B是最快的二个，Y和Z是最慢的二个。那么就有二种方案： 方案一 最快者将最慢的2个送过桥 第一步：A和Z过桥，花费Z分钟。 第二步：A回来，花费A分钟。 第三步：A和Y过桥，花费Y分钟。 第四步：A回来，花费A分钟。 这四步后总人数就减小2个，花费时间为A + A + Y + Z分钟。 方案二 最快的2个将最慢的2个送过桥 第一步：A和B过桥，花费B分钟。 第二步：A回来，花费A分钟。 第三步：Y和Z过桥，花费Z分钟。 第四步：B回来，花费B分钟。 这四步后总人数同样减小2个，花费时间为A + B + B + Z分钟。 这样，每次比较一下这二种方案就能将总人数减小2。然后我们再考虑一些边界情况： 有三个人过桥设为A，B，C（已经排好序，下同）。应该花费A + B + C分钟。 有二个人过桥设为A，B。那么肯定是花费B分钟。 有一个人过桥设为A。肯定花费A分钟。 所以 只需要比较 (B+B)>?(A+Y) int m=((2B)>(A+Y))?2B:(A+Y) 总时间： B+A+Z+m Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-27 18:26:39 "},"4-LeetCode/回溯、DFS、递归.html":{"url":"4-LeetCode/回溯、DFS、递归.html","title":"回溯、DFS、递归","keywords":"","body":"回溯、DFS、递归 今天写322题，一看题目想到用回溯法，尽管题目提示用 DP，但是自己在写回溯法的时候脑子里总是感觉和 DFS 有点像，而且回溯和递归是什么关系呢？查看了一下别人写的一些博客，总结一下为了让自己写代码的时候思路更清晰。 回溯和 DFS 都是一种算法思想，而递归则是一种编程的技巧，一般使用递归去实现回溯，但是 DFS 可以用递归去实现，也可以用栈去实现。 我看到别人的博客说 DFS 是一种特殊的回溯，因为回溯可能在任何节点上回溯，这取决于你的回溯条件了，但是 DFS 就是在叶子节点上的回溯。 回溯和 DFS 还有就是：回溯不会保留完整的搜索树结构，而 DFS 则会保留完整的搜索树结构。DFS 有点类似于暴力，而回溯则会进行剪枝、会回头。 下面是我看到的一个比较好的总结： 1. 回溯和 DFS 的相同点： 回溯也是遵循深度优先的，一步步往前，而不是像广度那样往周围。 2. 不同点： （1）访问序 深度优先遍历：目的是遍历，所以本质是“无序”的，也就是访问次序不重要，重要的是都被访问过了，所以在实现上只需要对每个位置记录是否被 visited 就够了。 回溯法：目的是求解过程，本质是有序的，也就是说每一步都必须是要求的次序，所以在实现上不能只是记录是否 visited 就够了，因为同样的内容不同的序访问会造成不同的结果。要使用访问状态来记录，也就是对于每个点记录已经访问过的邻居方向，回溯之后从新的未访问过的方向去访问邻居。至于这点之前有没有被访问过并不重要，重要的是没有以当前的序进行访问。 （2）访问的次数 深度优先遍历：访问过的点不再访问，所有点仅访问一次。 回溯法：已经访问过的点可能再次访问，也可能存在没有访问过的点。 322 题利用 DFS 来做： class Solution { int resultCoin = Integer.MAX_VALUE; public int coinChange(int[] coins, int amount) { // 方法一： // 题意：coins数组是你有的硬币种类，你可以假设每种硬币都有无限个，问你怎么拿硬币 硬币面值和等于amount，要你返回硬币数最少的是几个？如果拼凑不成功就返回-1 // 看上去像找零钱问题 Arrays.sort(coins); // int i = coins.length - 1; // 硬币指针 // 首先你得明白这个回溯函数的作用是什么，它的作用就是返回硬币个数或者-1 // int result = backTracking(coins, amount, i, 0); // return result; for (int i = coins.length - 1; i >=0 ; i--) { DFS(coins, amount, i, 0); } if (resultCoin != Integer.MAX_VALUE) { return resultCoin; } return -1; } // 方法一：应该叫做深度优先搜索 其实也就是回溯法 这里会超时，题解说这种就相当于暴力解法了。。。 public void DFS(int[] coins, int amount, int i, int currCoin) { if (amount == 0) { resultCoin = Math.min(resultCoin, currCoin); return; } for (int j = i; j >= 0; j--) { if (coins[j] 39题 Combination Sum 用回溯来做： class Solution { List> result = null; // 保存满足条件的回溯路线 public List> combinationSum(int[] candidates, int target) { // 用回溯来做，回溯其实就是多叉树的遍历 result = new ArrayList<>(); if (candidates.length == 0) { return result; } // Arrays.sort(candidates); List track = new ArrayList<>(); // 保存当前的回溯路线 int curr = 0; backTrack(candidates, target, track, curr); return result; } public void backTrack(int[] candidates, int target, List track, int curr) { if (target Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-11-04 22:05:05 "},"4-LeetCode/堆排序.html":{"url":"4-LeetCode/堆排序.html","title":"堆排序","keywords":"","body":"堆排序 public int findKthLargest(int[] nums, int k) { // 方法一：用快排里面的分区思想 // return quickSearch(nums, k, 0, nums.length - 1); // 找[0, nums.length - 1]这个区间第k个元素 // 方法二：堆排序 // 1. 构建大顶堆 for (int i = nums.length / 2 - 1; i >= 0; i--) { adjustHeap(nums, i, nums.length - 1); } // 2. 依次找最大值，然后调整大顶堆，执行k次就是第k大 for (int i = 0; i temp) { nums[start] = nums[i]; start = i; } else { break; } } nums[start] = temp; } priorityQueue 实现细节 Java中priorityQueue通过二叉小顶堆实现，实现了Queue接口，不允许放入null元素。其中存储数据用的是：Object[] queue;它其实是一棵完全二叉树，leftNo = parentNo 2 + 1; rightNo = parentNo 2 + 2; parentNo = (nodeNo - 1)/2; 添加元素add： 每次往里面添加元素的时候，用到了sifiUp()函数，先把新节点放到Object[] queue队列最后一个位置，然后按照完全二叉树结构依次往上调整，维持小顶堆结构。（这里调整其实也简单，因为整个堆结构是正确的，只有刚加入的这个节点位置不正确，所以只需要把新加入的节点和其父节点依次比较交换，放到合适位置即可。 取出元素poll： 这里用到了sifiDown()函数，类似与堆排序，将堆顶元素和数组中最后一个节点位置的元素交换，然后执行adjustHeap即可，注意这里是从上往下调整，所以需要父节点和左右孩子中较小的那个交换，交换之和还需要继续维持子树的小顶堆结构。 删除元素remove 该方法不是Queue接口内的方法，而是Collection接口里面的方法，删除元素会改变堆的结构，如果是删除最后一个节点，则直接删除即可，如果是删除中间的节点，则把该节点删除，我们把最后一个节点放到删除节点的位置，再执行一次sifiDown()函数即可。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-03-31 16:51:10 "},"4-LeetCode/树.html":{"url":"4-LeetCode/树.html","title":"树","keywords":"","body":"树 在做二叉树题目的时候，如果要从根节点出发，问你达到某种最优值，你可以这样考虑：因为是二叉树，所以将大问题划成小问题，也就是 root.left 或者 root.right 都是一棵小的二叉树，这样你要求从 root 开始的这棵二叉树的最优解只需要考虑分别从 root.left 和 root.right 开始这两棵子二叉树的最优解加上 root 的值就是总的最优解了。（这就是天然的递归结构，必然用递归去做最方便） 而且在二叉树中也可能出现子问题重叠情况，可以考虑用 HashMap 来保存子问题的结果。子问题重叠 + 最优化结构 = DP 了。。 LeetCode337题 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public int rob(TreeNode root) { // 题意：小偷盗窃，一棵二叉树，从根节点出发，为了不惊动警方，同一个晚上不能偷相互连接的两个房子，问一晚最多偷得钱有多少？ 其实就是要间隔咯 // 方法一：简单的用递归来做，也就是只考虑最优子结构 // int result = money(root); // return result; // 方法二：但是你会发现在简单的用递归来做中会用到money(root.left.left)、money(root.left.right)、money(root.right.left)、money(root.right.right)、money(root.left)、money(root.right)；而计算后面两个的时候又会重复计算前面四个函数，也就是会产生重复子问题，所以：最优子结构+重复子问题=DP，所以想到用动态规划来做，那么怎么存储这些子问题呢？用hashmap 存储以某个节点为根节点能偷的最多的钱 // HashMap map = new HashMap<>(); // int result = moneyWithDP(root, map); // return result; // 方法三：在方法一中，money函数定义是返回从root开始这棵二叉树能偷到的最多的钱，但是这个问题的本质是某个节点 偷/不偷；所以我们再重新定义一个函数，它会返回一个两个元素的数组，这两个元素的值是：root节点偷的话最多多少钱/root节点不偷的话最多多少钱 int[] res = robOrNot(root); int result = Math.max(res[0], res[1]); return result; } // 这个函数会返回以root为根节点的树 能够偷到的最多钱的数目 public int money(TreeNode root) { if (root == null) { return 0; } // 偷根节点这栋房子 int leftLeft = 0, leftRight = 0, rightLeft = 0, rightRight = 0; if (root.left != null) { leftLeft = money(root.left.left); leftRight = money(root.left.right); } if (root.right != null) { rightLeft = money(root.right.left); rightRight = money(root.right.right); } int res = leftLeft + leftRight + rightLeft + rightRight; // 也就是偷和不偷根节点 这两种那种情况得到的钱更多； int robMoney = Math.max(res + root.val, money(root.left) + money(root.right)); return robMoney; } public int moneyWithDP(TreeNode root, HashMap map) { if (root == null) { return 0; } if (map.containsKey(root)) { return map.get(root); } // 偷根节点这栋房子 int leftLeft = 0, leftRight = 0, rightLeft = 0, rightRight = 0; if (root.left != null) { leftLeft = moneyWithDP(root.left.left, map); leftRight = moneyWithDP(root.left.right, map); } if (root.right != null) { rightLeft = moneyWithDP(root.right.left, map); rightRight = moneyWithDP(root.right.right, map); } int res = leftLeft + leftRight + rightLeft + rightRight; // 也就是偷和不偷根节点 这两种那种情况得到的钱更多； int robMoney = Math.max(res + root.val, moneyWithDP(root.left, map) + moneyWithDP(root.right, map)); map.put(root, robMoney); return robMoney; } public int[] robOrNot(TreeNode root) { int[] res = new int[2]; if (root == null) { return res; } // 首先你得知道root的两个子节点偷或者不偷的情况 int[] left = robOrNot(root.left); int[] right = robOrNot(root.right); // res[0] 存储root被偷的情况下最多的钱；那left和right就不能被偷 res[0] = root.val + left[1] + right[1]; // res[1] 存储root不被偷的情况最多的钱；那left和right就随便（也就是看偷或者不偷哪种情况钱更多） res[1] = Math.max(left[0], left[1]) + Math.max(right[0], right[1]); return res; } } Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-07-26 10:29:10 "},"5-Compute-Network/计算机网络介绍.html":{"url":"5-Compute-Network/计算机网络介绍.html","title":"计算机网络介绍","keywords":"","body":"计算机网络介绍 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-11 11:30:59 "},"7-Linux/Linux 目录介绍.html":{"url":"7-Linux/Linux 目录介绍.html","title":"Linux 目录介绍","keywords":"","body":"Linux 目录介绍 详细查看了一下买的阿里云服务器上装的 Linux 系统（CentOS 7.6 x64）的目录，记录一下各个目录下一般放什么东西。 1.文件系统层次标准：FHS 2.Linux directory structure explained FHS 定义了 Linux 或者 UNIX-like 的文件系统结构，但是 Linux 系统中还包含了一些至今未被这个标准定义的目录。 / -根目录 Linux 系统所有的文件和目录都在根目录 / 下面，即使这些文件存在于不同的物理或者虚拟盘上。 /bin -基本用户二进制文件 这下面的是单用户模式下安装系统时必须存在的基本用户二进制文件。比如像 Chrome 这样的应用就放在 /usr/bin 目录下，一些重要的系统级程序 比如 bash shell 就放在 /bin 目录。 /boot -静态启动文件 这下面放的是启动系统时需要的文件，比如 GRUB boot loader's files 和 Linux kernels 就在这里。但是 boot loader's configuration files 不放在这里，它们放在 /etc 目录下。 /dev -驱动文件 我们都知道 Linux 系统的思想是“万物皆文件”，在 Linux 系统下，一些外部设备也以文件的形式展示出来，/dev 目录下就放的是这些文件。 /etc -配置文件 它这里说 The /etc directory contains configuration files, which can generally be edited by hand in a text editor，我猜想 etc 会不会是 edited configuration 的缩写:) 注意 /etc 放的是 system-wide configuration files，用户级别的配置文件放在每个用户的 home 目录下。 /home 这个目录下给每一个用户都分了一个 home 文件夹，文件夹的名字就是你的 username，注意 root 用户的 home 目录并不在 /home 下，而是 /root。比如 Linux 系统下有个 bob 用户，那么就有 /home/bob 文件夹，里面放的是 bob 的 user's data files 和 user-specific configuration files。每一个用户只有对他自己的 home 目录 write 的权限。root 用户才有对所有用户的 home 目录 write 的权限。 /lib - Essential Shared Libraries 上面 /bin 目录里面的一些二进制程序所需要的一些库文件就放在 /lib 目录下，当然了 /usr/bin 目录下的二进制程序需要的库就放在 /usr/lib 下咯。 /lost+found -Recovered Files 每个 Linux 文件系统都有一个 lost+found 目录，当文件系统冲突的时候，那么下一次启动的时候会执行一个文件系统 check。这些不要的文件就会放到 lost+found 目录下，可以从这个目录下去尽可能的恢复数据。 /media -可移动媒介 当你插入一张 CD 的时候，就会自动在 /media 目录下自动生成你这张光盘的文件夹，通过这个文件夹就可以访问这张 CD 里面的数据。 /mnt -临时挂载点 系统管理员用这个目录来挂载临时文件系统，比如你要挂载一个 Windows 分区来执行一些文件恢复的操作，你就可以把它挂载到 /mnt/windows 下。 /opt -Optional Packages 这下面放的是可选软件包的子目录。一些不符合标准文件系统层次结构的专有软件一般用的就是 /opt 目录，比如一些专有程序安装的时候会把它的文件放到 /opt/application 下。 /proc -内核和进程文件 /proc 目录和 /dev 目录相似，它也不包含这些标准的文件，它包含的是代表系统和进程信息的特殊文件。 /root 这里是 root 用户的 home 目录，注意 root 用户的 home 目录并不是 /home/root 哦.. /sbin -System Administration Binaries 它和 /bin 目录相似，它放的也是基本二进制文件，但这里的二进制文件是在 root 用户进行系统管理时用到。 /srv -Service Data 这下面放的是这个系统提供的一些服务的数据，比如用 Apache HTTP server 来跑一个网站的时候，你网站的一些文件就可以放在 /srv 目录下面。 /tmp -Tmporary Files Application 的一些临时文件会放在这下面，系统重新启动或者程序运行当中就可能会把这下面的文件给删除。 /usr -User Binaries & Read-Only Data 这下面当然放的是用户的 application 和 files，和系统级 application，files 相对立。比如 non-essential application 会放在 /usr/bin 目录下而不是 /bin 下，non-essential system administraion binaries 会放在 /usr/sbin 而不是 /sbin 下。每一个程序所需要的库都会放在 /usr/lib 下面。 /usr/local 是本地编译的应用程序安装的目录。这样可以防止它们破坏系统的其余部分。 /var -Variable Data Files /var 目录是 /usr 目录的可写副本，在正常操作中，该目录必须为只读。日志文件和在正常操作期间通常会写入 /usr 的所有其它内容都会写入 /var 目录。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-20 17:03:27 "},"7-Linux/Linux常用命令汇总.html":{"url":"7-Linux/Linux常用命令汇总.html","title":"Linux常用命令汇总","keywords":"","body":"创建、删除目录： $mkdir testDir ## rmdir只能删除空目录 $rmdir testDir $rmdir -r testDir # 会将testDir里面的东西删掉，然后再把testDir这个文件夹删掉 # 显示文件夹中的东西 $ls -al （可以加个路径） 检查文件的内容： # cat, tac, more, less, head, tail 修改文件权限： $chmod 777 test.txt 复制： cp [-ai] 来源文件 目标文件 #如果来源文件有两个以上，目标文件一定得是一个目录;i参数是会询问是否覆盖同名文件，a参数（相当于-dr）是指会把:1.如果文件是链接文件（-d），它相当于会再复制一个快捷方式。2.如果来源文件是个文件夹，它会递归持续复制（-r） cp ~/.bashrc /tmp/bashrc cp ~/.bashrc . #将文件复制到当前目录 cp -r /etc/ /tmp #将etc这个目录下所有内容复制到/tmp目录下面，注意-r复制出来的文件的权限可能会被改变，所有用cp时一般用-a 压缩、解压缩： # zip、unzip zip test.zip test.txt # 讲test.txt压缩成test.zip zip /root/test.zip test.txt unzip test.zip #默认将文件解压到当前目录（就是把这个压缩包里面的东西拿到当前目录） unzip test.zip -d /root/testDir #将压缩包里面的东西放到testDir这个指定的目录中 软链接：相当于给原文件创建了一个快捷方式，如果删除了原文件，对应的链接文件也会消失。 ln -s test.txt test_softlink 硬链接：相当于给原文件取了个别名，两者是同一个文件，删除其中一个，另一个不会消失，但是对其中一个修改，另一个也会随之改变。 ln test.txt test_hardlink 观察文件的类型： $file test 指令文件名的搜索：就是找命令对应文件所在的位置（which是在PATH这个环境变量里面找） $which ls 文件文件名的搜索： ## whereis 只是查找某几个目录下面的，所以比find快 $ whereis -[bmsu] 文件或目录名 ## locate用这个命令去查找的原理是通过数据库，所以查找之前可能需要用updatedb命令来更新一下数据库 $ updatedb $ locate test.txt ## find [PATH] [option] [action]; 注意用find找数据的时候相当的操硬盘，所以一般先使用whereis和locate去找 $find / -name passwd $find / -name *passwd* // *通配符 移动文件： ## 可以用mv命令来重命名 $ mv test1.txt test2.txt # 将test1重命名为test2 $ mv file1.txt file2.txt file3.txt folder # 移动多个文件到某个文件夹 # 加了-u 表示foo.txt bar.txt这两个文件中只有比bar文件夹中的文件更加新的才会移动到bar中 $ mv -u foo.txt bar.txt bar # 注意：bar文件夹中也有foo.txt bar.txt文件；The file foo.txt is not moved as it is older than the file in the destination folder. # 移动多个文件(夹)到 某个目录 加-t即可 mv build config test1.txt -t folder ## mv 一个文件夹下的所有东西（文件、文件夹）到另一个目录时发生报错，可以换成cp复制的方式，然后删除原目录即可 mv ./backup/* ./backupArchives mv: cannot move './backup/base' to './backupsArchive/base': Directory not empty cp -r ./backup/* ./backupArchives && rm -R ./backup/* # ps命令 Process Status # 显示所有进程 ps -A 或者 -e ps -f 全格式显示进程 # grep命令 global regular expression print # grep [option] pattern file ps -ef | grep -f adb # 也可以加字符串，然后这个字符串作为正则匹配 grep -f test.txt # 后面可以加文件，test.txt文件中每一行都作为正则匹配项 # wc命令 wordCount wc testfile # 统计行数 单词数 字节数 wc -l # 统计行数 # du命令 diskUseage du -h # 输出当前文件夹中文件的大小，单位是M # awk命令 三个人名字的首字母 主要用于对字符串进行处理 输入流 ｜ awk -F '=' '{print $1 $2}' # 根据‘=’等号来切割 $1 $2是切割得到的第1，2个元素 awk '这里是脚本' 文件名 # 对文件中每一行利用脚本进行过滤，得到符合的行 awk '$1>2 && $2==\"Are\" {print $1, $2}' log.txt awk '$1>2 && $2==\"Are\"' log.txt # 后面不加print就是默认输出符合脚本的整行 # sort命令 # uniq -c ls -l | sort | uniq -c | sort -k 1 -nr sort # 会将输入流所有行按照ascii排序 uniq -c # 排完序之后，这个命令会合并相邻的重复行，并统计重复数；输出(前面是频率 后面是内容)： 2 hello 3 my 4 thanks sort -k 1 # 表示按照每行的第一个字段排序 从小到大 sort -nr # -n表示指定按照数值大小进行排序，后面加r表示逆序 cat simpleLocker.txt | awk -F ' ' '{print $2}' | sort | uniq | while read line do adb uninstall $line done # top命令 top # 看当前机器中的进程状态 uptime # 看CPU负载情况 # ps命令 process status进程状态 ps -a # 显示所有有终端控制下执行的进程 ps -A 或者 ps -ax # 显示所有进程 无论是否运行在终端 ps -au # 显示所有有终端控制下执行的进程的详细信息 包括CPU使用情况等等 ps -aux # 所有进程的详细信息 无论是否运行在终端 ps -e # 和-A效果一样 会显示所有进程的信息 但是只看得到几项信息 ps -f # 把全部列都给显示出来，通常和其它选项联用 ps -fe 和 ps -aux效果差不多 ps -u root # 看root用户下的进程 # uname命令 unix name 用于查看一些系统信息 uname -a # 看内核 操作系统 CPU信息 # netstat命令 显示Linux系统的网络情况 netstat -a # 详细网络情况 哪个ip和哪个ip用哪种协议建立连接，当前连接状态是什么样的 netstat -apu # -all protocal udp netstat -apt # -all protocal tcp 看tcp协议端口使用情况 netstat -i # 显示网卡列表 就是ifconfig看到的网卡名称 netstat -tunlp | grep 8080 # 查看端口占用情况 -tcp udp n(拒绝显示别名，全用数字显示) listen(仅列出在listen的服务) p(显示建立相关连接的process) kill -9 PID # 杀掉进程 # lsof命令 list open files 列出当前系统打开文件的工具 lsof -i:端口号 # 这个命令得root用户才能执行 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-05-31 11:54:51 "},"8-数据结构和算法之美/入门篇.html":{"url":"8-数据结构和算法之美/入门篇.html","title":"入门篇","keywords":"","body":"10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树； 10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。 这里我要再强调一下，即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。 时间复杂度的全称是渐进时间复杂度，表示的是一个算法执行效率与数据规模增长的变化趋势。 最好情况时间复杂度、最坏情况时间复杂度、平均时间复杂度、均摊时间复杂度。 总结：其实在 CPU 眼中去看一段代码就是一行一行去执行，假设每行代码需要花费一个 unit_time，那么这段代码真正的执行时间就是执行所有行（可能某一行要执行很多遍）需要花费的总的 unit_time，但是我们用大 O 表示法来表示这段代码的时间复杂度，一些常量、低阶项就可以直接忽略。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-01 10:06:38 "},"8-数据结构和算法之美/排序.html":{"url":"8-数据结构和算法之美/排序.html","title":"排序","keywords":"","body":"排序 排序算法 时间复杂度 是否基于比较 冒泡、插入、选择 O(n*n) 是 快排、归并 O(n*logn) 是 桶、计数、基数 O(n) 否 1. 冒泡、插入、选择（适合小规模数据量排序） 冒泡和选择都是固定的移动次数，也就是原始数据的逆序度。而插入排序移动次数在实际中更少，虽然这三种排序的时间复杂度都是 O(n*n)，但一般选择的循序是：插入>冒泡>选择。这三种都是原地排序，因为空间复杂度都是 O(1)，都没有利用额外的空间。而插入和冒泡是稳定的排序，但是选择排序由于每次都是将未排序的那一部分中最小的那个元素和第一个元素进行交换，改变了原有的顺序，所以选择排序是不稳定的。 2. 快排、归并（适合大规模数据量排序） 归并排序用到分治思想，分治需要用到递归来实现。分治是一种解决问题的处理思想，递归是一种编程技巧。 可以看出，归并排序先是不断的分治，然后利用 merge() 函数对两个子队列进行合并，那么当子队列1和子队列2中出现相同元素的时候，我们会先把子队列1放到新的合并位置上，所以不会影响原先的顺序，是稳定的排序。 归并排序的执行效率与原始数组的有序程度无关，时间复杂度非常稳定，最好、最坏、平均都是 O(nlogn)。看起来非常优秀，因为快排最坏情况下也要 O(n*n)，但是归并排序也有致命缺点，就是它不是原地排序，在 merge 时它需要 O(n) 的空间来合并两个子队列。 快排也用到分治思想，但是它的核心思想是分区： 如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。我们遍历 p 到 r 之间的数据，将小于 pivot 的数据放到左边，大于 pivot 的数据放到右边，pivot 放到中间。这样就将 p 到 r 之间的数据分成了三部分。 问题：有十个小日志文件，每个 300 MB，你有十个接口去访问这个十个文件，每个文件中的日志都按照时间戳从小到大排好了序，你只有 1 G 的内存，让你合并这十个日志文件成一个，如何比较快速的合并？ 线性排序 下面几种排序因为时间复杂度是线性的，所以称为线性排序。它们不是基于比较的排序算法，不涉及元素之间的比较操作。 3. 桶排序 思想也很好理解，就是先划分成很多个桶，每个桶中放的是固定大小区间的数据，然后如果你要对一大批数据进行排序，你就直接把这批数据逐个放到对应区间的桶里面就行了。然后再利用快排分别对每个桶进行排序，这样从第一个桶到最后一个桶依次取出数据就是最终的排序结果了。 桶排序时间复杂度是 O(nlog(n/m))，当桶的个数接近数的个数时，就变成了 O(n)，但这都基于所有数据能够比较均匀的分布在各个桶之内这个假设，如果所有数据都被分到一个桶内，那就退化成 O(nlogn) 了。 比较适用于外存上的，数据量比较大，内存有限的排序。 4. 记数排序 针对数据量远大于数据所在区间的这种情况，是一种特殊的桶排序。比如高考有 50 万考生，但是成绩都是在 0~750 之间，那么可以设置 751 个桶，把相同分数的放到相同的桶里面。 5. 基数排序 比如你要给十万个 11 位的电话号码排序，你用快排也可以，但是是 O(nlogn)，用桶排序或者记数排序肯定不现实了，因为 11 位代表的数字太大了。用基数排序就是从最后一位开始排序，一直到电话号码的第一位，但是这里针对每一位上的排序要用稳定性排序。我们在每一位上排序可以用桶排序，比如这里的电话号码有 11 位，那么就需要进行 11 次桶排序，这样时间复杂度就是 11*O(n)，也就是 O(n)。 但是如果这些电话号码不都是 11 位的呢？你可以给不是 11 位的那些号码在前面补 0，补齐 11 位，因为这样也不会影响比较。 可以仔细想想，基数排序是需要可以分割出独立的“位”来比较的，而且“位”之间有递进的关系，如果 a 数据的高位比 b 数据大，那么剩下的低位就不用比较了。而且每一位上的数据范围不能太大，否则就不能用线性排序了，最终也就达不到 O(n) 的时间复杂度了。 如何实现一个通用的、高性能的排序算法 由于 O(n) 这类线性排序算法只适用于特定数据，所以不太考虑。一般小数据量选择冒泡、选择、插入这种 O(nn) 的排序，但是当数据量大的时候，肯定还是选择 O(nlogn) 的，那么这里又有归并、快排，堆排序，由于归并不是原地排序，需要耗费额外空间，所以一般用的是快排，那么快排也有缺点就是当最坏情况（也就是当所有的数据都跑到一个分区里面了）下会变成 O(n*n)，这是由于分区点选的不合理导致的，当分区点分成的分区之间数据量差不多才是最理想的。 为了让每个分区数据量都比较平均，也就是你要找到一个 pivot，这个 pivot 越接近中位数越好，那么我们一般可以用： 1.三数取中法（多数取中法） 从首、尾、中间取到三个点，取这三个数的中间值作为 pivot。 2.随机法 也就是从这些数据中随机去一个数作为 pivot，这样也比你每次都取第一个或者最后一个数作为 pivot 遇到最坏情况的可能性要小。 C 语言中的 qsort() 函数 这个函数会优先使用归并排序，因为当数据量少的时候排序更稳定。但数据量大的时候会转而使用快排，而且 qsort() 函数在快排中也是用三数取中法来确定 pivot 的。并且当数据量很小很小时，它会转而使用插入排序，因为小数据量的时候 O(n*n) 并不一定比 O(nlogn) 的算法执行时间长。 而且为了防止堆栈溢出，qsort 实现了一个堆上的栈，手动模拟递归。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-01-24 15:28:46 "},"8-数据结构和算法之美/数组.html":{"url":"8-数据结构和算法之美/数组.html","title":"数组","keywords":"","body":"数组 数组：是一种线性表数据结构，用一组连续的存储空间来存储一组具有相同类型的数据。 首先看线性表，链表、队列、栈都是线性表结构，线性表上的数据最多只有前后两个方向。和它对立的是非线性表，比如二叉树、堆、图，这里面的数据并不是简单的前后关系。 再看连续的存储空间和相同的数据类型，就是由于这两个特点它才有随机访问这个绝招。但为了保持数据的连续性，导致插入、删除等操作变得很麻烦。 注意：数组是适合查找，但是说它查找的时间复杂度是 O(1) 就不太对了，就算你数组是有序排列，用二分查找也要 O(logn)，正确的说法是：根据数组下标进行随机访问的时间复杂度是 O(1)。 低效的插入和删除 每次插入都需要将插入位置后面的所有数据往后移动，但是假如这个数组只是用来存储一块数据，它们前后直接并没有什么关系，那么我们可以将插入位置的数据放到最后一个位置，再把插入的数据放到插入位置即可。 删除也是这个道理，如果每次删除都去移动，是低效的，但是如果很多次删除连在一起，我们可以在每次删除的时候进行虚假删除，记录下每次删除的数据，在最后集中删除，这样就只需要将所有数据移动一次就行了。JVM 的标记清除垃圾回收算法就是这个原理。 警惕数组的越界访问问题 在 C 语言中，并没有决定当数组越界之后编译器应该怎么做，因为访问数组的本质就是访问一段连续的内存，只要数组通过偏移得到的访问地址是可用的，程序就不会报错。 int main(int argc, char* argv[]){ int i = 0; int arr[3] = {0}; for(; i 其实更为细节的是，应该去了解在函数调用的时候会用到栈，在这里 main 函数会依次往栈中压入 i、arr[2]、arr[1]、arr[0]，由于栈是向下增长的，所以当访问 a[3] 的时候其实访问的是变量 i ，而且 i 变量的地址是属于当前进程的，所以操作系统不会终止进程。这段代码会无限打印 hello world。 但 Java 在数组越界会：java.lang.ArrayIndexOutOfBoundsException。 容器是否能替代数组 比如 ArrayList，它将数组的很多操作封装起来，且支持动态扩容，每次不够时会扩容至 1.5 倍，但是需要注意每次扩容涉及到空间申请、数据迁移，要花费比较多的时间，所以尽量在创建 ArrayList 的时候就指定大小。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-22 23:10:33 "},"8-数据结构和算法之美/栈.html":{"url":"8-数据结构和算法之美/栈.html","title":"栈","keywords":"","body":"栈 先进后出，从操作上看是一种“操作受限”的数据结构，当然栈可以用数组和链表实现。那么仔细想想为什么不直接用数据或者链表呢，为什么要使用这种操作受到限制的结构呢？其实会发现数据或者链表过多的暴露了操作的接口，而栈只能从栈顶进行入栈或者出栈操作。 每一种数据结构都是有特定的应用场景的。 栈在函数调用中的应用：一个 main 函数调用一个 add 函数，栈中会存储函数调用时的临时变量。当进入一个函数时，这个函数中的每一个临时变量都会以一个栈帧的形式入栈，当被调用函数执行完成后，返回之后，这个函数对应的所有栈帧都会出栈。 栈在表达式求值时的应用：用两个栈，一个操作数栈、一个操作符栈 栈在括号匹配时的应用：左括号入栈，右括号取栈顶元素进行匹配后将栈顶元素出栈 如何用栈实现浏览器的前进和后退功能呢？ 也是用两个栈 X，Y，当不断的点击网页（前进） 比如 a,b,c，那么依次将 a,b,c 入栈 X，当后退的时候从 c 退回 b，那就需要将 c 从栈 X 出栈然后入栈 Y，但是如果你到网页 b 之后点击了一个新的网页 d，那么此时你无法再返回 c 了，所以你需要将栈 Y 清空。 问题1：为什么要用栈来实现函数的调用，可以用别的数据结构吗？ 因为函数调用的执行顺序符合栈的先进后出的特点，比如函数中局部变量的生命周期就是先定义的生命周期长，后定义的短。函数调用也是满足这个特点，只有当该函数内部调用的函数执行结束之后该函数才会结束。 其实并不是一定要用栈来实现函数调用，函数被调用时数据会发生什么变化呢？其实本质就是作用域，只要能够保证每进入一个新的函数都是一个新的作用域就行了。所以这里用栈很方便，每进入一个新函数，分配一段新的栈空间就行了，当这个被调用函数结束之后，恢复到原来的栈顶就行了。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-21 17:17:20 "},"8-数据结构和算法之美/链表.html":{"url":"8-数据结构和算法之美/链表.html","title":"链表","keywords":"","body":"链表 链表中比较常见的几个问题：除了环的检测，其它几个都比较简单，利用快慢指针就可以做了。 单链表反转 链表中环的检测 两个有序的链表合并 删除链表倒数第 n 个节点 求链表的中间节点 注意点： 警惕指针丢失和内存泄漏 利用哨兵简化难度，比如要对第一个节点或者最后一个节点操作，我们可以增加两个空节点分别在首尾，这样就躲过了原本需要处理的第一个和最后一个节点的特殊情况。 留意边界条件的处理 1.如果链表为空时，会不会报错？ 2.只包含一个节点、或者只包含两个节点，会不会报错？ 3.代码逻辑在处理首尾节点，有没有问题？ Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2021-04-01 10:06:01 "},"8-数据结构和算法之美/队列.html":{"url":"8-数据结构和算法之美/队列.html","title":"队列","keywords":"","body":"队列 和栈一样，也是一种操作受限的线性表数据结构，先进先出。也有顺序队列和链式队列。队列中有 head，tail，如果你用的是数组来实现队列，那么当 tail = n 时，就应该执行数据搬移操作，将所有数据向前移至数组第一个元素的位置。 循环队列 如果每次当 tail = n 的时候都要去进行数据搬移，那么会影响入队的性能。所以采用循环队列，那么要注意：用数组实现的非循环队列判断队满条件是：tail = n，队空：head = tail。那么判断循环队列队满的条件：(tail + 1)%n = head，队空：head = tail。 注意循环队列最后一个 tail 是不存数据的，如果最后一个 tail 也存了数据，你就无法判断是队满还是队空。 阻塞队列 就是在队列的基础上增加了阻塞操作，在队列为空的时候往队列中取元素会被阻塞，队列满的时候插入元素会被阻塞。所以这和“生产者-消费者”模型很像，所以你也可以通过协调生产者和消费者的数量来提高数据的处理效率。 这里设置了三个线程去 take，所以会涉及到线程安全问题，线程安全的队列称为并发队列，最简单的方法就是在 enqueue() 和 dequeue() 函数上加上锁，但锁粒度过大会导致并发度低。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-21 22:00:43 "}}