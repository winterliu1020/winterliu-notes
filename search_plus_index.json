{"./":{"url":"./","title":"Introduction","keywords":"","body":"winterliu-notes 我学习过程中记录的一些笔记 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 10:40:33 "},"notes/Java.html":{"url":"notes/Java.html","title":"Java 基础","keywords":"","body":"Java Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 17:23:22 "},"notes/Java基础.html":{"url":"notes/Java基础.html","title":"Java 基础1","keywords":"","body":"Java基础1 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 19:08:50 "},"notes/Java 并发.html":{"url":"notes/Java 并发.html","title":"Java 并发","keywords":"","body":"Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 18:54:10 "},"notes/负载均衡三种架构.html":{"url":"notes/负载均衡三种架构.html","title":"负载均衡三种架构","keywords":"","body":"1.负载均衡 负载均衡指的是通过一组后端服务器来有效的分发输入进来的网络请求，这里的服务器组其实就是 server pool. 总的来说，load balancer有以下功能： 将客户端的所有请求以及网络负载有效(这里涉及负载策略)的分发到各个服务器那里去。 确保这个 client-server 架构是 high availability and reliability 的，这些客户端发来的请求只会被分发到这些 online 的 server 那里去。 可以根据需求来灵活的增、减任意服务器。 Session Persistence 也就是 session 的持久性问题。一个用户的 session 一般都是直接存储在本地浏览器中，但是如果在分布式架构中，你去改变接收客户端请求的服务器，这个动作其实是会带来 performance issues 和 transaction failure 的。如果要保证性能不受影响、又保证传输成功的话，那就要做到： duration of the session， 来自于同一台客户端的所有请求都应该是被发送给同一台服务器。(load balancer 是可以处理这种问题的) 还有就是上游服务器会在它的缓存中直接存储用户要求的信息，通过这种方式来提高性能。但是如果你换了一台服务器来处理同一个客户端的请求，那么第二次这些用户要求的信息就需要从客户端那里重新 fetched 过来，这就造成了性能的 inefficiencies. 2.高并发负载均衡 -- LVS 模式 整个互联网是建立在下一跳的模式下，IP 是逻辑上的两个端点，MAC 是物理上连接的两个节点。 端点间 TCP 传输过程注意： 确认机制 状态机制 不可分割 解析数据包需要成本： 交换机：二层，只关心 MAC 地址 路由器：三层，只关心 IP 和路由表 LVS 服务器：四层，只关心 PORT,状态 Nginx：七层，关心 socket 对应关系(也就是说这里已经关注了应用层了!)利用负载均衡器的三种通信模型 第一种：source_net 模型 这是源NET，但是从互联网的角度出发，如果外面的机器想访问这个局域网中的某一台机器，如何访问？？？ 因为即便你知道它的公网地址18.18.18.8，你也不知道它的私有地址。。没有公网和私网地址的转换。。你最多访问到这个路由器的地址。。所以还是需要一个地址转换表，把公网转私网。。 第二种：DR 模型 VIP：虚拟服务器地址 DIP：转发的网络地址 和 RIP 通信：ARP 协议，获取 real server 的 RIP：MAC 地址 转发 client 的数据包到 RIP 上(其实是到 real server 内核里面的 VIP) RIP：后端真实主机 CIP：客户端 IP 地址 转成CIP_RIP之后，这时Server RIP才会接收这个包。 注意这里是目标地址转换，也就是D_NAT 然后，服务器端的RIP_PORT要返回数据包给客户端。。规则就是：RIP_PORT:CIP_PORT,但是如果服务器端返回RIP_CIP,这时客户端是会直接把它丢弃的。（其实就是客户端没有请求RIP，别人只是请求的VIP，现在返回一个RIP，这时客户端肯定不要啊。。）原因如下： 所以要规避这个问题，这样做： 不要把RIP_CIP直接返回给客户端，而是先交给负载均衡服务器，负载均衡服务器再恢复成VIP 给CIP返回就行了。。。。 为了把Server RIP服务器返回的所有数据包都给负载均衡服务器，所以需要把Server RIP的默认网关指向lvs 也就是负载均衡服务器。。 DR模型的第二种架构(最常用) 问题：由于客户端发送的请求数据相比服务器端返回的数据是很少的，所以可能5万个请求，只能返回1万个相应给客户端。。。因为服务器端都再次通过负载均衡给客户端传输相应数据太慢了。。。所以产生了以下这种模型。。。能不能直接从服务器端连接一跟光纤到客户端，这时：客户端发送请求还是通过负载均衡服务器发送给服务器端，但是服务器端返回的相应数据直接通过光纤传输，这样返回的数据传输就大大加快了！！！！！ 对于客户端来说，后面的负载均衡服务器和Server RIP都是透明的。。不管这些怎么变化，客户端还是CIP想访问VIP（这样套接字也就是：CIP_PORT:VIP_PORT），。。。。。。然后Server RIP需要返回一个VIP_CIP的数据包（也就是返回一个VIP包给CIP这个客户端。。） 但是！这就说明Server这台机器中必须要有一个VIP： VIP地址不能再在网络当中出现！！我们可以走擦边球，也就是给它持有这个VIP地址，但是别人问他有没有VIP地址时，他会返回没有。。。在真实的网络中真正有VIP的只有负载均衡服务器那里的VIP。 （下面图中我画的VIP_CIP反了，应该是CIP_VIP） 但是！！！！还有一个问题，就是：客户端发送一个CIP_VIP，去访问VIP，那么负载均衡器怎么扔给Server???? 解决办法如下： 在外面套一层MAC地址，也就是RIP-MAC。。。 数据包封的时候，在最外面加上RIP-MAC地址。。要有一个约束：就是负载均衡服务器和真正的server在同一个局域网。。。这里涉及到的叫MAC欺骗。。 最后注意一点：右边的几台真正的server，他们其实长得是一样的，也就是配置、资源位置都是一样的，这样面对几万个资源请求是，负载均衡器只要稍微平均一下分发给不同的server就行了。。 IP 背着 IP 架构(隧道技术) 无论翻墙也好还是VPN也好，都是IP背着IP这种机制。。。 比如你租了一台香港的服务器，因为香港的服务器可以访问国外的IP，所以先从你这里传到香港你租的服务器IP地址(这个过程其实就是隧道。。)，然后你的服务器再看到里层你想去的国外的IP地址。。。就比如这里的DIP_RIP背着CIP_VIP。。把这里的负载均衡器看成你租的香港服务器，那么你先要请求VIP，所以你发送一个CIP_VIP先给这个香港服务器，香港服务器知道你真正想访问的是RIP这个真实的服务器地址，然后就组成包DIP_RIP,其中的数据就是CIP_VIP，然后这个大包到达RIP之后，真正的服务器也就知道你是采用这种IP背着IP的技术传过来的数据包，所以他会把外壳脱去，知道真正发来请求的是CIP。。emm...真他妈难。。。受 然后RIP返回相应数据又有两种方式。。一种是继续通过负载均衡器返回数据，还有一种可以直接把数据给CIP。。。可以通过设置选择不同的方式。 参考文章 Nginx Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 17:51:43 "},"notes/网络的层次介绍.html":{"url":"notes/网络的层次介绍.html","title":"网络的层次介绍","keywords":"","body":"网络介绍 netstat -natp;虽然就是两台主机的参与，但是这里有4个TCP连接，说明TCP连接的虚拟性， 并不是真实的两条物理线的连接，就比如这里一台主机里面四个端口就相当于4个虚拟连接了 /etc/sysconfig/network-scripts/ifcfg-eth0\" 查看网卡。。。配置 route -n 互联网的传输方式是基于下一跳的方式，而不是基于路径规划的方式。。。 网络层就是决定下一跳。。 总结： 互联网确实是建立在下一跳的机制之上，不光要IP地址就行了，还需要链路层 利用MAC地址不断下一跳。。。。 三层 这是能够知道IP地址的逻辑地址，怎么知道目的机器的网卡地址呢？？ 本质： 这样可以一个数据包传输，那么网络通信无非就是先TCP三次握手，然后客户端和服务器端发送真正的数据，发发发。。。最后TCP4次分手。。。。这就是网络数据通信。。 ARP协议： 网络传输总结： 比如一个浏览器想请求服务器端Tomcat返回一个页面资源，首先不是从最上层应用层开始的，而是最上层这个请求先阻塞。。。先从第四层TCP层开始发送握手包。。， 1.先TCP-->IP-->数据链路层 （ 这当中有申请端口号的、有做路由表判定的、有网络请求下一跳地址的。。）-->物理层 2.然后服务器端的：物理层-->数据链路层-->IP层-->TCP层，这样来回发送三次数据包传输，也就是TCP三次握手，到此C/S两边的TCP打通了。。然后两边开辟资源之后，然后！才会从最上层的应用层传输真正的数据包依次往下。。。到达服务端的物理层-->.......-->应用层。。。 这样就完成了网络数据传输！！！！！！！！！！！！！！！！！！ 也就是：虽然是7层交互，但是要先4层TCP先建立连接，建立的连接都是IP,port连接，很多这样的IP，port连接，但是这些都是虚拟的连接。。。 目的是知道：你最终知道什么是负载均衡服务器，以及它们的性能开销和弊端。。 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 17:51:43 "},"notes/Compute-Network.html":{"url":"notes/Compute-Network.html","title":"Compute-Network","keywords":"","body":"Compute-Network Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 15:18:01 "},"notes/计算机网络介绍.html":{"url":"notes/计算机网络介绍.html","title":"计算机网络介绍","keywords":"","body":"计算机网络介绍 Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 19:07:42 "},"notes/LeetCode.html":{"url":"notes/LeetCode.html","title":"LeetCode","keywords":"","body":"LeetCode Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 17:51:43 "},"notes/1.html":{"url":"notes/1.html","title":"第一","keywords":"","body":"diyiti Copyright © winterliu all right reserved，powered by Gitbook该文章修订时间： 2020-04-07 19:02:57 "}}